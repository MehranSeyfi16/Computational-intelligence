{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d4951e2-39e3-4424-b3a4-67b29dd32554",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66d1d180-d308-4bcd-a2fa-93efecf95062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import sys'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "# Misc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "pd.options.display.max_seq_items = 8000\n",
    "pd.options.display.max_rows = 8000\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import pandas as pd # dataframe manipulation\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from yellowbrick.cluster import KElbowVisualizer # cluster visualizer\n",
    "\n",
    "# sklearn kmeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import rand_score\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "\n",
    "\n",
    "# pyclustering kmeans\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.utils.metric import distance_metric\n",
    "from pyclustering.cluster.center_initializer import random_center_initializer\n",
    "from pyclustering.cluster.encoder import type_encoding\n",
    "from pyclustering.cluster.encoder import cluster_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d6da1b-2739-442d-9e1b-8591d3330ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "[0 1 2 0 0 1 0 2 0 0 2 1 1 1 1 0 2 0 0 2 1 0 1 2 2 2 2 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "x = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "# print(np.unique(y))\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train , x_test , y_train , y_test = train_test_split(x,y,random_state=42,test_size=0.2)\n",
    "kmeans.fit(x_train)\n",
    "x_pred = kmeans.predict(x_test)\n",
    "\n",
    "print(y_test)\n",
    "print(x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f918f80-aa84-4483-a166-3555bebd8422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981703936425799"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_rand_score(y_test, x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc454a7b-9c32-4f03-b3cb-c01bc0a7ca8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9563218390804598"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_score(y_test, x_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59bd142b-0d08-4493-8252-87e874682aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869123863067224"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_info_score(y_test, x_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eeabda-3a20-4bf8-bc45-f5d01ef01d5c",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414690ec-9aea-4557-848c-3c5250d2f7da",
   "metadata": {},
   "source": [
    "## We can use evaluation set data that is a part of train set data. So this will act like test data when we do not have a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345f7bf3-8bea-455b-8d03-49542c4e722f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
