{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f48763-4400-4cdc-be26-18db47519de2",
   "metadata": {},
   "source": [
    "# The Fourth Exercise of The Computational Intelligence Course - Spring 1402"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340cb1e-f587-4b21-8089-c21ba2bead37",
   "metadata": {},
   "source": [
    "### Import Essentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "262f6851-8cc0-498b-90d2-2e491ef576b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import sys'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from typing import Tuple\n",
    "from numpy import reshape\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "pd.options.display.max_seq_items = 8000\n",
    "pd.options.display.max_rows = 8000\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "import os\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from sklearn.metrics.cluster import silhouette_score\n",
    "\n",
    "#classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415bfba0-f9b4-4a80-8f4e-fe113a4a699d",
   "metadata": {},
   "source": [
    "### Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b2f85cb-a532-49cd-8de6-4a77fe1c101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    data = np.load(f'{filename}')\n",
    "    return data['data'], data['labels']\n",
    "\n",
    "train_data, train_labels = load_data('train_data_SYN.npz')\n",
    "test_data, test_labels = load_data('test_data_SYN.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5fc706-6fa6-4553-9ffc-245c3784431c",
   "metadata": {},
   "source": [
    "### Part one \n",
    "* #### Here, the goal is to use an svm model that recognizes digits' labels well. So, we first start with the default parameters of SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a660b-563d-46ed-9289-3c4f3e86215d",
   "metadata": {},
   "source": [
    "### Default hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d83cab7-9be7-4c63-a6a0-60fe93c8cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.8990\n"
     ]
    }
   ],
   "source": [
    "svc=SVC() \n",
    "svc.fit(train_data,train_labels)\n",
    "y_pred=svc.predict(test_data)\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e6861-a84b-45d1-aa0f-8104e9ba6fe3",
   "metadata": {},
   "source": [
    "#### With the default parameters: \n",
    "* #### means C=1.0\n",
    "* #### kernel=rbf\n",
    "* #### gamma=auto among other parameters. \n",
    "\n",
    "#### The score doesn't seem bad! But from now on, we will try to tune the models' parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ac127-4442-4f34-9e01-aa1a51890463",
   "metadata": {},
   "source": [
    "#### Hyperparameter Optimization using GridSearch CV\n",
    "* #### Stratified k-fold Cross Validation with shuffle split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a982d45c-159d-41c5-8803-5bc9a570d100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
       "                         {'C': [1, 10, 100, 1000],\n",
       "                          'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8,\n",
       "                                    0.9],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'degree': [2, 3, 4],\n",
       "                          'gamma': [0.01, 0.02, 0.03, 0.04, 0.05],\n",
       "                          'kernel': ['poly']}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=SVC() \n",
    "\n",
    "# declare parameters for hyperparameter tuning\n",
    "parameters = [ {'C':[1, 10, 100, 1000], 'kernel':['linear']},\n",
    "               {'C':[1, 10, 100, 1000], 'kernel':['rbf'], 'gamma':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]},\n",
    "               {'C':[1, 10, 100, 1000], 'kernel':['poly'], 'degree': [2,3,4] ,'gamma':[0.01,0.02,0.03,0.04,0.05]} \n",
    "              ]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = svc,  \n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5,\n",
    "                           verbose=0)\n",
    "\n",
    "grid_search.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e46f5d15-da19-4f57-ad42-4bf3afc815f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with sigmoid kernel and C=100.0 : 0.8588\n"
     ]
    }
   ],
   "source": [
    "y_pred=grid_search.predict(test_data)\n",
    "print('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ba0c900e-5f19-4975-bb2e-02859819c67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "grid_search.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc4f89-c216-462a-9cbb-21d02dd03595",
   "metadata": {},
   "source": [
    "### Understanding the Impact of C and Gamma Parameters, as well as Kernels, on SVM Algorithm Performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24718ef8-365c-4278-b172-a5063d89ec98",
   "metadata": {},
   "source": [
    "Firstly, it is important to understand that the SVM algorithm is essentially a linear classifier that finds the optimal separating hyperplane between two classes of data. However, when the data is not linearly separable, the SVM uses a kernel function to transform the data into a higher-dimensional space, where it may be linearly separable. The choice of kernel function has a significant impact on the performance of the SVM, as different kernels have different nonlinear mapping capabilities. \n",
    "\n",
    "The four kernels used in this study are:\n",
    "\n",
    "1. Linear Kernel: The linear kernel assumes that the data is linearly separable. It does not perform any feature transformation and simply computes the dot product between input vectors. This kernel is suitable for datasets with simple linear decision boundaries.\n",
    "\n",
    "2. RBF Kernel: The radial basis function (RBF) kernel is a popular choice for nonlinear classification problems. It is capable of transforming the input data into an infinite-dimensional space, where it becomes linearly separable. However, increasing the value of the gamma parameter makes the decision boundary tighter around the training data, which may lead to overfitting.\n",
    "\n",
    "3. Sigmoid Kernel: The sigmoid kernel is commonly used in binary classification tasks. It maps the input data into an infinite-dimensional space using a sigmoid function. However, it is more sensitive to small changes in the input values than the other kernels, which may lead to poor generalization.\n",
    "\n",
    "4. Poly Kernel: The polynomial kernel performs a feature expansion of the input data, making it possible to fit nonlinear decision boundaries. However, increasing the degree of the polynomial may result in overfitting, while decreasing it may lead to underfitting.\n",
    "\n",
    "The C parameter in the SVM algorithm controls the trade-off between maximizing the margin and minimizing the training error. A low value of C allows for a wider margin, which may reduce overfitting, while a high value of C allows for a smaller margin, which may lead to overfitting. The gamma parameter controls the shape of the decision boundary. A low value of gamma results in a smoother decision boundary, while a high value of gamma makes it more complex.\n",
    "\n",
    "In terms of performance, the SVM algorithm with the linear kernel is less sensitive to changes in the C and gamma parameters because it assumes that the data is linearly separable. However, the other kernels are more sensitive to these parameters. In general, increasing the value of C increases the risk of overfitting, while decreasing it leads to underfitting. Similarly, increasing the value of gamma makes the decision boundary tighter around the training data, which may result in overfitting, while decreasing it makes the decision boundary smoother and may lead to underfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd629cc2-5bca-4667-8603-7a9d6f72eb78",
   "metadata": {},
   "source": [
    "#### Running svm models with different C and gammas with ***linear*** kernel to see how the resaluts changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3e6e6d6c-2f21-4341-ab86-af107d997810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with C=0.01 and gamma=0.001: 0.8706\n",
      "Model accuracy score with C=0.01 and gamma=0.010: 0.8706\n",
      "Model accuracy score with C=0.01 and gamma=0.100: 0.8706\n",
      "Model accuracy score with C=0.01 and gamma=1.000: 0.8706\n",
      "Model accuracy score with C=0.01 and gamma=10.000: 0.8706\n",
      "Model accuracy score with C=0.10 and gamma=0.001: 0.8588\n",
      "Model accuracy score with C=0.10 and gamma=0.010: 0.8588\n",
      "Model accuracy score with C=0.10 and gamma=0.100: 0.8588\n",
      "Model accuracy score with C=0.10 and gamma=1.000: 0.8588\n",
      "Model accuracy score with C=0.10 and gamma=10.000: 0.8588\n",
      "Model accuracy score with C=1.00 and gamma=0.001: 0.8588\n",
      "Model accuracy score with C=1.00 and gamma=0.010: 0.8588\n",
      "Model accuracy score with C=1.00 and gamma=0.100: 0.8588\n",
      "Model accuracy score with C=1.00 and gamma=1.000: 0.8588\n",
      "Model accuracy score with C=1.00 and gamma=10.000: 0.8588\n",
      "Model accuracy score with C=10.00 and gamma=0.001: 0.8588\n",
      "Model accuracy score with C=10.00 and gamma=0.010: 0.8588\n",
      "Model accuracy score with C=10.00 and gamma=0.100: 0.8588\n",
      "Model accuracy score with C=10.00 and gamma=1.000: 0.8588\n",
      "Model accuracy score with C=10.00 and gamma=10.000: 0.8588\n",
      "Model accuracy score with C=100.00 and gamma=0.001: 0.8588\n",
      "Model accuracy score with C=100.00 and gamma=0.010: 0.8588\n",
      "Model accuracy score with C=100.00 and gamma=0.100: 0.8588\n",
      "Model accuracy score with C=100.00 and gamma=1.000: 0.8588\n",
      "Model accuracy score with C=100.00 and gamma=10.000: 0.8588\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "gamma_values = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for c_value in c_values:\n",
    "    for gamma_value in gamma_values:\n",
    "        svc = SVC(kernel='linear', C=c_value, gamma=gamma_value)\n",
    "        svc.fit(train_data, train_labels)\n",
    "        y_pred = svc.predict(test_data)\n",
    "        print('Model accuracy score with C={:.2f} and gamma={:.3f}: {:.4f}'.format(c_value, gamma_value, \n",
    "                                                                                    accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ab616-1513-4bfe-b7c1-8de4c841d9c1",
   "metadata": {},
   "source": [
    "#### Running svm models with different C and gammas with ***rbf*** kernel to see how the resaluts changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62d8db69-946d-42fd-89af-f96335372976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with C=0.01 and gamma=0.001: 0.1380\n",
      "Model accuracy score with C=0.01 and gamma=0.010: 0.1078\n",
      "Model accuracy score with C=0.01 and gamma=0.100: 0.1078\n",
      "Model accuracy score with C=0.01 and gamma=1.000: 0.1078\n",
      "Model accuracy score with C=0.01 and gamma=10.000: 0.1078\n",
      "Model accuracy score with C=0.10 and gamma=0.001: 0.7166\n",
      "Model accuracy score with C=0.10 and gamma=0.010: 0.1930\n",
      "Model accuracy score with C=0.10 and gamma=0.100: 0.1078\n",
      "Model accuracy score with C=0.10 and gamma=1.000: 0.1078\n",
      "Model accuracy score with C=0.10 and gamma=10.000: 0.1078\n",
      "Model accuracy score with C=1.00 and gamma=0.001: 0.8882\n",
      "Model accuracy score with C=1.00 and gamma=0.010: 0.6884\n",
      "Model accuracy score with C=1.00 and gamma=0.100: 0.0968\n",
      "Model accuracy score with C=1.00 and gamma=1.000: 0.1078\n",
      "Model accuracy score with C=1.00 and gamma=10.000: 0.1078\n",
      "Model accuracy score with C=10.00 and gamma=0.001: 0.8918\n",
      "Model accuracy score with C=10.00 and gamma=0.010: 0.7096\n",
      "Model accuracy score with C=10.00 and gamma=0.100: 0.0968\n",
      "Model accuracy score with C=10.00 and gamma=1.000: 0.1078\n",
      "Model accuracy score with C=10.00 and gamma=10.000: 0.1078\n",
      "Model accuracy score with C=100.00 and gamma=0.001: 0.8916\n",
      "Model accuracy score with C=100.00 and gamma=0.010: 0.7096\n",
      "Model accuracy score with C=100.00 and gamma=0.100: 0.0968\n",
      "Model accuracy score with C=100.00 and gamma=1.000: 0.1078\n",
      "Model accuracy score with C=100.00 and gamma=10.000: 0.1078\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "gamma_values = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for c_value in c_values:\n",
    "    for gamma_value in gamma_values:\n",
    "        svc = SVC(kernel='rbf', C=c_value, gamma=gamma_value)\n",
    "        svc.fit(train_data, train_labels)\n",
    "        y_pred = svc.predict(test_data)\n",
    "        print('Model accuracy score with C={:.2f} and gamma={:.3f}: {:.4f}'.format(c_value, gamma_value, \n",
    "                                                                                    accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634c1542-ae16-435e-bbf2-eb60c72a113c",
   "metadata": {},
   "source": [
    "#### Running svm models with different C and gammas with ***poly*** kernel to see how the resaluts changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "062cabb6-a875-4745-89ea-894c9c0595b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with C=0.01 and gamma=0.001: 0.1078\n",
      "Model accuracy score with C=0.01 and gamma=0.010: 0.8680\n",
      "Model accuracy score with C=0.01 and gamma=0.100: 0.8796\n",
      "Model accuracy score with C=0.01 and gamma=1.000: 0.8796\n",
      "Model accuracy score with C=0.01 and gamma=10.000: 0.8796\n",
      "Model accuracy score with C=0.10 and gamma=0.001: 0.1604\n",
      "Model accuracy score with C=0.10 and gamma=0.010: 0.8806\n",
      "Model accuracy score with C=0.10 and gamma=0.100: 0.8796\n",
      "Model accuracy score with C=0.10 and gamma=1.000: 0.8796\n",
      "Model accuracy score with C=0.10 and gamma=10.000: 0.8796\n",
      "Model accuracy score with C=1.00 and gamma=0.001: 0.5658\n",
      "Model accuracy score with C=1.00 and gamma=0.010: 0.8798\n",
      "Model accuracy score with C=1.00 and gamma=0.100: 0.8796\n",
      "Model accuracy score with C=1.00 and gamma=1.000: 0.8796\n",
      "Model accuracy score with C=1.00 and gamma=10.000: 0.8796\n",
      "Model accuracy score with C=10.00 and gamma=0.001: 0.8680\n",
      "Model accuracy score with C=10.00 and gamma=0.010: 0.8796\n",
      "Model accuracy score with C=10.00 and gamma=0.100: 0.8796\n",
      "Model accuracy score with C=10.00 and gamma=1.000: 0.8796\n",
      "Model accuracy score with C=10.00 and gamma=10.000: 0.8796\n",
      "Model accuracy score with C=100.00 and gamma=0.001: 0.8806\n",
      "Model accuracy score with C=100.00 and gamma=0.010: 0.8796\n",
      "Model accuracy score with C=100.00 and gamma=0.100: 0.8796\n",
      "Model accuracy score with C=100.00 and gamma=1.000: 0.8796\n",
      "Model accuracy score with C=100.00 and gamma=10.000: 0.8796\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "gamma_values = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for c_value in c_values:\n",
    "    for gamma_value in gamma_values:\n",
    "        svc = SVC(kernel='poly', C=c_value, gamma=gamma_value)\n",
    "        svc.fit(train_data, train_labels)\n",
    "        y_pred = svc.predict(test_data)\n",
    "        print('Model accuracy score with C={:.2f} and gamma={:.3f}: {:.4f}'.format(c_value, gamma_value, \n",
    "                                                                                    accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d47b848-3bc0-4346-8957-8d92387af687",
   "metadata": {},
   "source": [
    "#### Running svm models with different C and gammas with ***sigmoid*** kernel to see how the resaluts changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "97c269f3-8ac1-4b26-ba7f-796aba717ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with C=0.01 and gamma=0.001: 0.1180\n",
      "Model accuracy score with C=0.01 and gamma=0.010: 0.2462\n",
      "Model accuracy score with C=0.01 and gamma=0.100: 0.1394\n",
      "Model accuracy score with C=0.01 and gamma=1.000: 0.1364\n",
      "Model accuracy score with C=0.01 and gamma=10.000: 0.1364\n",
      "Model accuracy score with C=0.10 and gamma=0.001: 0.7000\n",
      "Model accuracy score with C=0.10 and gamma=0.010: 0.2670\n",
      "Model accuracy score with C=0.10 and gamma=0.100: 0.1000\n",
      "Model accuracy score with C=0.10 and gamma=1.000: 0.1126\n",
      "Model accuracy score with C=0.10 and gamma=10.000: 0.0934\n",
      "Model accuracy score with C=1.00 and gamma=0.001: 0.8646\n",
      "Model accuracy score with C=1.00 and gamma=0.010: 0.2120\n",
      "Model accuracy score with C=1.00 and gamma=0.100: 0.0956\n",
      "Model accuracy score with C=1.00 and gamma=1.000: 0.1120\n",
      "Model accuracy score with C=1.00 and gamma=10.000: 0.0926\n",
      "Model accuracy score with C=10.00 and gamma=0.001: 0.8682\n",
      "Model accuracy score with C=10.00 and gamma=0.010: 0.2086\n",
      "Model accuracy score with C=10.00 and gamma=0.100: 0.0962\n",
      "Model accuracy score with C=10.00 and gamma=1.000: 0.0960\n",
      "Model accuracy score with C=10.00 and gamma=10.000: 0.0936\n",
      "Model accuracy score with C=100.00 and gamma=0.001: 0.8496\n",
      "Model accuracy score with C=100.00 and gamma=0.010: 0.2086\n",
      "Model accuracy score with C=100.00 and gamma=0.100: 0.0958\n",
      "Model accuracy score with C=100.00 and gamma=1.000: 0.0960\n",
      "Model accuracy score with C=100.00 and gamma=10.000: 0.0938\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "gamma_values = [0.001, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for c_value in c_values:\n",
    "    for gamma_value in gamma_values:\n",
    "        svc = SVC(kernel='sigmoid', C=c_value, gamma=gamma_value)\n",
    "        svc.fit(train_data, train_labels)\n",
    "        y_pred = svc.predict(test_data)\n",
    "        print('Model accuracy score with C={:.2f} and gamma={:.3f}: {:.4f}'.format(c_value, gamma_value, \n",
    "                                                                                    accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719ebe9-0d69-4373-a0e5-1eaf88cc5289",
   "metadata": {},
   "source": [
    "First, let's discuss the role of the kernel. The kernel is a function that transforms the input data into a higher-dimensional space in which it may be more separable. In this case, we have used four different kernels: linear, rbf (radial basis function), sigmoid, and poly (polynomial). Linear kernel is used for linearly separable data, rbf kernel is used for non-linearly separable data, sigmoid kernel is used for binary classification tasks, and poly kernel is used for polynomial feature transformation. As we can see from the results, the choice of kernel has a significant impact on the accuracy score. \n",
    "\n",
    "Next, let's talk about the role of the C and gamma parameters. C is the regularization parameter, which balances the trade-off between correctly classifying training data and keeping the model simple (to avoid overfitting). Higher values of C allow more strict fitting to the training data, while lower values allow more flexibility. Gamma, on the other hand, controls the shape of the decision boundary. A low gamma means that the decision boundary is relatively flat, while a high gamma means that the decision boundary is more irregular.\n",
    "\n",
    "Now let's analyze the results of the code runs with each kernel:\n",
    "\n",
    "1. Linear Kernel:\n",
    "    - We can observe that increasing or decreasing the values of C and gamma does not significantly impact the accuracy score.\n",
    "    - This is because the linear kernel assumes that the data is linearly separable, so changing the regularization or decision boundary does not make a big difference.\n",
    "\n",
    "\n",
    "2. RBF Kernel:\n",
    "    - For the rbf kernel, we can see that increasing gamma leads to a decrease in accuracy score. This is because high gamma makes the decision boundary very specific to the training data, leading to overfitting and poor generalization to new data.\n",
    "    - We can also see that increasing C leads to an increase in accuracy score, but only up to a certain point. After this point, further increases in C do not lead to significant improvements in accuracy. This is because high values of C may lead to overfitting, as the model is too complex.\n",
    "\n",
    "\n",
    "3. Sigmoid Kernel:\n",
    "    - For the sigmoid kernel, we can observe that increasing or decreasing gamma does not have a significant impact on the accuracy score. However, the optimal value of gamma depends on the value of C. When C is low, a higher gamma leads to better performance, while when C is high, a lower gamma is better.\n",
    "    - We can also see that increasing C leads to a decrease in accuracy score. This happens because high values of C lead to overfitting, as the model tries to fit the training data too closely.\n",
    "\n",
    "\n",
    "4. Poly Kernel:\n",
    "    - For the poly kernel, we can observe that increasing or decreasing gamma does not have a significant impact on the accuracy score. However, the optimal value of gamma depends on the value of C. When C is low, a higher gamma leads to better performance, while when C is high, a lower gamma is better.\n",
    "    - We can also see that increasing C leads to an increase in accuracy score, but only up to a certain point. After this point, further increases in C do not lead to significant improvements in accuracy. This is because high values of C may lead to overfitting, as the model is too complex.\n",
    "\n",
    "In summary, the choice of kernel has a significant impact on the accuracy score, and the optimal values of C and gamma depend on the kernel. In general, high values of C may lead to overfitting, while high values of gamma may also lead to overfitting and poor generalization to new data. Therefore, it is important to experiment with different values of C and gamma to find the optimal values for a given dataset and kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99029b84-1bb0-4bc1-a045-20497ed804c8",
   "metadata": {},
   "source": [
    "#### According to the above analysis, we can see that the svm classifier with rbf kernel and c = 100 gives the best results -considering not beimg overfitted and also be generalized, now we try to make the best model by setting other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3c891c12-97fe-43b3-bb5d-38adbda05d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate classifier with rbf kernel and C=100\n",
    "svc=SVC(C= 100.0,\n",
    " break_ties= False,\n",
    " cache_size= 200,\n",
    " class_weight= None,\n",
    " coef0= 0.0,\n",
    " decision_function_shape= 'ovr',\n",
    " degree= 3,\n",
    " gamma= 'scale',\n",
    " kernel= 'rbf',\n",
    " max_iter= -1,\n",
    " probability= False,\n",
    " random_state= None,\n",
    " shrinking= True,\n",
    " tol= 0.001,\n",
    " verbose= False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "77055eed-6300-48f5-8ec9-642774d39f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=100.0 : 0.9018\n"
     ]
    }
   ],
   "source": [
    "svc.fit(train_data,train_labels)\n",
    "y_pred=svc.predict(test_data)\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671dfc7f-e1ee-4db7-b6ac-4bb5f74a47d0",
   "metadata": {},
   "source": [
    "#### *0.9018* is a better than all of the previous scores!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf652af3-d4d2-496c-a1cd-3582a30e3a91",
   "metadata": {},
   "source": [
    "The SVC is instantiated with the following parameter values:\n",
    "- C=100.0: Penalty parameter for the error term. Set to 100.0.\n",
    "- break_ties=False: In case of a tie in predicted class labels, predict method will not break ties according to confidence values. Set to False.\n",
    "- cache_size=200: Size of kernel cache in MB. Set to 200.\n",
    "- class_weight=None: Weights associated with classes. None means all classes have equal weight.\n",
    "- coef0=0.0: Independent term in kernel function. Only significant in ‘poly’ and ‘sigmoid’ kernels. Set to 0.0.\n",
    "- decision_function_shape='ovr': Determines whether one-vs-one (‘ovo’) or one-vs-rest (‘ovr’) multi-class strategy is used. Set to 'ovr'.\n",
    "- degree=3: Degree of the polynomial kernel function. Ignored by other kernels. Set to 3.\n",
    "- gamma='scale': Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. High gamma can cause overfitting. Set to 'scale'.\n",
    "- kernel='rbf': Specifies which kernel to use. rbf is Radial basis function kernel. Set to 'rbf'.\n",
    "- max_iter=-1: Hard limit on iterations within solver. -1 means no limit. Set to -1.\n",
    "- probability=False: Whether to enable probability estimates for classification. Set to False.\n",
    "- random_state=None: Seed for pseudo-random number generator used by the shuffling of samples for probability estimation. Set to None.\n",
    "- shrinking=True: Whether to use the shrinking heuristic. Set to True.\n",
    "- tol=0.001: Tolerance for stopping criterion. Set to 0.001.\n",
    "- verbose=False: Controls the verbosity when fitting and predicting. Set to False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd6e2eb-8fe6-4dea-9927-ac4d6bd77097",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c1d7c36-5e9c-467f-95e4-51ef41aab93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(y_true, y_pred, figsize=(10,10)):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true))\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(cm, cmap= \"YlGnBu\", annot=annot, fmt='', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "901d96fb-2438-42f4-a3dc-ccc2aac226f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[440,   6,   8,   1,   4,   0,  11,   3,   3,   7],\n",
       "       [  1, 467,  18,   3,  14,   0,   1,  33,   2,   0],\n",
       "       [  7,   8, 502,   2,   2,   3,   5,   6,   2,   2],\n",
       "       [  3,   7,  12, 414,   5,  21,   6,   0,   8,   8],\n",
       "       [  4,  22,   5,   2, 441,   0,   3,   2,   2,   9],\n",
       "       [ 11,   4,   9,  28,   1, 440,  12,   3,   7,  11],\n",
       "       [ 11,   1,   1,   5,   8,  20, 418,   1,  12,   6],\n",
       "       [  2,  31,   7,   0,   1,   0,   2, 461,   1,   1],\n",
       "       [  9,   7,   4,  21,   5,  15,  30,   1, 358,  21],\n",
       "       [ 13,   5,   9,   5,  11,   8,   3,   2,  12, 411]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76d0794f-b879-4937-beec-8702c1232f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAJNCAYAAADTWGS6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOzdd1QUVx/G8e8uVQG7iAr2klhiLFGT2EvUJEqxd7FrxAooKmJXRFDBXrCiWEFQ0Yg1aqyvJpbEKBZU7B2ls+8fq6tEFIkLy8rvcw7nuLN3Zp5Z78zevVOuQqVSqRBCCCGE+MwodR1ACCGEECIjSCNHCCGEEJ8laeQIIYQQ4rMkjRwhhBBCfJakkSOEEEKIz5I0coQQQgjxWTLUdQAhhBBCZG/29vaYm5sDYG1tTfv27ZkyZQoGBgbUqVOHQYMGkZyczPjx47l48SLGxsZMnjyZ4sWLf3C5WbKRU7aGn64jpNvFE411HSGd9O/xSEqFka4jpJuKJF1HSBcFBrqOkG5JqnhdR0g3fazL+kal0q99D0CpqJCp68tRrGOmrSsmct1734uLi0OlUrF69WrNNFtbW/z8/LCxsaFv375cuHCBmzdvEh8fz/r16zlz5gzTp09nwYIFH1xvlmzkCCGEECJ7+Pvvv4mJiaFnz54kJibi5OREfHw8xYoVA6BOnTocOXKE+/fvU7duXQC+/vprzp07l+aypZEjhBBCZEMKRda4LNfU1JRevXrRtm1brl27Rp8+fciVK5fmfTMzM27cuEF0dLTmlBaAgYEBiYmJGBq+vykjjRwhhBBC6EzJkiUpXrw4CoWCkiVLYmFhwZMnTzTvv3jxgly5chEbG8uLFy8005OTkz/YwAG5u0oIIYTIlhQoM+3vQzZt2sT06dMBuHv3LjExMeTMmZPIyEhUKhWHDh2iRo0aVKtWjYMHDwJw5swZypUrl+Y2Sk+OEEIIIXSmTZs2uLm50bFjRxQKBVOnTkWpVOLs7ExSUhJ16tShSpUqVK5cmcOHD9OhQwdUKhVTp05Nc9mKrDgKudxdlRmy3H97mvTxjhS5uyrjyd1VIjVyd1XazIp3zbR1vbi+Ou1CGUB6coQQQohsKKtceJyRPv8tFEIIIUS2JD05QgghRDYkPTlCCCGEEHpKenKEEEKIbEihUOg6QoaTnhwhhBBCfJakJ0cIIYTIlj7/fo7PfwuFEEIIkS1JT44QQgiRDcndVUIIIYQQekrvGjld23/Frs1dCAnowKwpzcidy0TznlUhc37b4Uje3KYfXEZq5To4VCRsQ2c2+LfBusibId6XzGlJ6RJ5tboNKpUKt1G++C8LTvX9kJD92NkOw95uGB07jOLc2csAPH78jC5dxtCq5RDmz9+gKX/q1AVcXWdrNeO7ef1SzRscvA97u+GavyaN+1O5UlsePHhCZOQd2rZxoWXLIWzevOet7TvA7NlrMyzv/v0naNnSiWbN+jN48HSio1++U2br1n20auWEre1gOnRw4ezZS4D6M+7ceRQtWw5i3rxATfmTJ8/j4uKdgZlP0qrlEJo3G8iQwTNSzbx791FatRyCne1QunUdS2TkbQAiI2/TprUzLX8ezOZN4ZryIVv3M3tWQIZl1jchIQewtx2Ovd0IOnUYrdmv3hYWdhi7VsOwazUMx+4eXLsWBcCTx8/p2mUsti2HsWD+Rk35U6f+YqTrnAzLvH//CVq1dKJ5swEMeU9dvnjxGl27jsbebgitHYZz7txbx4vOo2jZ0on5b9XlUycv4OriI3nfktYx+bXw8GPUqN5J81pXx2RtUSiUmfanK3rVyKlVvSh9u1Wn+4AgWnUOZP/ha0we0wgAu5++YN2S1lhZmn9wGe8r17d7dWw7r2Nl4B90blsZgOaNS3P5yiMirj3W2jZERNzAscc4du48nOr7V6/cwstrFYuXuBMUPIv+A9oyeLAnANtCD1K/XjW2hsxmx45DREe/JCkpiVk+a3B27qa1jCnz3sSxh8d789rZNSQo2IegYB82bJxBgQJ5GDu2NwUK5GFtQBg9HG3ZvHkmixZuAuBFdAwBATvo1691huR99Ogpbm5z8PNzY9euhdjYWDFz5ooUZa5cuYmX13KWLp3A1q2+DBjQHicn9UBvoaH7qV+/OiEhfuzYcVDzGfv4rMLFxTHDMo9288PXbyQ7d83HxqYQ3jNXpSgTGxuHq8ss/OaOInjrbBo1rsmUyUsBCAgIw7GnLZu3eLNwofoLOPr159y/TYZk1jdXr9xipma/8qbfgNYMHuyVosyDB0+YMH4xCxaNIThkFk2a1mLKJPVnHBp6kHr1qhEc4vOvfS8gw/Y9db3wxdfPjZ27FmBjY4X3zJUpysTExNG7lwe9ezsQFDyHgQPb4eLs/SrzAerVr0FIiC87dvyWoi47u/TI9nlfS+uY/Nq1a1F4zVjB28M96uKYLNJHrxo5lb605MjxG9y59wKAX/dG0KhuSQoXMqdp/VL0GRLywfktC5i9t1xiYjLGxgbkyGFEQkIypiaG9OpSjblLjmt1G9YGhGHv0Jjmzb9P9X1jYyMmTRqIpWU+ACpVKs2DB0+Ij0/A2NiImNg4EhOTSEpMQqlUErhuFw0bfaMpr23qvI3em/dtS5cGkT9/btp3aKbZltjYOOLi4lEo1VVt3rz1ODrakiOHyYcW9Z8dOnSaypXLUqJEEQA6dmxBaOiBFAcmY2MjJk92euszLpPyM45Rf8aJickolUrWrQujUaNaGfYZHz50hsqVy2gyd+jYnNDQgykyJyUlo1KpeP5cXfdfvojB2MRIsz2xMerPWan5nAMz9HPWN6/3q4KW6l7Zt//PXytQIA+/HVpG4cIFSExMIirqPnnyWGjmj9Xse8lv7Xs1NMvUtsP/qssdUqnLhw+fxsbGivr1awDQqHEtZs92fZM51bpcM0Pqsr7lfS2tYzKoG2cjXWczclTKHzq6OCZrkwJlpv3pil41cv48f5fa31hTxEp94GndqgLGxgYkJibzi+sOLl/9cI/LvQcv3lvOe97vrFnkQPNGZVgZeIYBPWuwZuOfvHiZkMqS/jv3cX2xtW3w3veLWlvSoIH6AKBSqfCcvpyGDb/B2NiIlq3qc/nSDdq3c6VHj1bExcWzbdtBunVrqdWMKfP2+WDe1x4/fsaK5SG4je6pmdal64/s2H6IHt09cHHpRkTETS5diqR58+8yLO+dO/exsiqgeW1lVYDo6Je8eBGjmWZtXYgGDb4B1J/xtGnLaNSoJsbGRrRq1ZDLlyNp23YEjo62xMbGsW3bAbp3b5VhmW/feZBmZjOzHIyfMICOHUZRt44jAQE7cHbuDkDXrj+xfcdvdO/ujotrdyIibnDpn0iat0i7YZpdFLW2pH6D6sDr/WoFjRrWwNg45WjgRkaGnDt7mYYN+rJxQzidu/wIQMtW9V7te6Po3qMlcXHxbN92iG7dfs6wzB9TL65dvUWBgnkZM9qX1g7D6ek4jsSkZABatWrApcuRtGs7gh6OtsTFvjpeZFBd1re8r6V1TAbw8FhAu/Y/UL5ciRTTdXFMFumjV3dXnTgdhd+S48yf+SPJySo2hfzF4ycxJCQmf/Kyd+2NYNfeCACKFc3F15WtmLPoGGOG18W6aC6O/+8WywPOfPJ6PtbLl7GMdvPl9p2HLFkyDoCcOU3x9RupKePuPo9Bgzpw4cIVFszfQI4cJoxw7oa1daFMy/nahvW/0qhRzRTrtrTMxzJ/D83rvn0nM3KUI/v3n2Tdup3kyWOBm1tPza9lbUhOVqU6/XUPx9tevoxl1KjZ3LnzgKVLxwPqz9jPb7SmzNixfgwa1JELFyKYPz8QU1MTnJ17YGNjpcXMqdfftzNfvHiN+fPWs32HH8WKFWbVqm0MdvIkeOssLC3z4e8/QVO2b5+JjHLrqf6c14apP+fRvbT6Oesr9X41lzt3HrB4iXuqZSpVLsNvh5bx22+n6d9/Kr/unk+uXGbM8XPVlBnnvoBfBrXjwoUrLJy/CdMcxoxw7qrVfe9j6kViYhIHD5xk5aopVKlSnj3hR+nXdwJ79y17VZfdNGXdx859qy6vJ4epCc7O3bHWUl3Wt7wfa+3aMAwNDGjdugm3bt5L8V5WPiZ/DLm7Kosxy2nE8VO3sOuyHoduG9i1V33B2pOnsVpdj9vwunjOOcR331hjZmbEgBHbqfdtcYpZ59bqet4nKuo+nTq6oTQwYOXKieTKZfZOmbNnL/Hs6Qu+r/M106f54zG+P127/Yyv77pMyfhvYWGHsXdo9N73d+08QqmSRSlTxgbP6SuYPduFOnW+ZuXKUK3mKFy4IPfvv+mpu3v3Iblzm5MzZ8qL0aOi7tGhgwsGBkpWrZpCrlzvXsv155//8OxZNHXqVGPatKWMHz+Qbt1a4eur3Yt5i3xE5kOHzlC12pcUK1YYgM6dW3DpUiRPHj9PsaydO49QspQ1ZcrYMH2aP7PnuFKnTlVWrvjwqdzsICrqPp07jsbAQMmKlRPe2a/u3X3Eod9Oa17XrVsVc7Mc3Ii8k6Lc2bOXefY0mu/rfI3ntBWMG9+Xrt1+xs83EG1S14tHmtep1YuClvkoVcqaKlXKA9C4SW2SkpK5ceNfmf+8xNNn0dSpU5Vp05YxfvwAunVria+v9m4A0Le8Hys4aC9nz13C3m4Y/fpNIjY2Hnu7Ydy7+yhFuax2TBZqetXIsSxoRsAiB8zN1F3Mv/SuybZfL2l1HQ3rlODe/RdcuPhAcyoM1F3cpiYZ3/H15MlzunUdS9OmtfHxGYGp6bvXVKhUKrxmrMTVtQcA8fEJGBoaoFAoiI2Jy/CM//b0aTSRkXeoWrV8qu/HxMTh77+VQU7tAfWvOQMDJUqFUut569Spyh9/XNTcFRMYGEbjxrVSlHny5Dldurjxww/fMWuW6/s/Y6/luLqqT7+pP2NDlEolsbHazfx9na//lXkXjRrXTFGmYoVSnDhxjgcPngDquzysrS3Jm+/NnYAxMXH4LwvCyakD8OZzVigVxGg5s7558uQ53buOo0nT2nj7DE/1/zwuPp4Rw324fl1919qxo2dJSkqiVGlrTRmVSsXMGatwcVWfKny97ykzYN/7PpW63OhfdblevercunVPc4fSiRPnUCgUKXoOVCoVM7yW4+rq+FZmQxRKpVbrhb7l/VgbNnoRGupLUPAsFi1yx9TUmKDgWVgWenPNTVY7Jos39Op01dXrT1i08hSbVrRDoVRw6kwUE2Yc+OA8Q/qpd7I5i46luXxjIyW/9P6GXoPVv3oPHY2kU5uvCFnbkT/O3eGfiIefvhGpOHf2Mu7u8wgKnkVg4E5u335AePhRwsOPasr4L59A3rzqL7RNm8KpVasyRa0tAeg/oC2Ojh4YGxsxccKADMn4bt75BAWrb+uMjLxNwYJ5MTJKvTotWrSZjh2bY26eEwDHnq1wsB+BmXkOvL2HazVb/vx5mDZtCIMHTyMhIZFixazw9BzO2bOXGDvWj61bfVm3bge3bz9g9+7f2b37d828K1ZMfusz/pVatb7SHHwHDGhPjx5j1J/xxEFazzx1mhNDBs8gISERm2JWeHoO4ezZy7iPnUvw1tnU/vYrevWyp1vXsRgZGZI7tznz5o9OsZxFCzfRsVMLzefcs6ct9nbDMDfPibf3CK1m1jeBgbte7VfHCA9/cyxYuGg0/ftNZdGiMdjYWDFp8kCGDvYChYJcFmbMW+CW4uLtzZv2ULNWpbf2vTb0dByPsbEREyb012pmdb0YwpDB09+qF8M4e/bSq3oxh4IF8zJ33mgmTlhITEwsRsZG+Pm5YWJirFnOpk27qVWr8lt1uR2OPcaqM0/8Jdvm/ZC3j8kfQ9fH5P8qO5yuUqjevvQ9AyQnJ6d6PcSHlK3hl0FpMs7FE411HSGdMvS/PUMoFUZpF8piVCTpOkK6KDDQdYR0S1LF6zpCuuljXdY3KpV+7XsASkWFTF1f/nKDM21dD//xzbR1vS1DenJu3LjBtGnTOHfuHIaGhiQnJ1OuXDnc3NwoWbJkRqxSCCGEEOmQHXpyMqSRM2bMGEaMGEGVKlU0086cOYObmxuBgdq9OE8IIYQQIjUZ0siJj49P0cAB+PrrrzNiVUIIIYT4DxQodB0hw2VII6d8+fK4ublRt25dLCwsePHiBQcOHKB8+dTvvklLk/ql8JrQlKoNFqWYPnp4HUrY5KHvsG0AmJoYMtW9ERXKF0ShVODle4TwA1c05UcO+Z7jp26x79A1AIwMlaxd0pqdey6zbI361tEyJfMyaUwjzHIYoQK8/I5w6GgkAMMG1OaHhqUB+PPCXTym7Sc2LvE/bVNa/rl4ncmTlxAd/RKlUsmECQOoWKl0hqxLW3bvPspcv/UolQpy5TJn0uSBFCuWuc+0SC+VSoWb22zKli1Or14Ouo7z0cLDjzLSdQ6n/ie3p2qLSqVijNtcypQtRs9etgA8e/aCbl3GMnnKL1SqXEbHCd9vzZptBK4LQ6FQvLqAehD58+fRdawP0rfMwcH7UjyK4fnzl9y9+5B9+5dSoEAe3QUTH5QhJ+TGjx9Po0aN+PPPP9m1axdnzpyhYcOGjB8/Pt3LKm6Tm1FDv+ffpw5bNCmDbYsvUkwb3K8mL14m0LxtAD0GBjN+VH2sLN88C+O7mjYcPn5D83rMiLrvPPtm/KgGbA65QKvOgbhNDMd3enMMDBT80LA039cuRqtO62jRLoAcpoZ075iyt0pbYmLi6NV7Ar1627MlyIcBA9vi4vJxV/nrSmxsHCNd5+Dr50pQsA8NG33DlClLdR3rgyIibtC9+1jCwg7pOkq6XLsWxQzPlGPoiE8TEXGTnj3Gs3PnEc20AwdO0b7tSK5cjdJhsrSdO3cZf/9g1gXOIHTbXIqXKMKcOVl7YFZ9zKwep28WQcGz2LDR69U4fX30uoGTHQbozJCeHIVCQdOmTWnatOknLcfUxBDvST8wddYhfCb/oJleukRe+nSrxtylx6lbu5hmetMGpRk+dhcAt+9Gc/joDVo0LcvygDOUKZWPG7eeEh+vvuLe9sfyWJibsP9Vr85rSqWSXBbqh1eZ5TQmLk5d/td9Eew9eJXEpGTMzYzInzen1h9C+Nrhw2coZlOI+vXVj6H/95OEs6LXYytFP1ePOvzyZQwmxsZpzKVbAQHbcXBoTJEiBdIunEXExKgH6hw1qifOzhk7MnN2si4gDHuHhhQu/KYuBKzewbTpTjiPyNo/MCpVKsOuXQsxMjIkLi6eu3cfZvnjhT5mftu/x+kTWVeWfk7OpDENCdxyjouXHmim5cxhhNfEpoycEE7lLy1TlC9cyJzbd6M1r+/ci9aMNt6kfil271efuipXOj/dO1Shc98tjB/ZIMUyJnjuZ9VCexw7fU2+fDkYNnoXSUnqX8yJScl0afcVwwbU5u69aHbvi8iIzebatSgKFMjLmDFzufj3NSxymWX5EW3NzHLgMb4fHTu6kSePBcnJyQSsnarrWB80bpz6uSZHj/6h4yQfz2PcfNq3b0a58sV1HeWzMnZcHwCO/n5WM23x0tSHfciKjIwMCQ8/ytgxfhgbGzF4cGddR0qTPmaG1+P0bWXzFm9dR/lk2eHuqiy7hZ3aVCYpMZlNIX+lmD7VvTGr1//JpYhH78yjUL57EVXyqwZKgzrF2X/oGuZmxsyc2BRXj93ExKa8nsbY2IA505ozanw4dX9aTuc+m5k0uiFWhd488n/Nhj+p3nAxu/dfwc/zR21s6jsSExM5ePAU7dr9wKbNM+nS5Uf695ucYsTkrOafi9dZMH8j27b7cvC3ZfTr14Yhg2fIKRUtWhuwAwNDA1q3aaLrKCILatKkNkePBTDIqSO9e3m8dyyprEQfM6c2Tp/IurJsI8eh5ZdUrliIkIAOLJ3TClMTQ8KDutKiSRkcO31NSEAHhvSvTY2qRVgyRz3i6+07z7EskFOzjEIFzbhzLxrLAmbExSXx9Fkcdb8thoWFCT6TmxES0IFG9UrSo9PXDOlXi3Kl82Nqaqi5MPnMubtcuvKQrysV4ouyBahQ/k1X9obg81T4omCGbLtlwXyULGVNlSrlAGjcuFaq47tkJYcOnaZq1S80Fxp36tycS5du8OTJ8zTmFB8rKGgf585exs52KP36qsfQsbMdyt277zb4RfZx/XoUp05e0Lxu3boJUVH3efo0+gNz6ZY+Zn4trXH69Ilck6NDbbpv0Py7aGELtq/vRBP71SnKOPz8Bc0bl9HcXRV+4Crt7SvhMX0/VpZm1P2uOPOXnaBJ/ZLsPXgVgLDwy4SFX9Ysw9OjCf9EPGTZmtNYmBtjYW5C1a+sOP3nHYoVzUXpEvm48Pd9qlYpTK/OVWnXcxOxcYnY//QFR0/ezJBtr1uvGjNmrOD8uQgqVirNiRPnUSjI0r8cKlQsTUBAGA8ePKFAgTzsCT+uHlspb660ZxYfZeMmL82/b968S6uWQwjeOlt3gUSWcP/+Y0YMn0lw8Bzy5stFaOgBypYtlqX3PX3MDK/H6btN1apfpF1YZAlZtpHzX/guOsYEtwbsWN8JpYESzzmHibz1jMb1SzFu2r40538eHc9A5+2MHVEPExP14JzuU/cReesZkbeeUdw6D0Gr25OYlMzlK48YPXFPhmxHwYJ58Zs7iokTF/EyJhZjIyN8/UamGN8lq6lduzI9e9nRvZv7q7GVLJg7b5SuYwnx2atRoyL9+7elW7fRGBgYYGmZj3nzRqc9ow7pY2ZIe5w+/ZNlT+ZoTYaPXfVfyNhVmSHL/benSR/H+5GxqzKejF0lUiNjV6XNqoJbpq3rzoVpmbaut30uzVEhhBBCpIPcXSWEEEIIoaekkSOEEEKIz5KcrhJCCCGyITldJYQQQgihp6QnRwghhMiGFNmgn+Pz30IhhBBCZEvSkyOEEEJkQ3JNjhBCCCGEnpKeHCGEECIbUigUuo6Q4aQnRwghhBCfJenJEUIIIbIhuSZHCCGEEEJPSU+OEEIIkQ3Jc3KEEEIIIfSU9OQIIYQQ2ZBckyOEEEIIoaeyZE/OpZPNdB0h3awqLNd1hHS5ca6driOkm0KRJavrByUlx+s6QroYKnPoOkK6GSiMdR0h3WISH+g6QrqYGubXdYR0U+rh8SKzSU+OEEIIIYSekkaOEEIIIT5L0p8nhBBCZENyC7kQQgghhJ6SnhwhhBAiO5ILj4UQQggh9JP05AghhBDZkNxCLoQQQgihp6QnRwghhMiGFAqFriNkOOnJEUIIIcRnSXpyhBBCiGxInpMjhBBCCKGnpCdHCCGEyIbk7iohhBBCCD0lPTlCCCFEdiR3V2Vt+/efoGVLJ5o168/gwdOJjn75TpmtW/fRqpUTtraD6dDBhbNnLwHw+PEzOnceRcuWg5g3L1BT/uTJ87i4eGs1Z4vGFdgbNJjwLU5sXt6b4jb5AOjRoTa/bhrEwdBhzPVsh7GRQarz/9S0Irs2DmL/1iGsWdCdvLlzAlD1Kxv2Bg1mb9BgGtcrryk/tF9DOrWuobX8awN2YvuzM3YtnXH6xYuHD59+dJnIyDu0bzsau5bObNm8T1M+NOQ3fGev11rGt+3ff4JWLZ1o3mwAQ95TLy5evEbXrqOxtxtCa4fhnDt3GVDXiy6dR9GypRPz36oXp05ewNXFJ0PyAoSGHMTezgUHexc6dxzLuXMR75SJinrAwP7Tae3gil2rERw6dAaA+PhEBvafjr2dC+M9FmvKR0beoXfPSRmWWd/oy/HibZf+uUGvHtNp39qDTu0mcOH8tfeWne8XxLTJqzWvnzyJpme3abSxG8viBSGa6adP/cOYUYtTW8Qn+5h977Xw8KNUr9Ze81pX+574vOltI+fRo6e4uc3Bz8+NXbsWYmNjxcyZK1KUuXLlJl5ey1m6dAJbt/oyYEB7nJymAhAaup/69asTEuLHjh0HiY5+SVJSEj4+q3BxcdRaTlMTQ+Z5tqfnkACaOPixa99fTBndkh+bVKRn529p12sZ9VvNxtTEiL7d67wzf5WKRZk6thW9h6yhge0cIq49YNTQHwAY1Ksezh5BtO/jj+ugJgAULZybet+WYe3mk1rJf/78FVb4b2PNuokEh86kWHEr5vpu+OgygWt/pXuPn9mweRqLFwUB8OJFDOsCdtGnn51WMr7t0aOnjHbzxdfPjZ27FmBjY4X3zJUpysTExNG7lwe9ezsQFDyHgQPb4eKs/qIKDT1Avfo1CAnxZceO31LUC2eXHlrPC3D1ahQzvdawePFotgR50a+/A0MGz3yn3C8DPalXvxqbt8xg2vRBuIyYQ3x8AocOnaGQVT6Cgr2IirrPpX8iAfCasQpn164Zklnf6Mvx4m0xMXEM6ONNj54tWL95An36t2T0yEXvlLt75xHOQ+exasXOFNN3bPudOnW/YmPQJHaGHSM6OoakpGR8Z29i6Ih2Ws/7Mfvea9euRTHD0x+VSqWZpot9L9tTZuKfjuhtI+fQodNUrlyWEiWKANCxYwtCQw+k2GmMjY2YPNkJS0t1z0mlSmV48OAJ8fEJGBsbERMTR2JiEomJySiVStatC6NRo1qa8tqgNFCCAnKZmwBgltOE2LhE2tpWZeGK33jyNAaVSsXICcFsCjn9zvytW1Zl7eaT3Ih6AsDMeeHMW3YAgPj4JHLkMCJnDmPiE5IA8HD5kUneYVrLX7FiKbbvnI2FRU7i4uK5d/cxufOYf3QZI2MjYmPjiItLQPnqIrf58zbR3fFncuQw0VrO1w7/q150SKVeHD58GhsbK+rXV/d2NWpci9mzXQF1nYlNtV7U1Gq9eJuxsSETJ/WnoGVeACpWKv2qniZqyvz11zWePY2mQ0d1A/fLCiVZvWYiCoUCY2NDYmPiUalUxMXGY2RkyP59p7C0zMcXX5TIkMz6Rl+OF2/7/ch5rG0sqVuvCgANGlZlhvfAd8oFbTlI1epl6dq9WYrpxsaGxMbGk5iYRFJSMgZKJRsD91K/YVUKFsyj9bwfs++BuvHm6uLDqFG9/pU38/c98fnT20bOnTv3sbIqoHltZVWA6OiXvHgRo5lmbV2IBg2+AUClUjFt2jIaNaqJsbERrVo15PLlSNq2HYGjoy2xsXFs23aA7t1baTXny5fxjJwQTOjaAZzZ70bPTrWZ7LOT0iUKUCC/OWsXObI3aDDOvzTm2fOYd+YvXaIAhgZKVsztyp4tg5nmbsuLF/EAzFq4F5dBTZg/oz0TvHZQ99vSRL+I4/TZm1rdBiMjQ/aEn6Bxg184dfIv7O0bfHSZLl2aE7bjCL16TGKES2ciIm5x+dJNmjWvrdWMr92+8yDNenHt6i0KFMzLmNG+tHYYTk/HcSQmJQPQqlUDLl2OpF3bEfRwtCUuNp5t2w7STcv14m1Fi1pSv0E1QF1PZ3iupGHDGhgbv7lk7vq1KIoULYjn9JV0aD+azp3cuX//MUZGhnz33VcYGRnS2sGVb2pWpEjRgixauIXBQzpkWGZ9oy/Hi7ddv3aHAgVyM97dn07tJtC/90ySkpLeKdd/oB2du/6g/kH1lp9+/o6Iy7fo0mESXbv/QGxcPDt2HKVz16YZkvdj9j0Aj3HzaN++GeXKl0gxXRf7nvj86e2Fx8nJqlSnK5Xvtttevoxl1KjZ3LnzgKVLxwOQM6cpfn6jNWXGjvVj0KCOXLgQwfz5gZiamuDs3AMbG6tPyvlF2UIMH9iYei1ncf3GI3p1+Y5lsztjaGhA/W/L0H3QauLiE/Gd2pZRQ5oxbvq2FPMbGir5oeGXtOm5lAcPXzDOuTkzJ9rj6LSGfyLuYdd1saZc0Mq+ODqtpqNDDVo0rsDte89wnxqq6eX5FI2bfEPjJt+wacMe+vWZxo5ds9/5rFMrU9AyL0uWjdGUGdB3Oq4ju3Jg//8IXLebPHnMGeXW/Z3eof8qOTk51elvZ01MTOLggZOsXDWFKlXKsyf8KP36TmDvvmWv6oWbpqz72Llv1Yv15DA1wdm5O9afWC9S8/JlLGNGz+fO7YcsWjI6xXuJiUmc/t9FHB1bMnJUd/788zL9+04lOGQmlpb5mDi5v6bswgWbsW/dkCePn+M+ZgEAAwa24csKJbWeWV/oy/HibYmJSRz67U+WLHel8lel2bf3fwzqP4uw8JkYGxulOX+OnCZ4zxmkeT1h3HL6D7Tj77+us3hhKKamxgwd3pai1gW1kvdj9r21ATswMDSgdZum3Lx5N0U5Xe572ZZceJx1FS5ckPv3H2te3737kNy5zcmZ0zRFuaioe3To4IKBgZJVq6aQK9e7X6Z//vkPz55FU6dONaZNW8r48QPp1q0Vvr4Bn5yzYZ1ynPjfda7feATA8rW/80XZQiQkJLFjzwWiX8SRkJDE5tDT1Pi62Dvz3733nH2HLnH/QTQqlYrAoFPUqPJuuT5dvyc47E9exibQv0cdug9aTdSdJ7RuWfWT8kdev8P/Tv2teW3fuiFRUfd59vRFusoA/LrrKCVLFaF0GWu8PFfjM3so39epwqqV2z8p49uKFC7I/fuPNK9TqxcFLfNRqpQ1VaqoL9Zu3KQ2SUnJ3LhxJ8Wyzv55iafPoqlTpyrTpi1j/PgBdOvWEl/ftVrL+1pU1AM6d3LHQKlk+UoPcuUyS/F+Qcu8WOTKSaPG6p6Gr74qg7VNIS7+ff2d5Rw5/Cdt2jRi7twNdO/xM2PcezF16nKtZ9Yn+nK8eFtByzyUKGlF5a9KA9CwUTWSk5O5eeN+upd17uwVnj97yXffV8LLcx1j3LvSqUtT5s8N0lrej9n3goL2cO7sJexsh9Cv70RiY+Oxsx3C3bsPUywrM/c98XnT20ZOnTpV+eOPi1y7FgVAYGAYjRvXSlHmyZPndOnixg8/fMesWa6Ymr57DYhKpcLLazmurj0BiI9PwNDQEKVSSWxs3Cfn/PPCLb79piQF8qsPli0aVyDy1mNWrT9Gy2aVMDVRd6Y1b1yBM6mcZgr99SxN6pfX3FH1Y5NKnDl3K0UZywIWtGhcgRXrjqJUKFAo1NuVnKwiZ460f/F9yP37j3EZ4cvjx88A2BZ6iDJlbciT1yJdZWJi4ljuH8rAQW0A9a9UAwMlSqWC2Nj4T8r4tu9TqReN/lUv6tWrzq1b9zR3VJ04cQ6FQoG1dSFNGZVKxQyv5bi6qi8qfV0vFEolMVqoF2978iSaHt08aNq0JjN9hmJqavxOmapVy2NibMy+feoLyq9cucWNG3coV754inIzvVYxwrkzSqXyVWYDlAoFsTHazaxv9OV4kTLzV0Tdeqi5o+rUyYugUKS750WlUjHLewPDXNR3MiXEJ77KrCA2JnP3vY2bvAndNpfgrXNYtHgcpqbGBG+dQ6FC+VPkzax9L9tTKDLvT0f09nRV/vx5mDZtCIMHTyMhIZFixazw9BzO2bOXGDvWj61bfVm3bge3bz9g9+7f2b37d828K1ZMJm/eXABs2vQrtWp9pfmCGzCgPT16jMHY2IiJEweluu70OHzsCvP9D7JlRR8SEpJ48vQlPQat4tKV++TJnZNfNw1CqVRy9kIU42eof1V1a1+TKhWtGTFuC7v3/02RQrkJWtUHpVLBzagnDBu7OcU63J1bMH3OryQlJRP9Io6wPRfYv3UIDx6+oNfQNZ+Uv3qNL+nTzw7HbhMxMDTAsmBefOc6c+5cBB7ui9kc5PneMm9bsiiYDh1/wNxc3Vjr4fgzbRxGYW6Wgxnegz8p49vy58/D1GlDGDJ4OgkJidgUs8LTcxhnz17Cfaz64FqwYF7mzhvNxAkLiYmJxcjYCD8/N0xM3jQuNm3aTa1ald+qF+1w7DEWY2MjJkz8RWt5AdYH/srt2w8IDz9OePhxzfQFC90Y0H8aCxe5YWmZj8VLxzB1sj+zfdYBMHnyAAoVenNB5u9H/iRHDlOqfF0OgB6OLTW3lA8b3kmrmfWNvhwv3lagYG5m+TkxddJqYmLiMDY2xGf2IJ4+jWZQ/1nMXTgMy1cXq39I0OaDfFPzC4oWVV8v06dfS/r2moGxsSHu43toLe/H7HsfIzP3PfH5U6j+fel7lvCPrgOkm1UF/TodcOOc9m8hzWiGypy6jpBuScmxuo6QLobKHLqOkC3EJD7QdYR0MTXMn3ahLEaBPl5vUi5z11ZnYaat659D/dMulAH09nSVEEIIIcSH6O3pKiGEEEL8dyq5u0oIIYQQQj9lSE9O165dSUhISDFNpVKhUCgIDAx8z1wZS6VS4eY2m7Jli9Orl0OGr6954wr4TWtL2ZoTAPX4U4P7NsTE2ICbUU9wGrWRx09fEhrQnxxv3QFVukRBAjadYOzUUAA8XFpw5PhVjp66ytnfxnD56pvbRz2mb+fw8St8X7MU45xbYGhoQGxcAmOnhmoeCDhycFNsW3zFy5h4Tp6OxMNzO3FvPUn3U6lUKsaOXkCZsjY49mxJUlIyUyb5c/LkXwDUrfc1zi5dUGTRXwxr1mwjcF0YCoUCGxsrJk0eRP78eXQd6x0qlYoxo+dTtqwNjj1TPhxtiNNMClrmZax7r/fMLdIrs48X/0VgQDgb1u97VXcLMm6CI0bGhkxwX87Vq7dRJatoafsdjr1/0nXUVIVs3ceyZUEoFApMc5gwZkwfKlcuq+tY2UvWPCxrVYY0cpydnRk7dizz5s3DwCD1QSczU0TEDSZMWMgff/xN2bLF057hE5Usnh8Plx9RKtU16PX4Uz93XMCNqCdMGPkTo4b+wMgJwbTs/ObCrx8afsnY4c3w9P1VM61O7TJMn7Obb78pydGT1+jQxz/FuoyMDFjk3ZEOff0599dtmtb/Ar/p7ajzkw8d7KvTtMEXNG83j2fPYxnWvxGjhjRlgpd2hn2IiLjFlEn+/PnHJcqUtQHUA01eu3aboK1eJCcn06XTOH7ddSzDnnD8Kc6du4y/fzBbt87BwsIMT09/5swJYGIWu4MjIuImkyct488/LlH21ef82rKlWzl16i+at/hOR+k+P5l9vPgvLpy/xsoVO9mwZSIWFjnx8Qpknt8WjI2NsCyUl5mzfyHmZRwOtmOoVqM8Vb4uo+vIKajHCVvB5i2zsLTMx4EDJxnsNI19+/3TnlmIdMiQRk6VKlWwtbXl4sWLNG2aMY8QT4+AgO04ODSmSJECaRf+RDlMjZjn2R4Pz+0s8FI/lyK18afy5kl5p1Ce3DmY4WFH919W8Txa/SyI8mUsuX7jEXHxiXxTtTh5c+dg6+p+5MxpzJoNx1m5/hgJCUl83XAaiYnqp40Ws8nH4yfqkX+/qlCUnXsu8Oy5+g6fHeHnWLOgh9YaOYFrd2FnX5/Chd/ceZGUlExMTCzx8QmoklUkJCRiYvJpz+rJKJUqlWHXroUYGRkSFxfP3bsPUzwrJ6tYt3YX9vYNKVw4Zf09duwchw6doV37pjx79uI9c4v0yszjxX9VoWIJQnZMf1V3E7h39wlFrAvgNKQ1Sa+GKLl//wkJ8YmYm2e9O+aMjY2YNHnQe8cJE5lE+fl35WTYhce9e/fOqEWn27hx6lvXjh79I8PXNWO8Pas3HOOvi7c100qXKMCFi7dZMbcrNkXy8telO3hMT/mU30G96rPn4EX+OP/mQX/NGlVg554LACQmJvPr/r+ZtXAvlgUs2LyiD3cfPGfnngskJiZTIL85uzcNIl9eM/qNUD9H5X9/3qBv9+/xD/idx09jaNuqGpYFLdCWMe7qB6IdO3pOM83OvgG/7jpG4wYDSUxM4rvvv6JBw+paW6e2GRkZEh5+lLFj/DA2NmLw4M66jvSO16ehjh49q5l2794jpk9dweIlY9iwYbeuon2WMvN48SmMjAzZu+d/TBy3HCNjQwY42aFQKDA0NGD0yEWE/3qSRo2rU6JkYV1HfYe1dSHNDwqVSsX0acto+GqcMCG0SS481qIeHWqTlJTEui2nUkx/Pf6Uy/ggmrT24/6D58ycaK9538TYkC5tazJn8b4U8zWpV57wg+rhEmYt3Iv3/D0kJ6u4c+8Zqzcc48fGFTVlHzyMpmrD6fzccQGzJ7ehVPECbAo9Teius2xa3pvQgP5cvnqfBC2MY/UhC+ZtIm9eCw78tog9++fz9Gk0K5ZvS3tGHWrSpDZHjwUwyKkjvXt5vHcMnqwiISER5+FzGOnWQzNyucieGjWuxv7DfvQfaMfAvj6aujvVsx/7D/nx9Gk0ixZs1XHK93v5MpahQzyJjLzN5MnafZii+AjZ4InH0sjRovZ21fi6kjXhW5wIWNQDUxMjwrc4AXxw/KlGdctx/u8oIm++GVunUEEL4uITefJUPYJvr87fUrRwbs37CoWChMQkLMxNaNG4gmb62b+iuHDxNl+WK0Se3DkI2v4Hjex9+bnTAi5G3ONqZMoxYrQtfPdxHFo3xMjYEAuLnNja1eP4sfMZus7/6vr1KE6dvKB53bp1E6Ki7vP0abQOU6Xt/Lkr3Lp1jxmeK3Gwd2H9+t3sDDvCuLGZ92AvoVuR1+9y+tSbh6baOdTldtQDdu86wb176uNITjNTmv9Ym78vXH/fYnQqKuo+HTu4YmBgwMr3jBMmxKeSRo4Wtegwnwa2c2ji4EfnfiuIjUugiYMfS9cc+eD4U99+U4rfjkakWFbzRhXYtfcvzeua1UowsGc9QH39TkeHGmwN+5OkZBWzJrfhm6rqCyTLl7GkTKmC/O/PG1SpaI2/bxcMDZUYGCgZ3Kc+W7adydDP4MsKJdkZpn4kfkJCIvv2nqJKlax5x8T9+48ZPtyLx4/UY26Fhh6gbNlimkf4Z1VfVy3Hnn0L2BLkxZYgL9q3b0rzFt+lGIlcfN4ePHjKSJeFPH78HIAd236nTBlrfj9ynkXzt6JSqYiPT+DXXcf5ptaXOk77ridPntO1ixtNf/gWn1kuqY4TJjKBIhP/dEQeBpgJ0hp/qlTx/PxxPuXgnM0aVWDkhDcjBI+eHMKM8XYcCBmKoaEB/mt/5+Dv6gEmHZ1WM2nUzxgaKYmPT2KASyC37z7j9t1nfPtNSfYGDUGpVLBzzwUWrTyUods6clQ3pk5ZTssfh6NUKqn1bSV69m6V9ow6UKNGRfr3b0u3bqMxMDDA0jIf8+aN1nUsIdJUrXo5evf9md49PDEwUFLQMg+z/JywyGXGlIkraWPnjkKhHrm8c1fd3/zxb4HrwtTjte0+Svjuo5rpy1dMyvI/MoR+kbGrtETGrsp4MnZVxpOxqzKHjF2V8WTsqrSVbbQk09Z1aW+fTFvX26QnRwghhMiOssEt5HJNjhBCCCE+S9KTI4QQQmRHWXS4HW2SnhwhhBBCfJakJ0cIIYTIjj7/jhzpyRFCCCHE50l6coQQQojsSO6uEkIIIYTQT9KTI4QQQmRHn39HjvTkCCGEEOLzJD05QgghRDakkufkCCGEEELoJ+nJEUIIIbIjubtKCCGEEEI/SU+OEEIIkR19/h050pMjhBBCCN17+PAh9evXJyIiguvXr9OxY0c6deqEh4cHycnJAMydO5c2bdrQoUMH/vzzzzSXKY0cIYQQIjtSKDLvLw0JCQmMGzcOU1NTAKZNm8bQoUNZu3YtKpWKPXv2cP78eY4fP87GjRvx8fFhwoQJaS43S56uSlYl6jpCukWd76LrCOliVnyyriOk28vI8bqOkG4GSlNdR0gXFSpdR/gPknUdIN1MDPLoOsJnTx/rcjY4e/Renp6edOjQgcWLFwNw/vx5atasCUC9evU4fPgwJUuWpE6dOigUCooUKUJSUhKPHj0iX758712u9OQIIYQQQme2bNlCvnz5qFu3rmaaSqVC8aoHyMzMjOfPnxMdHY25ubmmzOvpH5Ile3KEEEIIkcGyyC3kmzdvRqFQ8Pvvv/PXX38xcuRIHj16pHn/xYsX5MqVC3Nzc168eJFiuoWFxQeXLT05QgghhNCZgIAA1qxZw+rVq/nyyy/x9PSkXr16HDt2DICDBw9So0YNqlWrxqFDh0hOTiYqKork5OQPnqoC6ckRQgghsqes0ZGTqpEjR+Lu7o6Pjw+lSpWiWbNmGBgYUKNGDdq3b09ycjLjxo1LczkKlUqV5a7OSlZd0HWE/yDLfYwfJBcei8+H/l14nAUPux+kUBjoOkK2oKB8pq6vjP2qTFvX5aBumbaut0lPjhBCCJEdyQCdQgghhBD6SXpyhBBCiOxIenKEEEIIIfST9OQIIYQQ2VE26ObIBpsohBBCiOxIenKEEEKI7EiuyRFCCCGE0E/SkyOEEEJkR59/R4705AghhBDi8yQ9OUIIIUQ2pMoio5BnJL3vyVGpVLiN8sV/WXCq7wes2cHPPw+mZcvB/DJwKg8fPgEgMvI2bdu40LLlYDZvDteUDwnZz+zZAZmQ2e+9mT2nL6dRw77Y2w3H3m44w4bNBODx4+d06TKWVi2HMn/+Bk35U6f+wtV1jtbyDejRjD/2eXM0bBor/ZzIm9uMXBY5WLtwKCd3z+B/e7wYMaDlB5dhXTgfEcfnkT+vhWZar86N+d8eL/YHTaC4TUHN9KAVrpQvU0Rr+ffvP0Grlk40bzaAIYOnEx398r1lw8OPUr1ae83rx4+f0aXzKFq2dGL+vEDN9FMnL+Dq4qO1jPqe+WPyXrx4ja5dR2NvN4TWDsM5d+6yzvKqM5+kVcshNG82kCGDZ6SaefXqbTRvNhA726EMH+7NkyfPAfXxok1rZ1r+PJjNm946Xmzdz+xZmXG8eP8x7n1ldHGM07d6rK+ZxcfT60ZORMQNHHuMY+fOw6m+f/5cBP7+waxbN43QUF+KFy+C75x1AKwNCKOHYys2b/Zm0cJNALyIjiEgIIx+/dpkYOabOPbweG9mgNOnL+LtPZygYB+Cgn2YNcsZgG2hB6lfrxpbQ2axY8dhoqNfkpSUxCyfNTg7d9VKvnrfVmDEgJb82HEKtVu4sXPfaeZ59sHDuR23bj+iRlNX6vw8lj5dmlKrWtlUl9GpdV3CN42niFW+FNOdB7Sidgs35vnvpH+3HwCw/7Emf1+6xcXLUVrJ/+jRU0a7+eLr58bOXQuwsbHCe+bKVMteuxbFDE//FIMlhoYeoF79GoSE+LJjx2+az9jHZxXOLj20klHfM39M3piYOHr38qB3bweCgucwcGA7XJy9dZL3TWY/fP1GsnPXfGxsCuE9M+XghEePnmXpkiBWrJxI8NbZ1K9XjXHj5gMQEBCGY09bNm/xZuHCjQBER8cQELCDfv0z8njx4WPch8pk9jFO3+qxvmYW6aPXjZy1AWHYOzSmefPvU32/YqXS7Nw1HwsLM+Li4rl79yF58qh7FoyNjYiNjSMuLh6FUv0xzJu3HkfHVuTIYZLBmRu9N3N8fAJ//XUV/+VbsbMdxmCnGURF3X+V2ZCY2DgSE5NISkxCqVQSuG4XDRt9g6VlvlSXl17VKpdk76Fz3LrzCICtYSf4sXE13KYEMGryGgCsLPNgbGLI0+fv/uIpXCgvrX6ogV0Pz3feS0hMwsTYiJw5TYhPSCSHqTFD+/7MlNmbtZId4PCh01SuXJYSJdQ9Qx06tiA09MA7oz7HxMTh6uLDqFG9Ukw3NjYiNkb9GScmJqNUKlm3LoxGjWpq7TPW98wfk/fw4dPY2FhRv34NABo1rsXs2a46yavOfIbKlcu8lbk5oaEHU2Q+fz6Cb7/7CiurAgA0/eFb9u09QXx8giZzXFw8Ss3xIhBHR9tMOF68/xj3oTKZfYzTt3qsr5m1SqHIvD8d0etGjvu4vtjaNvhgGSMjQ8LDj9Ggfm9OnryAvUMjALp0/Ykd2w/Ro/s4XFy6ExFxg0uXIj94MNFO5j4fzHzv3iNq1a7M8GFdCAr2ocrX5Rj0y3RUKhUtW9Xn8qUbtG83kh49WhIXF8+2bb/RrdvPWst34kwEDb6rSLGi6gN9t3b1MTExIl8ec5KSkvGf/Qunds/gt9//4p+Id3tfbt99TId+s/j70q133hvnGciu9e7Y/1iLef47cR1kx8JVvxL9IlZr+W/feaD5kgKwsipAdPRLXryISVHOY9w82rdvRrnyJVJMb9WqAZcuR9Ku7Qh6ONoSFxvPtm0H6da9ldYy6nvmj8l77eotChTMy5jRvrR2GE5Px3EkJiXrJO/HZv7qq7IcO3qWW7fuAbBlyx4SEhJ58uQ5Xbv+xPYdv9G9uzsurq+OF/9E0rxFRh8v0j7Gva9MZh/j9K0e62tmkT7Z4sLjJk1q0aRJLTZs+JU+vSey69f5WFrmY5n/eE2Zvn0nMXKUI/v3n2Tdup3kyWOBm1tPTc9PZrG2LsTixWM1r3v2tGXB/I3cunUPa+tC+Pq5at5zd5/PoEHtuXDhCgvmbyRHDhNGOHfF2rrQf17/4eN/M2X2ZgIXDydZpWLV+v08fPyc+PhEdZ6h83AavZR1i4YxemhrJvts+uhlB4cdJzjsOAAli1tSq3pZJvlsxMujG8VtCnLo6F/4Lt3xn7MDJCcnpzr99a9vgLUBOzAwNKB1m6bcvHk3RbmcOU3x83PTvHYfO5dBgzpy4UIE8+evJ4epCc7O3bG2sfqknPqc+WPyJiYmcfDASVaumkKVKuXZE36Ufn0nsHffsiz7GX/zTUV++aU9ToOmo1AoaN26MbnzWGBkZEjevLnw95+gKdu3z0RGufVUHy/WhqmPF6N7Zfrx4kMy+xinb/VYXzNr1ed/3bF+9+Sk5fr125w6dUHzunXrxkRF3efp0+gU5XbtPEKpkkUpU8YGz+nLmT3bhTp1vmblytDMjszFi9fYunV/imkqlQpDQ4MU086evcSzp9F8X+drpk9bjsf4fnTt9hO+voF8CnMzU347+hff/TSaOj+P0TRKqn1VisKF8gLw4mUcG7Ye4etKJf7zejzdu+I2OYCG31fC3MyUdr29adqgCqWK//cGGkCRwgW5f/+R5vXduw/JnducnDlNNdOCgvZw7uwl7GyH0K/vRGJj47GzHcLduw9TLOvsn5d4+iyaOnWqMm3aMsaPH0C3bi3x9V37SRn1PfPH5C1omY9SpaypUqU8AI2b1CYpKZkbN+5ket43mR9/MHN0dAzf1KzEliAfNm/x5odm3wG80wjYufMIJUtZU6aMDdOn+TN7jit16lRl5YoQrWbWpsw4xulbPdbXzCJ9PutGzv37jxkx3IfHj58BEBp6kLJli5E3by5NmZiYOPz9gxnk1AFQ/wI1MFCiVCiJjYnL9MwKhYKpU5ZpfjGsW7eT8uWLp+hSValUeM1YhatrD0B9HY+hoQEKLWQuXCgvv25wx8I8BwBug+3ZuPUIrX+uzeihDoD62qDWP9fmwOHz/2kdLRpX5fbdx/xx/homJkYkJCZptiuHqfEn5f++TlX++OMi166pT6UFBobRqHGtFGU2bvImdNtcgrfOYdHicZiaGhO8dQ6FCuXXlFGpVMzwWo6rqyPw+jM2RKFUEhOr3Xqhb5k/Jm+9etW5deue5o6qEyfOoVAoUvQyZu5n/PW/Mu+iUeOaKcrcu/eIbl3Hau6umT9/Az/9VBfFW9cTxMTE4b8sCKd/HS8USoXWM2tLZh3j9K0e62tmrVIqMu9PRz6701Xnzl7G3X0eQcGzqFGjAv36t6Fbt7EYGhhQ0DIfc+eNSlF+0aJNdOzYHHPznAA49rTFwX44ZuY58fYenomZ5xMU7EO5csUZM7Y3AwZMJTkpmUJW+Zn5rxybNoVTq1YlilpbAtB/QBscHcdjbGzIxAkDPinLpSu3mTk/hINbJ6FUKjhy4iLD3JdjYmKE39RenNw9A5VKReiuk8z13wmA+3D1nRqTPuLUlbGxIW6DHbDtNh2A8IN/0rdrU47tnM7x05c4f/HGJ+XPnz8PU6cNYcjg6SQkJGJTzApPz2GcPXsJ97HqA9XH2LRpN7VqVdZ8KQ8Y0A7HHmMxNjZiwsRfPimjvmf+mLwFC+Zl7rzRTJywkJiYWIyMjfDzc8PE5E0jNvM/YyeGDJ7xVuYhnD17+VXm2ZQqVZQ+fR1o19aV5ORkqlf/EvdxfVMsZ9HCTXTs1EJzvOjZ0xZ7u2GYm+fE23uEVjO/z9vHuI+RWcc4favH+ppZpI9C9e/LyDNIfHw8xsYf9ys9WXUh7UJZTqZ8jFpjVnyyriOk28vI8bqOILKk1K+ryMoy6bCrNQqFQdqFxCdTUD5T11e62/pMW1fEqvZpF8oAWj9dtXfvXho2bEjTpk3ZsePNRaS9e/fW9qqEEEIIId5L66erFi5cSHBwMMnJyQwZMoS4uDjs7e317peLEEII8VnLBndXab2RY2RkRO7cuQGYP38+3bt3p3Dhwiku3stswcH7Utz58Pz5S+7efci+/UspUCCPznJ9yO7dR5nrtx6lUkGuXOZMmjyQYsUy5jbE6WO74PBTLR49Ud91dunKbbr+4ovLL7Z0bl0XQ0MD1gUdYsos9UP7ShUvhO/UXhTIZ4GxsSErA/czZ8l2zfKmjenMwaMXOHz8b66fWsjFt56n4zpxNQd/v0C9byswdUxnjAwNiI2NZ4THSk7+EQGAh3M72rSszYuXcRw9dYmRk1YTF5eg9e0O2bqPZcuCUCgUmOYwYcyYPlSunPpTnLMKfcy8Zs02AteFoVAosLGxYtLkQeTPn0fXsT5o+nR/du08Qu7c5gCULFmUWbNddJzq/f65eJ3Jk5cQHf0SpVLJhAkDqFiptK5jfZC+1WV9yyvUtN7IKVq0KNOmTWPIkCGYm5szd+5cevXqxbNnz7S9qo9mZ9cQO7uGACQkJNK1yxj69HHIsg2c2Ng4RrrOISjYh+LFC7NiRShTpixl0aKxac/8H9SuXpZug3w5euqSZlqzhl/j8FNtvvtpDEnJyYSuduPvS7fYvO0oS3z6s3rjQVYE7iOXRQ4OhU7hzPlrHDiivtuqwfeVGD9zA3Vrfcmh43/Tssu0FOszMjJg9bzBtOo6nT/OX6NF46osmz2QKg1H0LVtfVo0rkqdlmN5+uwlowbbM965HW5TtDvWzpUrN/HyWsHmLbOwtMzHgQMnGew0jX37/bW6Hm3Sx8znzl3G3z+YrVvnYGFhhqenP3PmBDAxi1+Mefr0Rbx9nKlW7QtdR0lTTEwcvXpPYPLkX6hfvzp79hzDxWUWO8Lm6jrae+lbXda3vB9NBuhMv6lTp1K+fHlNz03hwoVZtWoVLVq00Paq/pOlS4PInz837Ts003WU90pKSkalUhH9atiEly9jMPnIi7bTy9jYkCoVSzC0788c2zmddQuHYlMkP62af8OGrYd5GRNHXFwCqzbsp4N9HQBWBO5nfbB6nJxnz2OIuHZH84TkL8tZcy3yLnFxCdSuUY68eczZs9mD33dMo0+XJgAkJCRRuuYv/HH+GgAli1ny6LG6F6la5ZKE/nqSp8/U27515wnsf0x5S6d2ttuISZMHaR69XqlSGR48eEJ8vPZ7jLRFHzNXqlSGXbsWpjq0SlYVH5/AXxeusNw/GNtWQ3Fymq4ZWiUrOnz4DMVsClG/fnUAGjWqyazZzjpO9WH6Vpf1La94Q+s9OYaGhjg4OKSYVqBAAcaMGaPtVaXb48fPWLF8K5u3eOs6ygeZmeXAY3w/OnZ0I08eC5KTkwlYOzVD1lW4UF72HzmPu2cgl67cZli/n9mw1Jn7D5+y/9A5Tblbdx5R9NWAm6s3HtBMb1q/CrWrl2OA62IAfm5anZBfTwLq53HsCP8f0323YFUwDzvXu3Pn3hNCfz1JYmISlgVy8/uOqeTPa0HXX3wBOH7mMk69fmThil959CSazq3rYmWZR+vbbW1dSHO7p0qlYvq0ZTRsVBNjYyOtr0tb9DEzvB5a5Shjx/hhbGzE4MGddR3pg+7dfUTt2pUZNrwrJUsWwX9ZML8MnMqWIB+dnnZ/n2vXoihQIC9jxszl4t/XsMhlhrNzN13H+iB9q8v6lvejSU/O52XD+l9p1KjmJw17kBn+uXidBfM3sm27Lwd/W0a/fm0YMnhGhly8ff3Gfex7zODSldsAzFq0jVLFLVM81vy1fz8CvXObevjP+YVOA2Zz594TQP2gv517TgMw3TeIqbM3k5ysIuruY5YF7KFV828089978JTSNX+hgf04Fnn3o0xJK9ZtOcSWHccICxzLvi3juXg5iviERK1v92svX8YydIgnkZG3mTx5UIatR5v0MXOTJrU5eiyAQU4d6d3L472P088KrG0KsXjJOEqVKopCoaBnLzsiI+9w6+Y9XUdLVWJiIgcPnqJdux/YtHkmXbr8SP9+k/Wil0Hf6rK+5RXZrJETFnZYM0BnVnbo0GmqVv1Cc6Fxp87NuXTpBk+ePNf6uip9UYyODnVSTFMoFETevJ+iB6WIVT5u3X7z+PPpY7swbngbfuo0hX2venwKF8pLbFwCj5++AGBAj2bYFMn/1nLV10TlsshBq2Y1NNPPnLvG2QuRVPqiGHlzm7Eh+DA1m42kgb0Hf1+6ScS1lOPFaEtU1H06dnDFwMCAlaumkCuXeYasR5v0LfP161GcOvn20CpNUh1aJSu5+Pc1tgbvSzFNpVJhaJQ1nxVjWTAfJUtZU6VKOQAaN66V6hAaWY2+1WV9y/sxVIrM+9OVbNPIefo0msjI21StmvUvJKxQsTQnTpznwYMnAOwJP461tWWK4Si0JTk5Ge8J3SluUxCAvl2bcu7vSLbtPkV7+zrkzGGCsbEhXdvU05yG8p7QnTq1vuD7n8fw54XrmmX93LQ623ef0rz+7pvyDOvXEoC8uc3o3r4hm7YdJSkpmYUz+/FtDfVB+cty1pQrXYQTpy9T7atSBC4ejqGhAQYGSlx+sWV98CGtb/eTJ8/p2sWNpj98i88sF0xNTbS+Dm3Tx8z37z9m+HAvHj96PbTKgXeGVslqFEoFU6Ys5eaNV0OrrA2jfPkSKYZWyUrq1qtG1K17nD+nvjvxxInzKBRk6R5rfavL+pZXvPHZDevwPpGRtylYMC9GRll/k2vXrkzPXnZ07+aOkZEhuXNbvDMchbZc+Ocmw8etZLO/CwZKJbfuPKL7ID9uRD2kYnkbfgudjLGRAdt+PUXApoNYF85H/+4/EHnzAdsCRmuWM89/Jz//UAOn0Us104a5L2futN6cCvfCyNCAhSt3sfe3swC06+2Dl0c3DA0NiI9PpMfgudy684hbdx5Rt/aXnNjliVKpIPTXk588MnlqAteFcfv2A8J3HyV891HN9OUrJmXZL2B9zFyjRkX6929Lt26jMTAwwNIyH/PmjU57Rh0qV644Y8f2YcCAKSQlJWNllR9vn8wZsuG/KFgwL35zRzFx4iJexsRibGSEr9/IFENoZDX6Vpf1La94I9OGdUgPGdYh48mwDuLzkXWv73mfLHjY/SAZ1iFzZPawDqX6pj3eoLZcWdwm09b1tmxzukoIIYQQ2UvWP3cjhBBCCO3Lgo9E0DbpyRFCCCHEZ0l6coQQQojsSB4GKIQQQgihn6QnRwghhMiOskE3RzbYRCGEEEJkR9KTI4QQQmRHcneVEEIIIYR+kp4cIYQQIjuSu6uEEEIIIfST9OQIIYQQ2ZBKrskRQgghhNBP0pMjhBBCZEfZoJsjG2yiEEIIIbIjaeQIIYQQ4rMkp6uEEEKI7Cgb3EKeJRs5CoWBriOkm0qVpOsI6RJ93U3XEdKtXNNDuo6Qbv/s/k7XEdIlIfmlriOkm6Eih64jpJtSkSUPve+VrErQdYRsIRvc7JTp9GtPE0IIIYR2ZINWlVyTI4QQQojPkvTkCCGEENlRNrgmR3pyhBBCCPFZkp4cIYQQIjv6/DtypCdHCCGEEJ8n6ckRQgghsiGVXJMjhBBCCKGfpCdHCCGEyI6kJ0cIIYQQQj9JT44QQgiRHckTj4UQQggh9JP05AghhBDZUTbo5sgGmyiEEEKI7EgaOUIIIYT4LMnpKiGEECI7ygYXHut1I2f//hP4eK8iPj6R8uWLM2XqYMzNc6Yoc/HiNSZPXkz08xcolQZMmDiQSpXK8PjxM5wGTeXpsxe0aP49A3/pAMCpkxdYv34nM7yGZ1hulUrFaDc/ypYtRs9edu8tFx5+jFEj53Dy1FoAdWYnT549jaZ5i+8ZOLCdOvOpC6xf/yszZgzVetaQkIMsXxYCCshhasLoMT2pVLl0ijJrVoexaNFmChTIA4CZWQ7WBEwiPj6BIU4zuXPnIV9VKcuEif0AiIy8w4Txi1nmP05rOZt+X5zB3aqhUql4+jyOMT6HiLz9nGMbO3H34UtNuaUbzhKyN+Kd+YPm2WJqYkBCYrJ6u/dEsHTjWap8UZDJw+oAMHPZCQ4cvwnAwE5fc//xSzaG/aO1bVCpVLi5+VK2bHF6pVIv9u8/iY/3auLjEyhfvgRTpg7C3DwnkZG3GT7Mm7i4eHr0aEXrNk3U27B1P1eu3GLosM5ay/hve8JPMGbUQo6eXPbOezvDjrJ4YRAAefNaMG58L4qXKMyTx88Z4jSLZ89e0Kx5LfoPdADgf6f+ZuP6vUybMTDD8qa174WE7Md/2VYUCjA1NWHMmN5UqlxGJ/uevlJ/xnMpW9bmnc84OHgfK1eEal4/f/6Su3cfsm//El6+jGXEcG9iX9fj1o0BCAk5oK7HQztJZpFuenu66tGjp4x288XXz42duxZgY2OF98yVKcrExMTRu5cHvXs7EBQ8h4ED2+Hi7A1AaOgB6tWvQUiILzt2/EZ09EuSkpLw8VmFs0uPDMsdEXEDxx7j2Lnz8AfLXbsWhdeMFahUKs20baEHqV+vGltDZrNjxyFN5lk+a3B27qb1rFev3GKm12oWLxlDUPBM+g1ozeDBXu+UO3P6IiNHdicoeCZBwTNZEzAJgEOHzlDIKj9BW2dyO+o+l/6JBGCG5ypcXLWX18TYgJkj6/PLhHBa9Q9mz++RuP/yLSWtc/M0Op5W/YM1f6k1cHKYGlKsiAUt+wVpyi3deBaAvu2/wn32IRxH7WRI92oAFC5oxnfVimi1gRMRcYMe3cexMyz1eqGu7374+o1k56752NgUwnvmKgACAsJw7GnL5i3eLFy4EYDo6BgCAnbQr38brWX8t+vXbuPttZZkVfI77z148JRJE5Yxf6ErW7Z60rjpN0ydvAKA7dsOU7f+12zZOp2dO35/VY+TmTNrPcOdO2ZY3rT2vatXbuHltYrFS9wJCp5F/wFtGTzYE8j8fU9fRUTcxLGHx3s/Yzu7hgQF+xAU7MOGjTMoUCAPY8f2pkCBPKwNCKOHoy2bN89k0cJNALx4XY/7tZbMGUGpyLw/XW2iztb8iQ4fOk3lymUpUaIIAB06tiA09ECKRsHhw6exsbGifv0aADRqXIvZs10BMDY2IjYmjsTEJBITk1EqlaxbF0ajRjWxtMyXYbnXBoRh79CY5s2/f2+ZmJg4RrrOZuQoxxTTjY2NiIlVZ05KTEKpVBK4bhcNG32TIZmNjY2YNKk/BS3zAlCpUmkePHhCfHxCinKnz1xk+7ZDONi70KfXZP65eF09v5ERsbFxqFQqYmPjMTIyZP++UxQqlI8vviihtZwGSgUKhQILM2MAzHIYERefSLWKliQnq1jt1YLQRfYM6vI1ylR2tq/KF+RlTCJLpjRj22J7RvevhYmxAQDxCUmYmhiS09SQhAT1l/mofjWZseS41vKDuqHi4NCI5i1SrxeHD52hcuUyb9X35oSGHkSlUmnqclxcPEqlepeeNy8QR0dbcuQw0WrO12Ji4nAbOR+XkV1Sfb9Agdzs/20BVoXzk5iYxO2oB+TOYwGA0Vv7XlKSet9bH7ibBg2raepaRkhr31PX94Gafent+p7Z+56+Un/GjT54fHtt6dIg8ufPTfsOzYBXx+RYdT1WaOrx+gytx/qaWXw8vW3k3L7zACurAprXVlYFiI5+yYsXMZpp167eokDBvIwZ7Utrh+H0dBxHYpL6i6pVqwZcuhxJu7Yj6OFoS1xsPNu2HaRb91YZmtt9XF9sbRt8sIyHxwLatf+B8uVKpJjeslV9Ll+6Qft2rvTo0Yq4uFeZu7XMkKxFrS2p36A6oO7O9Zy+kkYNa2BsbKQp8/JlLKVKFqVvPwe2BHnh0KYR/fpO5cWLGL77/iuMjAxxsHfhm5oVKVK0IAsXbmbwkA5azfkyNpFxcw6zYXZLDgV2oIttBWYsPYGBUsnhU7foNXoXnYZvp04Na7rZVnhnfrOcRhz94zZOE/fg8EsIRSzNcO6lbhjPW3OGwd2q4e3WgOmLj/Nd1SK8eJnAnxcfaHUbxo3ri61dw/e+/6H63rXrT2zf8Rvdu7vj4tqdiIgbXPon8r0NJm2Y6LGMtu0aU658sfeWMTIy5Py5KzRpOIhNG/bSqfMPAPzc8nsiLt+kU3t3uvb4kbi4eHZsO0KXbi0yLC+kve8VtbakQQP1/7u6vi+nYcNvMDY2yvR9T1+5j+uT5vEN1KfeVywPwW10T820Ll1/ZMf2Q/To7oGLSzciIm5y6VIkzZt/l4GJ9TOz1mSDnhy9vSYnOfndLnJA80sWIDExiYMHTrJy1RSqVCnPnvCj9Os7gb37lpEzpyl+fm6asu5j5zJoUEcuXIhg/vz15DA1wdm5O9Y2Vhm+LW9buzYMQwMDWrduwq2b91K8lzOnKb5+I99kdp/HoEEduHDhCgvmbyBHDhNGOHfD2rqQVjO9fBnLaLd53LnzkMVLxryTacmysZrXLVp8x8L5mzh3NoJatSsxafIAzXsLF2zGwaEhjx8/Z+yY+QAMGNiWChVKflK+ciXyMqhLVVr03kzk7ed0s6vA3HGNadU/WFMmPiGe5ZvO0c2+AiuCzqeYf+/vkez9PVLzesG6P5jn0YQpC45xOfIJnYZvB8DQQEGA908MGB9Om+blaPpdce4+fMHk+UeJT0i9PmrLh+q7pWU+/P0naKb17TORUW492b//JOvWhpEnjwVuo3uR51VPyqcKXLsbA0Ml9q0bcOvW/Q+WrVipFPt/W8Ch3/7glwFehP06m1y5zJjlO0xTZrz7EgYOas1fF66xaEEQpjmMGTaiI9bWllrJm17q+u7L7TsPWbJEfd2Yrva9z9WG9b/SqFHNFJ+XpWU+lvl7aF737TuZkaMc1fV43U51PXbrqbV6nF76mFnocU9OkcIFuX//keb13bsPyZ3bnJw5TTXTClrmo1Qpa6pUKQ9A4ya1SUpK5saNOymWdfbPSzx9Fk2dOlWZNm0Z48cPoFu3lvj6rs2cjXlLcNBezp67hL3dMPr1m0RsbDz2dsO4d/dRinJnz17i2dMXfF/na6ZP88djfH+6dvsZX991Ws0TFXWfzh3HYmCgZMVKD3LlMkvx/q1b91mzOizFNBVgaGTwznIOH/6DNm0bM89vPd17tGSsey+mTvH/5Ix1axTl1Pm7RN5+DsCakL8oVyIvtk3KUL7km9MfCgWaC4vf1qi2Dd9UtnqrnILEVMp1t6/I9v1XiI1NpGfrSvT32M3t+y9o1bjMJ29DWtT1/bHmdWr1HWDnziOULGVNmTI2TJ/mz+w5rtSpU5WVK0K0lmVr8AHOn71CG3s3BvabQVxsPG3s3bh3702+e/cec/jQH5rXdepWwdwsBzdu3E2xrHNnI3j27AXfff8VM6avxt2jJ126Nmee7yat5U2PqKj7dOrohtLAgJUrJ75T3yHz9r3PWVjYYewdGr33/V07j1CqZFHKlLHBc/oKZs92oU6dr1m5MvS982Q0fcycFpVCkWl/uqK3jZzv61Tljz8ucu1aFACBgWE0alwrRZl69apz69Y9zp27DMCJE+dQKBQpWuIqlYoZXstxdVVf/xIfn4ChoSEKpZKY2LhM2po3Nmz0IjTUl6DgWSxa5I6pqTFBwbOwLPTmvL9KpcJrxkpcXXu8ldkAhUJBbIz2Mj958pzuXT1o0rQW3j7DMDV99xxzzpwm+M5Zx59/XgLgwIH/ERsTR+XKKb/4vWasxtm5C0qlkvj4RIwMDVAqlFrJe/7yQ2p+ZUX+POov/KbfFefmnWjKlcjLkO7VUSoVmBgb0MW2Ajv2X31nfqsCZozsWxMTYwOUSgU9W1di+4ErKcoUzJeDpnVKEBDyF0qlAoUCVCpITlaRwyTjO0S/r/P1v+r7Lho1rpmiTExMHP7LgnByUp8OTExMwsBAiUKp0GpdXrdhMkGhM9gUNI35i1wxMTVmU9A0LN+6niYuLh6X4X5EXlf/oDh+7DyJScmUKlVUU0alUuHttZYRruq7v1LUYx3se0+ePKdb17E0bVobH58Rqdb3zNr3PmdPn0YTGXmHqlXLp/p+TEwc/v5bGeTUHnhTj7V1vPgv9DGzUNPb01X58+dh6rQhDBk8nYSERGyKWeHpOYyzZy/hPnYuwVvnULBgXubOG83ECQuJiYnFyNgIPz83TEyMNcvZtGk3tWpV1jR8Bgxoh2OPsRgbGzFh4i+Zsi3nzl7G3X0eQcGzPqr8pk3h1KpVmaKvuvP7D2iLo6MHxsZGTJwwII25P15g4K/cvv2A8PBjhIcf00xfuMiN/v2msWjRaCwL5cNn1nDGeywmISERc7Mc+M51SXHdzpEjf5IjhwlVvi4HQA/HlniMWwTAsBGffnvz0TO3WbrxLAHePxGfkMTT53H099jNzTvP8Rj0HdsX22NoqCTs4FU2hF0EoOPPX1CpXAHG+Bxi3fa/sSlswdYFdhgYKDh65jbz1pxOsQ7XPjXx8T9JUrKK6JcJ7D5yne2LHXj4JIZBE/d88jak5uzZy6/q8uxX9d2JIYNnvFXfh6Qov2jhJjp2aqF5jELPnrbY2w3D3Dwn3t4jMiTj2+7de8zAfjOYv8gVG5tCTJjcl2FDZqsvCrfIydz5zikuxtyyaT81a1WgaNGCAPTrb09vxykYGxvhMbF3hueFlPteYODOV/X9KOHhRzVl/JdPIG/eXEDm7XufE/VnPJ+gYB8AIiNvU7BgXoyMUv/6WbRoMx07NtfUY8eerXCwH4GZeQ68vTPu0R76nvk/0dtujo+nUL19O1IWoeKiriOkm0qVpOsI6aIiUdcR0u2LH07oOkK6/bNbTy5AfCUh+WXahbIYQ0UOXUdIN6VCv35fJqsS0i4kPplSUTFT11d86u5MW9f10U0zbV1vy5Q9LTY2FqVSibGxcdqFhRBCCJHxssETjzOks+ry5csMHDgQNzc3jhw5wo8//siPP/7Ivn37MmJ1QgghhBDvyJCeHA8PD4YMGcKtW7cYPHgwu3btwsTEhN69e9Ow4fufBSKEEEKITKLD59dklgxp5CQnJ1OzpvrOj2PHjpE/f371ygx1dx56zZptBK4LQ6FQYGNjxaTJg8ifP4/O8nyIeqyUN7f8vhkrZalmfKisQqVSMcZtHmXKFqNnr1bExsYxaeIyzp29TLJKxVdflcV9XK9U71T5VE2+K46Xaz2q2q3WTLMwM2atz0+4ef/GuX9SPrAvl7kxwfNtmbHkBDt/u6aZPrJvTY7/cZt9x24AYGSoZK3PT+w8eJVlm84BUKZYHiYN+x6zHEaoVOC17ASHTt5Ksfzu9hVp16I8P/XdovVtfW36dH927TxC7tzmAJQsWZRZs10ybH3/RWjIIVb4b0OhUGBqaozbmO5UrFQKgGfPXtCj60QmTemnmZbV/HPxOpMnLyE6+iVKpZIJEwZQsVLptGcU6bJ791Hm+q1HqVSQK5c5kyYPpFixzH0uWXroW16hliGnq0qWLMmYMWNITk5m+vTpACxevJgCBQqkMWfGOHfuMv7+wawLnEHotrkUL1GEOXMCdJLlY6jHSplFUPAsNmz0ejVWSp8s18CJiLhJzx4T2Lnzd820RQu3kJSURNDWmQRvnUlcbDxLFgdpfd3Fi+ZiVN+aKN76JVK/pjWb57ailE3uVOfxcq2Pudm714V9V7UIh/8XpXk9ZkBtihVO+fCu8YO/Y/POf2jVPxi3mb/hO7YRBm+tu1pFS/q0r/ypm5Wm06cv4u3jTPDW2QRvnZ3lGjhXr0bh47WWhYtHsiloGn372zF0sPquwYMHTtOpnTtXr0alsRTdiYmJo1fvCfTqbc+WIB8GDGyLi8vH3fUoPl5sbBwjXefg6+dKULAPDRt9w5QpS3Ud6730Le9HywZPPM6QRs7kyZNp2LBhiqcPFypUiGnTpmXE6tJUqVIZdu1aiIWFGXFx8dy9+1BvnkD577FSspJ1ATuxd2hI8+bfaqbVqFGB/v1bo1QqMTAw4MsKJYm6pd0hEExNDPAeWZ+pi46lmN7NriKuMw5y7+G7dwj90vlr/r76iH+uPk4xvUzxPNy4/Yz4BPXdcbZNymBhZsT+4zdSlFMqFeSyUPdGmeU0Ii7+zd10+fOYMt7pO2Yszti7v+LjE/jrwhWW+wdj22ooTk7TiYr68BOHM5uxsRETJvXRjEFVsVIpHjx4QkJ8ImvX7GLytP5YFsy48ak+1eHDZyhmU4j69dXDmTRqVJNZs511nOrzk5SUjEqlIvq5el99+TIGkyx8Y4q+5RVvZMj5I6VSSZMmTVJMs7W1zYhVfTQjI0PCw48ydowfxsZGDB786c9nyWjqsVK2snmLt66jpGrsOPWzTI7+flYz7fs6VTT/vnXrPqtWbmfCxH5aXe+koXUI3P43F6+kfAp0r9G7Ui1fp3pRvvnKip5uu1g1I+X4SE2+K87uI+ohHcqVyEt3+wp0HrGD8U7fpig3we8Iq7x+xNGhEvnymDJs6j6SklUolQp8RjfEc/HxVJ+mrE337j6idu3KDBvelZIli+C/LJhfBk5lS5APiixyl0TRogU1z71RqVR4ea6hYcPqGBkbsnDJKB2nS9u1a1EUKJCXMWPmcvHva1jkMpNRxjOAmVkOPMb3o2NHN/LksSA5OZmAtVN1Heu99C2veCMbPArojSZNanP0WACDnDrSu5fHe8cDyipSGytFX5w/F0HXLu506tycBg2ra225nVp+SVJSMpt2Xfqo8oULmjGqX02cpx8gOfndR0I1qGXD/mORmOc0Yuao+rh6HiQmNuUzhIyNDJgzthGjvA5St1MgnUdsZ9KQ77EqaIZzzxqc+PNOitNdGcXaphCLl4yjVKmiKBQKevayIzLyzjtjnGUFL1/GMmLYHG5cv8v4SX10HeejJSYmcvDgKdq1+4FNm2fSpcuP9O83mfh4eU6MNv1z8ToL5m9k23ZfDv62jH792jBk8Ayy4GPbAP3L+9EUmfinI9mikXP9ehSnTl7QvG7duglRUfd5+jRah6nSltZYKVnVju2H6dVrEsOHd6ZffwetLtvhh7JULleQkIV2LJ3yA6bGBoQstMMyf85Uy7eoX5IcJob4T2tGyEI7KpUrgGufmnT8+Qss8+ckLj6Jp8/jqVvDGgszY3xGNyBkoR2NahenR+tKDOlejXIl82JqYqi5MPnMX/e5dP0JX39RENsmZfihTnFCFtoxdXhdihWxIGShnVa3+bWLf19ja3DKxzCoVKp3xgnTtdtRD+jaaTwGSiXLVo5NdfynrMqyYD5KlrKmShX107kbN66V6nh34tMcOnSaqlW/0Fy426lzcy5dusGTJ891nCx1+pZXvKFfj938j+7ff8yI4TMJDp5D3ny5CA09QNmyxTSPas+K1GOl3KZq1S90HSVddu38nalT/Fm61J1KlbV/R0obpzd3nRUtZM72JQ4pRhv/N/9N5/B/dYcUwJqZP7Jm6wV2/naNTj9/oRl9POzgVcIOvhnXytOlLv9cfcyyTeewMDPGwsyIqhUsOX3hHsUKW1C6WB4uXH7I9x3eDMpY8ysrPAZ998E8n0KhVDBlylKqV6+AtU0h1q0No3z5ElhZ6eaC/tQ8fRKNY7dJ2NrXY8AvrXUdJ93q1qvGjBkrOH8ugoqVSnPixHkUCvSyNzUrq1CxNAEBYTx48IQCBfKwJ/w41taWWfaYrG95P5ZKbiH/PNSoUZH+/dvSrdtoDAwMsLTMx7x5o3Ud64PSGislq5o1ay0qlQp39wWaadWqfYH7uMwZiyg9Gn9XnHFzDqdZ7vmLeAaO38PYgbUxMTYgMTEZ99mHNaOeZ5Zy5YozdmwfBgyYQlJSMlZW+fH2yfgxqdJjfWA4t28/YE/4SfaEn9RMX+o/mjx5s/7F/gUL5sVv7igmTlzEy5hYjI2M8PUbmWK8O/HpateuTM9ednTv5o6RkSG5c1swd17WvWZL3/KKN2TsKi2RsasynoxdlfFk7KrMIWNXidRk9thVxWbtz7R1RQ5rkGnrelu2uCZHCCGEENmPfv2cEEIIIYR2ZINrcqQnRwghhBCfJenJEUIIIbKjz78jR3pyhBBCCPF5kp4cIYQQIhtSZoNujmywiUIIIYTIjqQnRwghhMiGssi4vhlKenKEEEII8VmSnhwhhBAiG5KeHCGEEEIIPSWNHCGEEEJ8luR0lRBCCJENKbLB+SrpyRFCCCHEZ0l6coQQQohsKBt05EgjRwghhBC6k5SUxNixY7l69SoKhYIJEyZgYmLCqFGjUCgUlC1bFg8PD5RKJXPnzmX//v0YGhoyevRovvrqqw8uWxo5QgghRDaUVXpy9u3bB0BgYCDHjh1j1qxZqFQqhg4dSq1atRg3bhx79uyhSJEiHD9+nI0bN3L79m2cnJzYvHnzB5edRRs5yboOkG6Jqpe6jpAuRkozXUdIt39219F1hHQrV+NXXUdIl0snm+k6QrqpUOk6QrrpW2aFIot+VXyASpWo6wjiIzVp0oQGDRoAEBUVRa5cuThy5Ag1a9YEoF69ehw+fJiSJUtSp04dFAoFRYoUISkpiUePHpEvX773LlsuPBZCCCGyIYUy8/7SYmhoyMiRI5k0aRItW7ZEpVJp7v4yMzPj+fPnREdHY25urpnn9fQPkUaOEEIIIXTO09OTXbt24e7uTlxcnGb6ixcvyJUrF+bm5rx48SLFdAsLiw8uUxo5QgghRDakUGTe34cEBwezaNEiAHLkyIFCoaBSpUocO3YMgIMHD1KjRg2qVavGoUOHSE5OJioqiuTk5A+eqoIse02OEEIIIbKDH374ATc3Nzp37kxiYiKjR4+mdOnSuLu74+PjQ6lSpWjWrBkGBgbUqFGD9u3bk5yczLhx49JctkKlUmW5K+BU/KXrCOmWkPwi7UJZiD5eeKyPHY9y4XHG07eLeEXm0McLj5WKipm6vi+XHcy0df3Vq16mrett+vetIYQQQgjxEeR0lRBCCJENZZXn5GQk6ckRQgghxGdJenKEEEKIbEh6coQQQggh9JQ0coQQQgjxWZLTVUIIIUQ2pMgG56ukJ0cIIYQQnyXpyRFCCCGyoY8ZOFPfZYNNFEIIIUR2pNeNnP37T9Kq5RCaNxvIkMEziI5++U6Z3buP0qrlEOxsh9Kt61giI28DEBl5mzatnWn582A2bwrXlA/Zup/ZswIyNPee8JPUrtEr1fcC1uyiQd2BtLF3o429G927TAQgIT6RX/p70drOjQkeyzTlb0TepU/PaRmaV6VSMWrUHJYtC071/ff9P+jqM96//wStWjrRvNkAhgyenmq9eC08/CjVq7XXvH78+BldOo+iZUsn5s8L1Ew/dfICri4+Ws3Ztf1X7NrchZCADsya0ozcuUxQKhWMHVGXnZu6EB7UlY6tK6U674fKdXCoSNiGzmzwb4N1kVya6UvmtKR0ibxa3QZ98jH14uLFa3TtOhp7uyG0dhjOuXOXgcytF+nN/Jou67K+5n1NpVLhNsoP//cc43bvPoptq2HY2w2ne7dxREbeASAy8g5t27jQsuUQNm/eoykfEnKA2bPXZmhmbcgqA3RmJL1t5Dx69JTRbn74+o1k56752NgUwnvmqhRlYmPjcHWZhd/cUQRvnU2jxjWZMnkpAAEBYTj2tGXzFm8WLtwIQHR0DAEBO+jXv02G5b5+7Q7eXmtJfs+QYX+cvoTLyM5sCprGpqBprFyjHoDs0KE/KGSVj83B07gd9YBL/9wAwGtGAM6unTIsb0TEDXp0H8fOsMOpvv+h/wddfMbqPL74+rmxc9cCbGys8J65MtWy165FMcPTn7eHbwsNPUC9+jUICfFlx47fiI5+SVJSEj4+q3B26aG1nLWqF6Vvt+p0HxBEq86B7D98jcljGtHBoRLFi+Xhp/YBOHTbQPeOX/NVxULvzP+hcn27V8e28zpWBv5B57aVAWjeuDSXrzwi4tpjrW2DPvmYehETE0fvXh707u1AUPAcBg5sh4uzN5B59SK9mV/TZV3W17yvRUTcxLGHBzt3pn6Mi42NY6TrHHz9XAkK9qFho2+YMkX9PbI2IIwejrZs3jyTRQs3AfDi9TGuX+sMyyw+nt42cg4fOkPlymUoUaIIAB06Nic09GCKnSYpKRmVSsXz5+rBM1++iMHYxAgAY2MjYmPiiIuLR6lUfwzz5gXi6GhLjhwmGZI5JiYOt5HzcRnZ+b1lzpz+hx3bjtDWYTT9ek/nn38i38obj0qlIjY2HiMjQw7s+x+Wlnkp/0XxDMkL6oaKg0Mjmrf4PtX3P/T/oIvP+PCh01SuXPatPC0IDT3Av8ehjYmJw9XFh1GjUvaovc6cmJhEYmIySqWSdevCaNSoJpaW+bSWs9KXlhw5foM799R189e9ETSqW5IWTcqwOeQvkpJUPHsex/Zf/8G2Rfl35v+hYan3lktMTMbY2IAcOYxISEjG1MSQXl2qMXfJca3l1zcfUy8OHz6NjY0V9evXAKBR41rMnu0KZF69SG9m0H1d1te8r60NCMPeoRHNm6d+jHv9PRL9XN0r9fJlDCbGxm8yx6qPcQrNMW59hh7jtEl6crKw23ceYGVVQPPayqoA0dEvefEiRjPNzCwH4ycMoGOHUdSt40hAwA6cnbsD0LXrT2zf8Rvdu7vj4tqdiIgbXPon8r1f5tow0WMZbds1olz5Yqm+//JlLCVLFaFPP1s2bpmKfesGDOg7g5cvYvn2u0oYGRnS1mE039T8kiJFC7B4YTBOQ9plWF6AceP6YmvX8L3vf+j/QRef8cfUCwCPcfNo374Z5cqXSDG9VasGXLocSbu2I+jhaEtcbDzbth2kW/dWWs355/m71P7GmiJWFgC0blUBY2MDLAuacefuc025O3ejsbI0f2d+q0IW7y3nPe931ixyoHmjMqwMPMOAnjVYs/FPXrxM0Oo26JOPqRfXrt6iQMG8jBntS2uH4fR0HEdiUjKQefUivZlB93VZX/O+5j6uD7a2Dd77vplZDjzG96NjRzfq1e3F2oAwRjh3BaBL1x/Zsf0QPbp74OLSjYiIm1y6FEnz5t9laGbx8fT27qrk5ORUp7/uMQD1+fX589azfYcfxYoVZtWqbQx28iR46ywsLfPh7z9BU7Zvn4mMcuvJ/v0nWbc2jDx5LHAb3Ys8eSy0kjdw7W4MDA2wb92AW7fup1omZ05TFi0dpXndvEVtFi0I4ty5CGrWqsiEyX007y1aEIRd6wY8efyccWMWA9B/oD1fViihlbwf60P/D5n9GaeV57W1ATswMDSgdZum3Lx5N0W5nDlN8fNz07x2HzuXQYM6cuFCBPPnryeHqQnOzt2xtrH6pJwnTkfht+Q482f+SHKyik0hf/H4SQzKVH7yJKWyTcpUfhm9LrdrbwS79kYAUKxoLr6ubMWcRccYM7wu1kVzcfx/t1gecOaT8uubj6kXiYlJHDxwkpWrplClSnn2hB+lX98J7N23LNPqRXozZ4W6rK95P9Y/F6+zYP5Gtm33pVgxK1av2s6QwTMICvbB0jIfy/w9NGX79p3MyFGO6mPcup3qY5xbT60e47QpGzwmR397cooULsj9+2+uL7h79yG5c5uTM6epZtqhQ2eoWu1LihUrDEDnzi24dCmSJ4+fp1jWzp1HKFnKmjJlbJg+zZ/Zc1ypU6cqK1eEaC3v1uCDnD97hTb2bgzsN4O42Hja2Ltx796bbYi6dZ+ANbtSzqgCQ8OUbdHbUQ84cvgsrds0YN7cTXTr0YLR7t2ZPjXlNUmZ4WP+HyBzPuM3eR59ME9Q0B7Onb2Ene0Q+vWdSGxsPHa2Q7h792GKZZ398xJPn0VTp05Vpk1bxvjxA+jWrSW+vp9+QaFZTiOOn7qFXZf1OHTbwK696gtco+48p2ABM025Qpbm3LkX/c78UXeiP6qc2/C6eM45xHffWGNmZsSAEdup921xilnn/uRt0CcfUy8KWuajVClrqlRRn/Zr3KQ2SUnJ3LhxJ8WyMrJepDdzVqjL+pr3Yx06dJqqVb+gWDF146pT5+ZcunSDJ09Sfo/s2nmEUiWLUqaMDZ7TVzB7tgt16nzNypWhmZ5ZvKG3jZzv63zNH39c5Nq1KAACA3fRqHHNFGUqVijFiRPnePDgCQDh4cewtrYkb743d5zExMThvywIJ6cOgPrXnIGBEoVSQUxsnNbyrtswiaBQTzYFTWP+IldMTI3ZFDQNS8s3d7vkyGnK3DkbOfun+lf4wQNniImNo3Ll0imWNdNrLcOdO6JUKkmIT8TQ0AClQkFMjPbyfqyP+X/IrM9Ynafqv/KE0ahxrRRlNm7yJnTbXIK3zmHR4nGYmhoTvHUOhQrl15RRqVTM8FqOq6sjAPHxCRgaGqJQKrWS2bKgGQGLHDA3U18j9kvvmmz79RLhB67QplUFDAwUWJgb8/MPZQnff+Wd+fccTLtcwzoluHf/BRcuPsDY2IDExGTNtpma6G0n7n/yMfWiXr3q3Lp1T3NH1YkT51AoFFhbv7nwO6PrRXozZ4W6rK95P1aFiqU5ceK85ntkT/hx9fdI3n99j/hvZZCT+m6x18c4pUJJrA6Oyx9Lqci8P13R2yNd/vx5mDrNiSGDZ5CQkIhNMSs8PYdw9uxl3MfOJXjrbGp/+xW9etnTretYjIwMyZ3bnHnzR6dYzqKFm+jYqQXm5jkB6NnTFnu7YZib58Tbe0SGb8e9e48Z2G8G8xe5YmmZl5mzBjNx/DIS4hMxM8/BHL9hGBm/+W/6/cg5cuQwocrXZQHo7vij5pbyocM7ZHheIMVn/L7/h7dl5meszjOEIYOnv5VnGGfPXnqVec5HLWfTpt3UqlVZ8wU3YEA7HHuMxdjYiAkTf/nknFevP2HRylNsWtEOhVLBqTNRTJhxgMTEZIoVzU3o2o4YGRkQuOUcx/+n/tIY0k/9hTFn0THWbjr73nIAxkZKfun9Db0Gq3vKDh2NpFObrwhZ25E/zt3hn4iH74b6jH1MvShYMC9z541m4oSFxMTEYmRshJ+fGyYmxprlZHS9SG/mj5FZmfUt74ecO3sZd/f5BAX7ULt2ZXr2sqN7N/dX3yMWzJ03KkX5RYs207Fjc80xzrFnKxzsR2BmngNv7+GZklmkTqH696XvWYCKv3QdId0Skl/oOkK6GCnN0i6U5ehfx2O5Gr/qOkK6XDrZTNcR0k1FljuEiSxApUrUdYR0UyoqZur6qq/7LdPWdapj3Uxb19sy/Fvj4cPs9YtRCCGEEFmD1k9XXb16NcXrkSNH4unpCUDJkiW1vTohhBBC/AfZ4e4qrTdyHB0dMTU1xdLSEpVKxdWrVxk3bhwKhYJVqzL/7h8hhBBCZE9ab+Rs3rwZDw8POnbsyPfff0/Xrl1ZvXq1tlfzn4SHH2Wk6xxO/W+drqOkKjTkECv8t6NQgKmpCW5juvFlhRLM9g7k4IEzKJQKihe3YtyEXuR76w6xrGL6dH927TxC7tzqh9KVLFmUWbNddJzq/UK27mPZsiAUCgWmOUwYM6YPlSuXzbD1NalfCq8JTanaYFGK6aOH16GETR76DtuWYvoXZQuwzK8V3zf3TzF95JDvOX7qFvsOXQPAyFDJ2iWt2bnnMsvWnAbUw0a4DauDgYGSJ09jmeL9G39fegBAm1Zf0rtrNQwMlBw5foNJXgc1D70TamvWbCNwXRgKhQIbGysmTR5E/vx5dB3rvTK7LmuDvmVes3o7AQFhmJoaU6qUNe7j+mTZ59+IN7TeyMmfPz+zZ8/G09OTs2fPanvx/5l6rJQV7zxiPKu4ejUKH691bNg8mYKWeTl44AxDB8+m/wB7Lly4xoYtUzA2NsLHay0zPQOY6jlA15Hfcfr0Rbx9nKlW7QtdR0nTlSs38fJaweYt6gdDHjhwksFO09i33z/tmf+D4ja5GTX0exT/ugquRZMy2Lb4gj/OvXkWi4GBgq7tq9Cve3Vy5Hh3F/2upg2zFhzVvB4zom6K596Ymxkzz+tHnEaG8fuJm5QqnpcFPj/RssNaihfLw+C+tbDrEsjjp7H4TG6GY+evWbLqf9rfaD117txl/P2D2bp1DhYWZnh6+jNnTgATM+nOnvTK7LqsDfqW+djRsyxdGkTg+ulYWRVg69b9eIxbwBxfV11H+yQKXd7bnUky5MJjQ0NDxowZozllpWvqsVJmMWpUT11HeS9jYyMmTOpNwVfPzalYqSQPHjyhWHErhjt3xNhY/TyVCpVKERX1QJdRUxUfn8BfF66w3D8Y21ZDcXKaTlRU6k92zgqMjY2YNHmQZkycSpXK8ODBE+LjtT/0gamJId6TfmDqrEMpppcukZc+3aoxd2nKMaUqfmHJF2Xy4zQy7J1llSmVjxu3nhIfnwSA7Y/lsTA3Yf+rXh2AEsXy8Dw6nt9P3ATgyvXHREfH8/VXhWlSvxR7Dl7l0ZNYVCpYt+UcrVIZGys7q1SpDLt2LcTCwoy4uHju3n2YpX+xZ2Zd1hZ9y3z+fATffltFM2xF06a12bfvZJbNK97I0LurHBwcWLNmTUau4qN4jJv/aqyUjBvI8lMVLVqQeg2qAuqHYXl5BtCwYTW+qfklFSqqL9h++vQFi+YH8UPzWh9alE7cu/uI2rUrM2x4V4K3zuLrKuX5ZeDULNHITY21dSEaNPgGUH/e06cto2GjmprGpDZNGtOQwC3nuHjpTeM0Zw4jvCY2ZeSEcF68iE9R/s/zdxk1cQ+37z7/96JoUr8Uu1899K9c6fx071CFsVP2pihzLfIxOXMaUaeWDQCVK1hStnQ+LAvkpHAhc27fffNk5PeNjZXdGRkZEh5+lPr1HDl54jwODk10Hem9MrMua4u+Za78VVmOHTvLrVv3AAjaspeEhMR3nnqsb2SAzs/Am7FSsu5B6m0vX8YyYpgvN67fYfykN2NV3Yi8S4+uE6lavRwdOzXVYcLUWdsUYvGScZQqVRSFQkHPXnZERt7h1s17uo72QS9fxjJ0iCeRkbeZPHmQ1pffqU1lkhKT2RSS8tlPU90bs3r9n1yKePSeOVPXoE5x9h+6hrmZMTMnNsXVYzcxsSmfBxL9IoEBI7bTv2cNQtZ2xO6nLzh64iYJCckoUjnaJCdnzYaorjVpUpujxwIY5NSR3r083js2U1aR0XU5I+hL5m++qcjAX9rh5ORJm9YuKJQKcuc2x8goazbKxBt6+8TjjxUUtI/Y2DjsbIeSkJD4aqyUoSxaPI5ChfLpOl4Kt6MeMGigN6VKFWHZyrGYmqqftHr82Hlchs/FsdfP9Oj5k45Tpu7i39f4+++rKUYsV6lUGBoZ6DDVh0VF3WdA/0mULm3DylVTMDU10fo6HFp+SQ5TQ0ICOmBkZICpiSHhQV2xKZqbUsXz4Njpa3LnNsXC3Jglc1rSZ8j7x7mxLGBGXFwST5/F0aJJGSwsTPCZrH54X2ErC76rZYO5mTG+i4/x8mUCXfoFaebdubEz1288pXTJ51gWyKmZbmVpluqYV9nZ9etRPLj/hOo1KgDQunUTxnss4OnT6BSP8s9KMqMua5s+ZX4RHcM331Skzasfyw8ePMF3zjry5NHvXlC5hfwzsHGTl+bfN2/epVXLIQRvna27QO/x9Ek0jt0mY2tflwG/tNZMP3P6H4Y6zWaG9yDq1K2iw4QfplAqmDJlKdWrV8DaphDr1oZRvnwJzTnsrObJk+d07eKGvUNjBg3qmGHradN9g+bfRQtbsH19J5rYp7zb0OHnL2jeuMw7d1f9W5P6Jdl7UP0cqrDwy4SFX9a85+nRhH8iHmrurloypyUDRmzn3F/3aN64DAmJyfx96QEqlYoF3j8x3/8kjx7H0N6+kub0l1C7f/8xI4bPJDh4Dnnz5SI09ABlyxbLsg2czKrL2qRvme/de4Sjowfbtvtibp6TBfM38tNPdVPtGRVZy2ffyNEX6wPDuX37AXvCT7In/KRmet68uVCpVMz2CWS2TyAARYtaMmfuMF1FTVW5csUZO7YPAwZMISkpGSur/Hj7ZPzYX/9V4Lowbt9+QPjuo4TvfnOn0vIVk7Lsl1nj+qUYN23fR5UdMXYXU8Y2wshQyb0HLxnovB2Ai5cfMm/pCVYvtMfQUMkf5+6yeOWpjIytd2rUqEj//m3p1m00BgYGWFrmY9680WnPqCP6WJf1LXPJUkXp08eB9u1Gkpysolr1L3F3763rWJ8sO7TRZOwqLZGxqzKD/l1CJmNXZTwZu0qkRsauSlvtzYfSLqQlR1vXybR1vU16coQQQohsKBs8JkcPfxoLIYQQQnwE6ckRQgghsqHscE2O9OQIIYQQ4rP03p6cL774QnN73L+vTVYoFPz1l/5dHCyEEEIItX+Ppfc5em8j5++//87MHEIIIYQQWpXmNTkPHz4kNDSUFy9eoFKpSE5O5ubNm8yYMSMz8gkhhBAiA8g1OcCgQYP466+/CAkJISYmhr1796JUZoM+LiGEEELotTRbK48fP8bT05NGjRrxww8/sHr1ai5dupQZ2YQQQggh/rM0Gzm5c+cGoGTJkvz9999YWFiQmKh/T5IUQgghxBsKhSLT/nQlzWtyateuzeDBgxk5ciQ9e/bk/PnzmJhk3dFihRBCCCHgIxo5w4YNIzIykqJFi+Lj48OJEycYNGhQZmQTQgghRAbJDhcep9nICQ4OBuB///sfAHny5OHIkSPY2dllZC4hhBBCiE+SZiPn2LFjmn8nJCRw6tQpatSoIY0cIYQQQo9JTw4wbdq0FK+fPHnCsGHDMiyQEEIIIYQ2pHuAzpw5c3Lr1q2MyCKEEEKITCI9OUDXrl1TjGF18+ZN6tWrl+HBhBBCCCE+RZqNHCcnJ82/FQoFefPmpUyZMhkaKlmVlKHLzwhGSjNdR0gXlSpZ1xHSLT75qa4jpNulk810HSFdytbYpesI6fb3ifq6jpBuSoV+PYZDpYfHZBWqtAtlc8ps0JOT5sMAd+3aRc2aNalZsybffPMNZcqUYeTIkZmRTQghhBDiP3tvT86YMWO4ceMG586dSzGMQ2JiIs+fP8+UcEIIIYTIGNmhJ+e9jZwBAwZw69YtpkyZgpOTEyqVuuvPwMCA0qVLZ1pAIYQQQoj/4r2nq6ytralVqxZr167ln3/+oWbNmhQvXpxDhw7JsA5CCCGEnlMqVJn2p7NtTKuAs7Mz9+7dA8DMzIzk5GRcXV0zPJgQQgghxKdIs5ETFRWlefifubm5ZiwrIYQQQugvpSLz/nS2jWkVUCgUXLx4UfM6IiICQ8N0P0NQCCGEECJTpdlaGTlyJD179qRQoUIAPH78GC8vrwwPJoQQQoiMk2Yvx2cgzUbOd999x759+/j77785ePAgv/32G3369OH06dOZkU8IIYQQ4j9Js5Fz48YN1q9fz5YtW3j27Bn9+/dnwYIFmZFNCCGEEOI/e29v1e7du+nVqxdt27bl6dOneHl5YWlpyaBBg8iXL19mZhRCCCGElmWHW8jf25Pj5ORE8+bNWb9+PcWLFwfQDNQphBBCCJHVvbeRExISQlBQEJ06daJo0aL89NNPJCXp3yBtQgghhHhXdhjW4b2nq8qVK8fIkSM5ePAgffv25fjx4zx48IC+ffty4MCBzMwohBBCCJFuaV54bGBgQJMmTWjSpAmPHj1i69ateHt7U79+/czIJ4QQQogMkB1uIU/XNubLlw9HR0dCQkIyKo8QQgghhFbo9aOLQ0IOsHzZVlAoyGFqwugxPalUuUyqZf181/H0STRjx/UB4Mnj5zg5efLs6Quat/iOAQPbAnDq1F9sWP8rnjOGZEjm/ftP4uO9mvj4BMqXL8GUqYMwN8+Zoszu3Ufx812HUqkgVy5zJk/5hWLFChMZeZvhw7yJi4unR49WtG7TRP05bN3PlSu3GDqsc4ZkVqlUjHabS9myNvTsZZfiveDgfaxcEap5/fz5S+7efci+/Ut4+TKWEcO9iX2dt3Vjdd6QA+q8QztlSN6ZnuvYves4uXObA1C8pBVePr+kKLMr7BhLFqkb63nyWuDu0YPiJax48iSaYU5zePbsJT80r0m/AbYA/O/UP2zasI+pnv0yJPP+/Sfw9l6lqRdTpw5+p15s3bqPZcu2oFAoyJHDhDFj+lK5clkeP37GoEFTefYsmubN6/DLLx0AOHnyPOvX78TLa4RWMjZtUIrB/WqhSlbx9HkcYybt4dGTWKaNa0ypEnlRKhQEbf+LxSv/9868fp4tKG6dW/Paumgujv/vFv2Hb6eDQ0W6d/ia59FxDB/7KzejngGwZE5Lps86RMS1x1rJHxJykOXLQkDBW8eL0inKhIUdYdGCzQDkzWuBx4R+lChR+NXxwotnT6NfHS/aAK+PF7vxnDFYKxn/bf/+E/h4ryI+PpHy5YszJZV6cfHiNSZPXkz08xcolQZMmDiQSpXK8PjxM5wGTeXpsxe0aP49A1/Vi1MnL7B+/U5meA3PkMzq44UfZcsWe+d4ARCwZgfrAneiUEAxGysmThpI/vx5iIy8zYjhPsTGxb06Xrw6voW8Or4NzZjjmz5+j2hLtr4mJ6u7euUWM71WsXiJO0HB3vQb0JrBg999EvOdOw8ZOtiL5f4pe59CQw9Sr141gkN82LHjENHRL0lKSmKWTwDOzt0yJPOjR08Z7eaHr99Idu6aj41NIbxnrkpRJjY2DleXWfjNHUXw1tk0alyTKZOXAhAQEIZjT1s2b/Fm4cKNAERHxxAQsIN+/dtkSOaIiJs49vBg587Dqb5vZ9eQoGAfgoJ92LBxBgUK5GHs2N4UKJCHtQFh9HC0ZfPmmSxauAmAF6/z9mudIXkB/jhzCU/vgWwImsSGoEnvNHAePnjK5AkrmbtgOJuCp9C4SXWmTVkNwPbQI9SpV4VNwZPZueMo0dExJCUl4ztrI8Oc22dI3kePnuLmNgc/Pzd27VqIjY0VM2euSFHmypWbeHktZ+nSCWzd6suAAe1xcpoKQGjofurXr05IiB87dhzU1GUfn1W4uDhqJaOJiQEzJ/3ALy47aNU5kD0Hr+LuUp9hA2pz5240P7Vfi0O39XRsXZmvK1u9M7/TyDBadQ6kVedAxkzZy7PncYz3VF/b17d7dWw7r2Nl4B90blsZgOaNS3P5yiOtNXDUx4vVLF4yhqDgmakeLx48eMKE8YtZsMiN4BBvmjStxZRJywAIDf2NevWqEhzizY4dh986XqzF2bmrVjL+m/p44Yuvnxs7dy3AxsYK75krU5SJiYmjdy8Pevd2ICh4DgMHtsPF2ftV5gPUq1+DkBBfduz4LUW9cHbpkSGZIyJu4Nhj3HuPF+fPReDvH8y6ddMIDfWlePEi+M5ZB/DqeNGKzZu9/3W8CKNfv4w5vunj94hIH71t5BgbGzFp0kAKWuYFoFKlMjx48IT4+IQU5TZv2kP1Gl/Sw7HVO/PHxsaRmJhEUmIySqWSwHW7aNiohmaZ2nb40BkqVy5DiRJFAOjQsTmhoQdRqd48QyApKRmVSsXz5y8AePkiBmMTozeZY+KIi4tHqVT/182bF4ijoy05cphkSOa1AWHYOzSiefPv0yy7dGkQ+fPnpn2HZm/yxqrzKjR512do3vj4BP7+K5KVy8Noaz+W4UP8uB31MEWZ/AVys/c3X6wK5ycxMYnbUQ/Jk8f8rczx6nqRpK4X/2fvzuNqSv8Ajn/urW6lJEsJZRvb2Pc1WxjMjJB9S2Xs+y4qsiUplH3fstNiibETw2AwWX52opI1SXvd3x+XS4oY3W5Xz3tevV5zzn3OOd9zPPc5z33Oc55n+9YjNGteAxMTY5XEHBx8iSpVyirzRY8ebdmz50SafCGT6TBz5nBMTRVjVH2c32UyHeLiFHk5+V1e3rIlCCuresr030tLKkUigbyGMgAM9HVISExmxryTzFkYDIBJIQNkMi1iYhI+ux8dbSlzp7VilucpnkTGAJCcnIpMpoW+vg5JSano6WrTr3dNFq38O0tih/flxaCPyouf0pUXhQoZcyp4FUWKFCI5OYXw8Gef5Iv35UXKu/LiTxWXF2nzRfcM8sXp05ewsDCjadPaAFi1qMeCBRM+xJxhvqibZfniU4ryosVny4tKlX/iwMEl5M1rQEJCIpGRLzA2zvsh3gzLC2uVlReaeB/JShKJPNv+1EVjKznFzE1p2qwWoGgedZ+zDqvmtZHJdNKkGzqsK31sf1dWCt5rZ92EO7cf0a3rJPratSMhIZF9e4Oxtf1dZTFHPHmOmVkh5bKZWSFiYmJ5+zZOuc7AQJ9proPp0X0SjS3t8fXdz7hxfQHo0+c39u0/Rd++zoyf0Je7dx9x+1YobdpmXgH5r5xd+tO+fbNM0716Fc26tYE4TnZQruvd51f27wvGru9Uxo+35e7dx9y+HUqbNg1VFu/Tp1HUrfczI0d3YfvuGVSt+hMjhy1Ic2MA0NHR5trV+/zSfDS7dhynR69WAPzWriF374TRq5srffq2ISEhkaB9Z+ll+4vKYn7y5Fmm+cLcvDDNmtUBFPndzW01VlZ1kcl0sLZuzp07oXTpMhZ7+/bExyewd+8J+va1Tnes/yo2LgkXt+NsX9OF4CB7enetylzvMwCkpMiZN70V+7f15O+LYdx7GPXZ/XRpX5HIZ285dPyecp3n4r/YtNyGNlZlWL/1MoMdarNpx7+8jU367H6+VfryYn2G5YWOjjZXQ+7SvNlAdmw/TK/ebQFoZ92YO7cf062r4yflxW9ZFuOnvqa8eHA/jEIm+Zky2ZtONmNwsHchOSUVAGvrZty+E0rXLmOxs29PQnwie/eexDYL88WnnF0GZFpe6Ohoc/jwOZo1/YMLF67T0cYKgN59fntXXrgwfvy78u126Ff9wPqvNPE+Inwbje6TAxAbG89kx0U8efKcFSudv3q7PHn0WOgzQbns4ryUocO6cv36PZYt2Ymevoyx4/pgbl44y2JNTU3NcP3HX5ybNx+wZPE29u33oXjxImzYsJcRw93xD5iPqWkB1qxxVaYd0H86kxwdOH78Als2B2FsnBfHyf2Uv4yy0/Ztf2JlVTfN9TI1LcDqNVM/xDtgJhMn2Svi3XJAEa+jQ5bGa25uwuLlH/qg9HVoy4plAYSFPcfc3CRN2kqVS3H0lDenT/3LsEFe7PvTAyMjA7wWDlemcXVZw6ChHbhx/SErlgWgrydj5Nhu6fb1PVJTM/6V82mBCor8PmnSAp48ec6qVdMARV728ZmsTOPk5MOwYT24fv0uS5ZsRU9Pl3Hj7LCwSP8Y6WuV+6kgw/6oQ9sumwgNi8a2W1UWzf0V656KRw3jXA7h4nacRXPbMuyPunivOJfhfux6Vsdp9rE06w4evcvBo3cBKF7MiOpVzFi4/BxTxjRW9t1Z63v5P8f+MUV5sZgnT16wYuWUDNNUrvITp4JXcerUJQYNcuPPQ4sxMjJgoc84ZRoX52Xvyov778oLXcaO65Xt5UVycgonT1xg/YZZVKtWniOHzzJwgCtHj61+ly8clWmdnRZ9lC+2oa+ny7hxfTH/jnzxX7VsWY+WLeuxffuf9P9jOgf/XPKuvJimTDNgwAyVlxfvadJ9JCuJPjk5XHj4M3r1mIyWlpR1610xMjL4T/sJCblD9OsYGllWx91tHS7TBtDH9nd8vLdmabxFi5jw7NmHPgaRkS/Il8+QPHn0lOuCgy9To+bPFC9eBIBevdpy+3YoUa/epNnXgQNnKFXanDJlLJjjtoYFCydgaVmD9evU8+ZbUNBp5S+yjBw8cIbSpYpRpowF7nPWsWDBeCwtq7N+/Z7PbvNf3LoZyp7AtP0B5HLQ0dZSLj99+orTwSHK5UaNq2JoqM/jR0/TbHc15B7R0W9p2KgK89w34+TSl559fmGJz+4sjbnIV+QLgPDwp3TvPh4tLSkbNszCyMgw3b7+/fcW0dExWFrWxM1tFdOmDcHW1hpvb9/virFxg+JcvBJBaJiiU/CmHSGU+6kAv7Yqi2khxfcuNi6JvQdvUalCxhXAiuULoa0l5e+LYZ89juOYxrgvDKZhHXMMDHQYPHYfTRqUoPhHnZb/K0V54fSuvJiarrx4GvmS4FOXlcuNG9fA0CAPj0KfpEn3obyo9q686E8f21/x8d723TF+TFFevFQuZ5QvTEwLULq0OdWqlQegRcv6pKSk8ujRJzH/e5vX0TFYWtbAzW0106YNxta2Hd7em7M05sw8fBjBxYvXlcudOrUgPPwZr1/HpEmXtrxYq7LyAjTvPiJ8G42t5ERFvaFvHxdatqqPp9cY9PT+2zNbuVzOvLkbGD9B8UgoMTEJbW0tpBIJ8XGf71vwXzSyrM6VKzd58CAcgK1bD2LVom6aNJUqlub8+as8fx4FwOHD5zA3NyV/ASNlmri4BNas9mP4cMXbEsnJKWhpSZFIJcTFZ23MX+P16xhCQ59Qo0b5DD+Pi0tgzZoAhg1XdNx9H69UIs3yayyRSnGfvYnHj58BsH3rUcqVN6ew2Yc+CIkJSUwcu4TQh5EA/H3uBskpKZQqXVSZRi6XM3/eNsaMV1xjZb6QSomPT8zSmC0ta3ySL4Jo0aJemjRRUW/o3duRX35pyPz5EzLM73K5HA+PtUyY4PBRzNrvYv6+63ztf8+oW7MYBQvoA4o3rR6HR2NZ34LhAxR5WKYjpW2rsvx14XGG+6hbs9hnPwNoblmSp8/ecv3mc2QyLZKTU5Xnpaf7fY3OivJiKi1b1cPTa3SG1y8hMYmxY+bz8GEEAOfOXiUlJYXSP5kr0yjKi42Mn6DoVJq2vMjafNEog3xh9Um+aNKkFmFhT7l69Q4A589fRSKRpGk5kMvlzPVYy4QJ9h/FrI1EKs328uLZs1eMHePFq1eKyvKePScpW7Y4+fN/Ur6t8WfYJ+WbKsoLTbyPZCVpNv6pi8Y+rtq69SAREc85fPgchw9/aBpftnwygwbOZvnyKZgWzrxz3a6dR6hbrzLFzE0BGDS4Mw7205DJdHB1HZSlMRcsaMxst+GMHDGXpKRkLIqb4e4+kpCQOzg7LcI/YAH1G1SlX7+O2PZxQkdHm3z5DFm8ZHKa/SxftpMePdsqXyV1cGhPxw6jMTTMg6dn1rwu/CVXQ+7g7LwEP38vAEJDIzAxyY+OTsbZafnyXfTo0UYZr72DNTYdx2JgqI+nZ9a+xlq2rDmTJvdmxJD5pKamUrhwAeZ4DOHp01cMG+jFouVjMLcwZdoMB8aO8kGChLxGefBePDpN50a/XSeoU7cCxYopWiX6D7Kmv4M7MpkOLq5Z88bSewULGuPmNpIRI9xISkqmeHEz3N3HEBJyGycnHwICvNmyZT8REc85dOgvDh36S7ntunUzlTeInTv/pF69qsob3ODB3bCzm4JMpsP06cO+K8azFx6zauM/+C63ITEpldfR8Qwau4/IpzFMn9ycfdt6IpfLOXz8Huu3XAZg5EDFDXnhcsX3s4SFMWER0RnuX6YjZegfdeg3QtESGXw2lJ6dqxK4uQdXrj7h1t0XGW73tbZu/fMz5YUjgwa6sXz5ZCwsCjNj5mBGjfAECRjlNWDx0klp8sWunUc/KS864WA//V15kbXDCyjKi5GMHDHno/JiNCEht9+VFwsxMcnPosWTme66jLi4eHRkOvj4OKKrK1PuZ+fOQ9SrV+WjfNEVezsnRczTh37u8FlGUV4sxs9/PrVrV2TgoM7Y2jqhraWFiWkBFi2elCb98uU7Pykv2mPTcQwGhnmyvLzQxPuI8G0k8k97ZGax1NRUnj17homJSYZ9DDKSIr+qypBUQirRyjxRDiKXZ/y8PydLTH2TeaIcRk9LNW+xqErZ2gfVHcI3+995zRt9XSpRzdtCqiKXa968hXI0r4zTklTO1uP1PJ59UzRtbqae76lKWpEmT1a0PFy5coXWrVszbNgwfv/9dy5fvqyKwwmCIAiCIKSjksdVjx8rnrvPnz+flStXUrJkSSIjIxk7diybNm1SxSEFQRAEQRDSUGmfHC0tLUqWLAlA4cKFP/tKpCrJ5XKmOC6iTNniOPRTDNEfHf0W295OzJw19LPDd+cUhw+fZeKEhVz8Z4u6Q8nUpo378PUNQk9PRunS5ji79FfL6+xfsjfwNOvXBiFBgp6+jImTe1OpcimWLvLj4IFzSKVSKlYqifM0uzT9GnISuVyOo+MCypYtQb9+Nio9VsumpfFwbUWNZsvTrJ88xpKSFsYMGL0XAD1dbWY7W1GxvAkSqQQP7zMcPvFhLJyJIxvx98Uwzl8K5+yf/bj30UjGs7xOce5iGFUqmjJlbGPy6Okg1ZKwYv0/BAbdBBSvsLtMaEJeQ11SUlJxnn2Ma/97lqXnqigrFr8rK6yJj09gxvTVXA25Q6pcTtWqZXF26fefO6eq0qZNe9m6JQiJRIKFhRkzZg6jYEFjdYf1WYrpYD68CfphOphVFCpkrL7AMqDp95AvEa+Q/0cxMTHY2NgQFhbGjh07SEhIwNXVlaJFi2a+cRa6e/cxDnbTOHDgjHLdiRMX6dZlIvfuh2drLP/FgwfhzHVfl24gu5zo3NkQVq3yY+26afj5e9GkaU2muixVd1hpPLgfwfx521iyYhzb/WbQf6A1Y0Z4c/7vGxwIOsfWndPZFTCLmJg4tmw6rO5wM3T37iP69nUiKChY5ccqYZGPSaMaIfmklGjbsgzt21ZIs27EwLq8jU2iTRdf7Ib4M21SU8xMP7yK27CuBaf/fkT1KmacvxSunOLButdWzr17pXzR3F/xXv431r228seIQCaPtqSERT70dLVZu7g9Kzf8Q/teW1m8+jyeM1tn6bkqygpXDhz40Kl7+bLdpKSk4BcwD/+AeSTEJ7JyhV+WHjcrXL16RzFVwta57Nm7iBIli7Jw4fcNGaBqiulg5uPnP5/tOzzeTQfTP8dVcDT9HiKoqJKze/dutm7dyty5c6lWrRoSiYRy5crh5uamisN91hbfIDraNE8zwq7vxv24zRmOqUnOHnI7Lk4xh9WkSQ6ZJ84Brl27S4MG1ZQjtLZqVZ9jxy6kGx5dnXRk2kyd4aCcnqFi5VI8f/6axMRkEhOSSIhPJDkphcSEJOVUGjmNr+8+bGxa0LatpUqPo6erjeeMX5g9P21l6qeS+elvW5NFq9JOudCq2U9s978GQERkDKfPPqJtq7IAlCldgEdhr0lMTKFm1SLkM9Jly6pOBPh2p2cnRUdLmUwLn5V/c+bvRwA8efqWV1HxmJkaYlm/OKGPX3Pi9EMAjpy4z8hJQVl6vlt8D7wrKxoo19WuXZFBgzohlUrR0tLi54qlCA97nqXHzQqVK5fh4MFlGU6VoAk+nQ4mJ9Hke8jXEK+QfweZTEbVqlWVyz169FDVoT7r/UyxZ//6MPDbilVfP5qlOk11WUK3bq0pV76EukP5KlWqlmXTpv2EhT2lWDFT/HYfJSkpmaioNyqbJ+dbFStmonwlXC6XM899M82satDIsgr1G1aidYsx6OhoU7KUGV26NldztBlzcVG8jnr27BWVHmfGlOZs3X2Vm7c/3NTz6OvgMb0VE10PU+Vn0zTpixQ2JCLyw4BuT57GYGaqGKywZdPSymkcUlJSOXrqAUtWn8ekYB42LuvI0+exHD5xj50BHwaJ69axEnny6HD56hNsu1Xj+YtYZjtbUaFsIaLfJDLXO+MJIP8rJ5c/gLRlRSPLasr/Dwt7xob1+3CdrppZ6L+XYqqEszhN8UEm02HECNXM2J3VFNPBBLBrt6e6Q8mQJt9DBAWNHQzwR7bZdz9a2lp06txS3aF8tTp1KjFkaFeGD3enc6fxSKQS8uUzREcn57WIxMYmMH70Yh6FPmXqdAf8dp0k7PEzjpxcyJGTCylmbsK8uTm/D5Sq9OxchZTkVHYG3kizfrZzCzZu+5fbd1+m20aSwcP91BTFY9ZmliU4HvwAgMWrz7No5d+kpsqJfPaWrbuv0ap56TTbDehbixED6zFw9F4SElLQ1pbStFEJtu2+ho3tdjZuv8Kqhe2Q6WRP8XXt6l369HamZ682NGteK1uO+V+0bFmfs+d8GTa8B3/0m6qWPpDfKqPpYITsI5Vk35/azlF9hxY+x8/vGFdD7tCh/SgGDphBfHwiHdqPIjIy/c0lp3gbE0edOpXYvduTnbs8+OUXRbP/+1mcc4qI8Bf07TUDqZaUVesmYWRkwJHDF/j19wYYGOgjk+nQqUszzv99I/Od/aBs2v1MlUqFCfTtzqqF1ujpanPYrw9tW5bBvmd1An27M3JQfWrXKMrKhe0AiHjyBtNCeZT7KGxiwJOnMZgWMiAhIYXX0YpRX/t0q0qRwh/yhESCcmRjmY6U+bNa83vrcnS138H/3rUiPX32lnsPXnHlmmKE6iMn7qOlJcWi2PdP9ZCZ/ftO06/fDMaM6cXAQart5P1fPXwYzsULH0+V0DLDqRJyosymgxGE76WxIx7/yHbs9FD+/+PHkVi3G4l/wAL1BfQVnj59ib39VPbu88bQMA9Ll+zgt98aI5HknO77r6NicOg7m/YdLBk0tKNy/c8VS3Lk8EV+t26ElpaUI4cuUrXaT2qMVL06992u/P9iRfKyb1tPWnbcmCaNze8VaNOijPLtqsMn7tOtY2WmzjmOmakBjRuWYMnq87RsWoqjJ+8rt6tVrSglixszw+Mk+Yx06dK+IjPmnQTA270tWlIp3Rx2EBefrNzmxJmHTBplSaUKJlz73zPq1CiKXC7nUXjGoydnlYMH/mL2rDWsWuVM5So5Nz8opkqYh7//QvIXMGLPnhPppkrIiRTTwURQo0aFzBMLKiGV5PyXWr6XqOQIWaJU6WL0729Dt64TSU2VU7PWzzg7/6HusNLYvvUoTyJecPTwPxw9/I9yvc+y0axavoeO7RyRyXQoV96Cyc62aoxU83gvP4erYzP2b+uJVEuK+8LThIZF06JpaVzcPsw6Pn3ucWZMtmL/tp5oa0vZtP1fTp97RM1qRWjRpDT3Hr5i2+rOyvRzfc4QfDaUIeP24TqpGfr6OiQmpjB0/H4SE1U7Cu/8+ZuRy+U4O394S7BmzQo4u+SsfF27diUGDeqCre1ktLS0MDUtwOLFkzPfUM0ymw5GELKCyqd1+C/EtA6qJ6Z1yB5iWgfVE9M6qJ6Y1iF7ZPe0Dn8EH8+2Y62ybJZtx/qY6JMjCIIgCMIPSbQTCoIgCEIulBtaOXLDOQqCIAiCkAuJlhxBEARByIVyw9tVoiVHEARBEIQfkmjJEQRBEIRcSMxCLgiCIAiCoKFEJUcQBEEQhB+SeFwlCIIgCLmQeFwlCIIgCIKgoURLjiAIgiDkQrmhlSM3nKMgCIIgCLmQaMkRBEEQhFxIDAYoCIIgCIKgoURLjiAIgiDkQrnh7SpRyREEQRAEQW2SkpKYPHkyYWFhJCYmMnjwYMqUKcOkSZOQSCSULVuWqVOnIpVKWbRoEcePH0dbW5vJkydTtWrVL+5bVHIEQRAEIRfKKf1VAgMDMTY2xsPDg6ioKDp06ECFChUYNWoU9erVw8XFhSNHjlC0aFH+/vtvduzYQUREBMOHD2fXrl1f3Leo5GQRCVrqDuGbSCSaFS+ArlY+dYfwzVLlSeoO4Ztc+7uhukP4ZhVanFN3CN/s9tGm6g7hm6SSrO4QvplE3N40Rps2bWjdujUAcrkcLS0trl27Rt26dQFo0qQJp0+fplSpUlhaWiKRSChatCgpKSm8fPmSAgUKfHbfOaUiJwiCIAhCNpJKsu/vSwwMDDA0NCQmJoYRI0YwatQo5HI5EolE+fmbN2+IiYnB0NAwzXZv3rz58jl+91USBEEQBEH4DhEREdja2tK+fXvatWuHVPqhevL27VuMjIwwNDTk7du3adbnzZv3i/sVlRxBEARByIUkEnm2/X3J8+fPcXBwYPz48XTu3BmAihUrcu6c4lH0yZMnqV27NjVr1iQ4OJjU1FTCw8NJTU394qMqEH1yBEEQBEFQo2XLlhEdHc2SJUtYsmQJAFOmTGHmzJl4eXlRunRpWrdujZaWFrVr16Zbt26kpqbi4uKS6b4lcrk8xw15mCK/qu4QvpmWRKbuEH54clLUHcI3k8tT1R3CN0mWx6s7hG9WqeU/6g7hm2lax+MUDcwXmtjxWCqpmK3Hc7xwJNuO5Va7RbYd62PicZUgCIIgCD8kUckRBEEQBOGHpHnteYIgCIIgfLfc0MqRG85REARBEIRcSLTkCIIgCEIuJM3k1e4fgWjJEQRBEAThhyRacgRBEAQhF8psuoUfgWjJEQRBEAThhyRacgRBEAQhFxItOYIgCIIgCBpKtOQIgiAIQi6kpe4AsoFGV3ICA0+wdnUASCTo6+kyeYoDlauUSZMmKOg0y5fuBCB/fiOmug6kZMmiRL16w/Dh7kS/fkubtg0ZPKQLABcv3mD7tj9xnztSJTEfP34eT88NJCYmUb58SWbPHoGhYZ40aQICjrF69W4kEgn6+rpMmTKAKlXK8upVNMOGzSY6OoY2bSwZOrQ7ABcuXGPbtgN4eIwVMb8jl8txdPSmbNkS9OvXIYNzuoCX50blOc2aPQxDwzyEhkYwZrQnCQmJ2NlZ06lzSwACA45z714Yo0b3Ukm872Oe7LiIsmUtcPgkZn//Y6xft0e5/OZNLJGRLzh2fCWxsfGMHeNJ/PuYOynmiAkMPKGIeVRPlcV85PB5pkxaxtkLqz+bZpH3Dl6/jmGKsz0AUa/eMHL4fKKj39K6TT0GDbEB4J+L/2PHtqO4zR2SZfG1sizJiL41kcvh9ZsEpnieJDT8DT2tf6brbxXQk2lx9dZzJs87SWJS+nnG/JZ1QE+mTVKy4rPAI3dYte1fqlUwYebYxgDMW3WeE+ceATCkdw2evYxlx/6bWRK/pn33AgNPsnZ1IEj4qEz+KU2aTRuDWL58F4UKGQNgYKDPJt8ZJCYmMXL4PJ48eUHVamVxnT4QgNDQJ7hOW8HqNZlPxvhfKb57PpQtWzzdd09xXsdZszoAiQT09HSZMuUPKlcpw6tX0e/uIzG0aduIIUO6AnDx4nW2bfuTuXNHqSxm4eto7OOq+/fCmOexgRUrnfHz92Tg4E6MGOGRJs3z51G4TlvB0uVT8A+cT8tW9Zg1YxUAe/acpEmTmvgHerF/fzAxMbGkpKQw38uXceNsVRLzy5evcXRciI+PIwcPLsPCwox589alSXPv3mM8PNayapUrAQHeDB7cjeHDZ7+L+ThNm9YiMNCH/ftPKmP28trA+PH2IuZ37t59hF1fFw4Enf7sOU129MHbZyIHDi7BwqIwnvM2AODrG4S9Q3t27fZk2bIdAMTExOHru5+BgzqrJF5FzI+xt5vKgQMZx9yhQ3P8/L3w8/di+465FCpkjJPTHxQqZMxm3yDs7Nuza9c8li9TVOjfvo95YCeVxfzwQQSeHptJ/cwkpE+evGDMyAWsX7svzfp9e0/TuGl1dgfM4cD+v97liVQWzt/GmHE9siw+XZkW8xybMXTqYawH7ObIXw9xHtaQXxqXxLZjJfqO209bh53o6Wpj17lKuu319bQpXtSIdv13YT1gN9YDdrNq278ADOhRDWevYOwnBDHSrhYARUwNaFizaJZVcDTtu6cokzeyYuUU/PznZVgmA1y+dJOJE/vi5z8PP/95bPKdAUBw8GUKmxXEL2AeEeHPuH0rFIC57hsYP0E1ZTIoygt7O5fPfvfu3wvDQ3mvmc+gwV0YMcIdgL17TtK0SU0CAhd8ch/ZpLL7SFaSSuTZ9qe2c1Tbkb+TTKbDjBlDMDHND0DlymV4/jyKxMQkZZpChYw5FbyaIkUKkZycQnj4M4yN8yq3j49PIDk5hZTkVKRSKVu3HKS5VW3lPrNacPAlqlQpS8mSRQHo0aMte/ac4OOJ4GUyHWbOHI6paYF05yWT6RAXp4g5+V3MW7YEYWVVT5lexKyoqNjYWNGmbaMMPz8dfJkqVcooz6l7jzbs2XMSuVyuyBdxCSQkJCKVKr4eixdvxd6+Pfr6uiqJF2CzbxAdbaxo0ybjmD+2apUfBQvmo1v31sCHvJyQkIhEGfM2lcYcF5eA48QljJ/Y+7Np/HYdp2at8tja/Zpmvc67a5ycnEJKiiJPbNt6iGbNa2bpd09LKkEikZDXQAaAgZ4OCYkpdGhVltU7Qnj9JgG5HFzmBxNw6Ha67atWMCE2LomVbm3Yu6oTk4fUR1emaOBPTEpBT0+bPPofWnkmDarP3BV/Z1n8mvbdU5TJgz4qk39KVyYDXLp8k317g7HpOJ7+/WZy6+ZDxfY6inwsl8uJj09ER0eb48cuUrhwASpUKJnl8b6n+O61+Ox37/295sM1/intNVbeR1I+uo/UUVn5Jnwbja3kFDM3pWkzxS8ouVyO+5x1WDWvjUymkyadjo42V0Pu0LzZAHZsP0yv3ooCt511E+7cfkS3rpPoa9eOhIRE9u0Nxtb2d5XF/OTJM8zMCimXzcwKERMTy9u3ccp15uaFadasjvK83NxWY2VVF5lMB2vr5ty5E0qXLmOxt29PfHwCe/eeoG9faxHzR1xcBtC+Q/PPfh7x5Plnz6lPn9/Yt/8Uffs6M35CX+7efcTtW6GfrTBlFWeX/rRv3yzTdK9eRbNubSCOkx2U63r3+ZX9+4Kx6zuV8eNtuXv3Mbdvh9KmTUOVxTt96mq6dG1BufLFP5tm8NBO9LZti5ZW2mLm93aNuHvnMT27OdPH7lcSEhLZv/cMvW3bZmmMsfHJuMwPZruPNcHbe9K7Q0XmrvibUub5KGisz+o5bdiz0obhfWsSHZOYbnuDPDqcvRzB8GmHsRnsT1FTQ8b1V+TzxRsvMaJvLTwnN2fOsrM0rFmUt7FJ/Pu/Z1kWv6Z999KXyevTlcmxsfGULlWMAQNt2O3ngU1nKwYOmM3bt3E0bFQVHR1tbDqOp07dShQtZsKyZbsYMbK7SuJ9z9llwBe/e8XMTWnWrPZH57WW5s3rIJPp0M666bv7yATs7KxJSEhk796T2Nq2U2nMWUUqyb4/ddHoPjmg+NJMdlzEkyfPWbHSOcM0lauU4VTwak6dusSgQbP589ASjIwMWOgzQZnGxXkpQ4d15fr1eyxbshM9fRljx/XB3LxwlsWamppxk937FoOPxcbGM2nSAp48ec6qVdMAyJNHDx+fyco0Tk4+DBvWg+vX77JkyVb09HQZN84OCwuzXB1zZlJTM368IpVKMTUtwJo1rsp1A/pPZ5KjA8ePX2DL5iCMjfPiOLmfskUwu23f9idWVnXT5EtT0wKsXjNVuTxgwEwmTrJXxLzlgCJmR4csi3nr5kNoaUvp2KkZYWHfflPPk0eP+d6jlcvTnFcyZFgnblx/wPKlfujpyxg9tgfm5qbfFWe5UvkZZluDtg47CA1/g23HSixybYm2tpRGtYox2PlPEhJTmDupKWP61WbW4rNptj96JpSjZ0KVy0t9L7N4ektmLT7LnYdR9Byl6COlrSXBd0E7Bjv/See25WllWYLIZ7HMXHwmw34+X0tTv3uKMnkxT568YMXKKWk+y5NHj5WrnZTLbds2ZNmSnVwNuUu9+pWZMXOw8rNlS3dhY9OcV6/e4DRlCQCDh3ShYsVSWRrv11KclzcRT16wcqWif1CePHp4+0xUpnF2XsywYd25fv0eS5dsR19fl7HjbLP0PiJ8G41tyQEID39Grx6T0dKSsm69K0ZGBmk+fxr5kuBTl5TLjRvXwNBAn0ehT9KkCwm5Q/TrGBpZVsfdbR0u0wbQx/Z3fLy3Zmm8RYqY8OzZK+VyZOQL8uUzJE8evU/O6yndu49HS0vKhg2zMDIyTLevf/+9RXR0DJaWNXFzW8W0aUOwtbXG29s318ecmaJfeU4HDpyhVGlzypSxYI7bGhYsnIClZQ3WrwvM1ng/FhR0mo42Vp/9/OCBM5QuVYwyZSxwn7OOBQvGY2lZnfXr93x2m28V4H+CayH36NzRkSED55IQn0jnjo48ffoq840/cTXkLtHRb2nYqCpz52zEeaoDvfu0YbH3zu+Os3Edcy5ejSQ0/A0AmwKuU65kfpKSUzkU/ICY2CSSklMJOHSHGhXT34SsGhSnTtUPFQCJBJKT01da+naqzL6jd4mPT8ahSxUGOf1JxLMYrFuW/a74NfG7pyiTnd6VyVPTlclhYc/YtDEozTo5oK2T9j2f8PBnnD59hc5dWrDYZxt97drh5NyP2bPWZGm8Xys8/Bk9ezgi1dJi/frp6c4LICTkNtGv39LIsjpz3NYwddog+tj+jrf3FjVE/HVyQ0uOxlZyoqLe0LePCy1b1cfTawx6eun7HiQkJjJ2jBcPH0YAcO5sCCkpKZT+yVyZRi6XM2/uBsZP6AtAYmIS2tpaSCUS4uMSsjRmS8saXLlykwcPwgHYujWIFi3qpTuv3r0d+eWXhsyfPyHD85LL5Xh4rGXCBIePYtZGKpUSHy9izkwjy+qfnNNBrFrUTZMmLi6BNav9GD5c0VSenJyClpYUiVRCXDbH+97r1zGEhj6hRo3yGX4eF5fAmjUBDBveDfgQs1QizdK8vGX7TPz2zGWnnxtLlk9AV0/GTj83TL+xP41cLsfTYzNjJyjeWHv/3ZNIJFmSJ67dfkHdakUomF8fgFaNSvD4yRu27LlBm6allf1rWlqW5N+b6VukzEwMmDioHroyLaRSCQ5dqrDv2L00aUwK6NPKsiS+AdeRSiVIALlc0Qqjr/d9DeWa9t1TlMlTadmqHp5eozOMJU8eXbwXbuHffxV9oE6c+If4uASqfPJWrMfcjYwb1xupVEpiYjI62lpZno+/VlTUG2z7ONGqVX28vMZ+/hrPXc+ECXbAJ3lZDTELH2js46qtWw8SEfGcw4fPcfjwOeX6ZcsnM2jgbJYvn4KFhRkzZg5h1AgPkEgwymvA4qWOaTpj7tp5hLr1KlPsXdP4oMGdcbCfhkymg6vroCyNuWBBY9zcRjJihBtJSckUL26Gu/sYQkJu4+TkQ0CAN1u27Cci4jmHDv3FoUN/Kbddt24m+fMbAbBz55/Uq1dV2QQ6eHA37OymIJPpMH36sFwfc0ZCQu7g7LQI/4AFFCxozGy34YwcMZekpGQsipvh7p52yIDly3bSo2db5eu6Dg7t6dhhNIaGefD0VM1r75+6GnIHZ+cl+Pl7ARAaGoGJSX50dDL+2i5fvosePdooY7Z3sMam41gMDPXx9Byj8nifPn3FkIFzWbJ8wldVeHbvPE7dehUpVswEgIGDOvKH/SxkMh2mTv/ju+M5eymcVdv+xdfrNxKTU3kdncAg50PcC40iX15d/Jd1RKol4frt58xZqnhU1aPdz1QuV4gpnqfYsucGFkXyErC8I1paUs5eDmfxxn/SHGPCwHp4rb5ASqqcmNgkDp1+wL7VnXgRFc+wqYe+K35N++5t3frnZ8pkRwYNdGP58smYFi6A1/wxTJu6gqSkZAwN9PFeND5Nv50zZ/5FX1+XatXLAWBn346pLssBGD1WdUM4fEzx3VuMn/98tm498O68znL48IdHmmvWun50jQ9Tr16Vj+4jXbC3n6q4xq6DMzyGkD0k8o+76ucQKfKr6g7hm2lJZOoO4YcnJ0XdIXwz+Wder86pkuXx6g7hm1Vq+U/miXKY20ebqjuEb5KigflCooG/4aWSitl6PM+Q76uIf4uxVVpl27E+li2Pq16+fEkOrEsJgiAIgvADU0lVd9euXURERNC8eXPGjh2Lrq4u8fHxTJ06lYYNVfdaqyAIgiAIXyc3TNCpkkrO5s2b2bhxI4MHD2bp0qWUKlWKyMhIhgwZIio5giAIgiBkC5VUcnR0dMiTJw8GBgZYWFgAULhwYSSS7K82yuVypjguokzZ4jj0aw9AdPRbbHs7MXPW0HRzXeUkivmXFrybf8lG3eF8FU2Lec6cNRw8cIZ8+RSv3ZYqVYz5C8arOarPO3ToLIt8tiGVSjAyMmTGzCEUL559Ywx9jT2BwaxbsxeJRIKengzHKX2pVLk0K5f7ExhwipSUVH5v14jBQzuppExo2agEHpOaUaPdeuW6vAYyNi/4HUePk1y99RwA04J5mDOhKYUK6COVSFix9QqBh+8ot/GZ2gLv9f9w+4HiNW4jQxn+yzoyd8XfHDh5H4BalQszZWgDtLWkJCQm4+p9hqu3nqOjLcVleENqV1H825z4+xFzV/z92bFvsoImfPcU5fHid+WxNfHxCcyYvpqrIXdIlcupWrUszi79MnyDSd1u3XzIzJkriYmJRSqV4uo6mEqVf8p8wxxMndMtZBeV9MmxsrJi8ODBlC1bloEDB7Ju3Tr69etH/fr1VXG4z7p79zEOdtM4cOCMct2JExfp1mUi9+6HZ2ss3+ru3Uf07etEUFCwukP5apoY86VLN/H0God/wAL8Axbk6ApOfHwCEycsxNtnAn7+XjS3qsOsWavUHVYa9++H4+WxmWUrJrLTz40BgzowasR8Tp64xJ8Hz7Ft5yz8At35+9x1Dh44l/kOv1GJYkZMGlQPyUft8E3rWbBrSQdKFzdOk3ZsvzpcufEU6/676TcpCNdRjSj07nVzmY6UEsXyKSs4AB6OzTA0SPuCwbzJzZm74m+sB+xmxdZ/mTupGQC9O1SigLEev/bbye9/7KJmpcL82qx0lp/ve5rw3VOUx64cOPDhLbDly3aTkpKCX8A8/APmkRCfyMoVfmqMMmNxcQn0+8OVfn90ZLefF4OHdGH8+PnqDkv4CippyRkwYAB///03wcHBFC1alBcvXtCnTx+aNWumisN91hbfIDraNKdIkQ9Do/tu3I/bnOGMG5uzM6iv7z5sbFpQtGihzBPnEJoWc2JiEjeu32PtGn9cpz2heAkzHB37UbSoibpDy1BKSipyuZyYN7EAxMbGoSvLWW/1yWQ6uM7or5y/qFLl0jx/HsWfB8/x628NlQPZdbBpyr49wbRpm3U/fPR0tfCc3JzZS8/iNeXDgIm2HSsxwf04853SDqIo1fowr5WerjYpKXJS370g0bBmMc78E6ZMO7R3Df539yUG+mmnjdGSSshn+G5uLH0dEhKTAVi7M4SNfleRy8HYWA8jQxlR0aobL0UTvntbfA+kK49r11YMIfB+FOefK5bizu1H6grxs06fvkxxi8I0baqYtuLTUcc1leiT8x3q1q1L3bp1M0+oQk4u/QE4+1eIct2KVRlP/ZDTuLgoxug5e/aKmiP5epoW89PIl9SvX4XRY/pQqlRR1qz2Z+iQ2ez281LLo9XMGBjoM3XaQHr0cMTYOC+pqan4bp6t7rDSKFbMRDnujVwux8N9E82b1+L5sygaNaqqTFe4cAEin7zM0mPPGNOYrXtucPNu2v32m3Qgw/SeK8+zeWE72jQtRQFjfeYsPcvLKMWr0i0alSDgkOLRlWXtYtSpVgSHiUFsmJd2slFHj5Msmd4Kp2EJ5DXUxW78fuVnySlyxvWvQ+8Olbh68xkXQiKy8nTT0ITvnpOLYuyjj8vjRpbVlP8fFvaMDev34Tp9YLbHlpkHD8IpVCg/U6Ys4ub/HpDXyEAjZhkXNHjEY0H4XuYWhVmx0oXSpYshkUhw6NeB0NAnhD1+qu7QMnTr5kOWLtnB3n3enDy1moEDOzNyxNwcOTxDbGw8Y0cv5NHDSKbN6J9hXxSpVtYVPz2tfyYlJZWdB2599TaeU5qzatsVLLtupq39Dvr3qEbVCiZIJFD9Z1P+uRZJEVMDJg2qz7jZx9KdQ8H8+swc25heo/fSuNsWxs0+hs+0lmlGOp638jy1rdcT9iQG11GWWXa+P5prV+/Sp7czPXu1oVnzWuoOJ53k5GROnrxI166/sHPXPHr3/pVBA2emm2Fd02hl45+6iEqOkGvd/N8DAvyPpVknl8vTzaOTUwQHX6JGjQrKjsY9e7Xh9u1HREW9UXNkaUWEP6dPz2loSaWsXu+EkZEBRYoU5NmzKGWap09fUbhwgSw7pk2bclQpb0LgChtWubVBT6ZF4AobTAvmyTB9fiNdalUuzLa9/wPgYVg0Zy6EUaeqGdV+NuXqreekpspp27Q0+nrarHFvS+AKGyqXN2HCwHr0aPczdaqYER4Zo+zIfPj0Q5KTU/mpuDE1KxWmpHk+QNGis+vgLSqVzbmPktRp/77T9Os3gzFjejFwUM7sMG1qUoBSpc2pVk0xCnOLFvVISUnl0aMnmWwpqJuo5Ai5lkQqYdasVTx+FAnAls1BlC9fEjOznHkzqljpJ86fv8bz51EAHDn8N+bmpsqh5XOC11Ex2NvOoGWrOnh4jUBPT9FfpXmLWuzbe5rY2HgSE5MI8DuJVcvaWXbczkMC+K3fLqwH7OYPxwPEJ6ZgPWA3T1/EZpj+VXQCT56/pU1TxYzW+Y10qVPVjCs3ntGqUUkOn34IwJodIbTovQ3rAbuxHrCbqzefMXf5ObbsucH/7r2kbMn8yspMtQom6Otq8+DxaxrUKMqUIfXRkkqQSMC6ZRnOXsrZLzuow8EDfzF71hpWrXLm93aN1R3OZzVuUpPwsKdcu3oXgPPnryGRoPH9cnLDBJ2aN+61IGSRcuVK4OTUn8GDZ5GSkoqZWUE8vbJnXqr/on79Kjj060BfW2d0dLTJly8vixZPUndYaWzbepiIiOccOXyBI4cvKNevWjOZlq3q0LOrM0lJyTRvURvr9uq9qQ2a8icuIxoytE9NUlPlLNtymQshT3Aa1gDv9Rcz3f7B49e4LAhm0bSWyOVy4hOSGTr1EDGxSazYeoUpQxuwZ1UnUlPlXLz6hHmr/s6Gs9Is8+dvRi6X4+y8VLmuZs0KOLt8/9xlWcnEJD8+iyYxffpyYuPikeno4O0zEV3dnNXxX0hPzF2VRcTcVaon5q5SPTF3VfYQc1epnpi7KnMr/ncw2441oELrbDvWx8TjKkEQBEEQfkiaV9UVBEEQBOG7aeW8kTKynGjJEQRBEAThhyQqOYIgCIIg/JDE4ypBEARByIVyw7QOoiVHEARBEIQfkmjJEQRBEIRcSLTkCIIgCIIgaCjRkiMIgiAIuZBoyREEQRAEQdBQoiVHEARBEHIhLUmOm9Upy4mWHEEQBEEQfkiiJUcQBEEQcqHc0MqRG85REARBEIRcSLTkCIIgCEIuJN6uEgRBEARB0FCiJUcQBEEQcqHc0JKTIys5UomOukP4ZvEpL9QdwjeRSfOpO4RvJpXkyOz6RRKJlrpD+CYyDfzu3TraRN0hfLNilX3VHcI3CbvaS90hCMJ/onl3DUEQBEEQvpsYJ0cQBEEQBEFDiUqOIAiCIAg/JPG4ShAEQRByodzQ8Vi05AiCIAiC8EMSLTmCIAiCkAuJlhxBEARBEAQNJVpyBEEQBCEXEi05giAIgiAIGkq05AiCIAhCLqQlWnIEQRAEQRA0k2jJEQRBEIRcSCqmdRAEQRAEQdBMoiVHEARBEHKh3NDKkRvOURAEQRCEXEijKznHj5/Hut1w2rQezMgRc4iJif1s2sOHz1KrZjfl8qtX0fTuNYl27YazZPFW5fqLF64zYbyXymK+fesR/fq60dXGhR5dpnH92oPPpl3ss5vZMzcql6OiYrDvM5tO7Z1YvjRAuf6fi7eYPHG5ymKWy+U4TvJmzWr/L6Y7fPgctWv1VC6/ehVN795TsG43kiVLtivXX7x4nQkTFqgoWs10/Ph52rUbTuvWgxjxmbwcEHAMa+vhtG8/gu7dxxMSchtQXOdevSbRrt0wFn+Uly9cuMb48Z7Zdg45naaUF/Y963Fyz3D+3DmIxXM7Y2ykr/ysqJkRF46MJb9xni/uI6N0vbvU5ljAUAI3/YFFMWPl+g1LelGmdKEsiV0T87EmxpxVpJLs+1PbOarv0N/n5cvXTHb0xtvHkQMHl2JhYYbnvPUZpn3wIJy57muQyz90stqz5wRNmtYmMNCb/ftPERMTS0pKCl5eGxg33k4lMcfFJTDoj3nYOfzK9t3TGTDIGscJy9Kli3zykrGjFrFh7YE06/ft+QvLJlXZ6T+DA/vPERMTR0pKKt7zdzJ6XLd0+8kKd+8+wt7OhQMHTn8x3YMH4XjMXZfmGu/dc5KmTWoSELiA/fuDldd4vtcmxo2zVUm8mujly9c4Oi7Ex8eRgweXYWFhxrx569KkuXfvMR4ea1m1ypWAAG8GD+7G8OGzAdiz5zhNm9YiMNCH/ftPpsnL48fbZ/8J5UCaUl40rFOSoQ6N6PbHen7pvIyjp24xd1o7ADpbV2P3egeKFDb64j4+l25oP0tad17GKt+z2PWoC8BvrSpy+94z7tx7/t2xa2I+1sSYhW+jsZWc08GXqFKlLCVLFgWge4+27NlzIk3BBIqKxYTxXkya1C/NeplMh/i4BJKTU0hOTkUqlbJlSxBWVnUxNS2gkpj/On0V8+KmNG5aDYBmVjXw8BqaLp3frpPUrFWOPnatP4lZm/j4RJKTU0hJUcS8fetRmjWvjomJsUpi3uwbREebFrRp0+izaeLiEpg4YQETJ6X9UstkOsTFK65xSnIKUqmUrVsO0tyqjsqusSYK/iQv98ggL8tkOsycOVx53SpXLsPz51EkJiYprnOGebmeuM7vaEp5UaVSUU6dvUdEZDQA+w/foGWz8hQ1y0drqwr0Gez7xe0Lm+T9bLrk5BRkMm3y6MtISkpBT0+HQXYN8VpyPEti18R8rIkxZyUtSfb9qYvGVnIinjzHzOxDE6uZWSFiYmJ5+zYuTbqpLovp1q015cqXTLPe2roZt++E0rXLWOzs25MQn8jevSex7WutspgfPoykUKF8THVaTY8u0xjYz4OUlJR06QYN7UCvPr+gJU37z/Nbu4bcvRNGr27T6dO3NQkJiQTtO0sv219UFrOzywDat2/2xTRTpy6la7dfKF+uZJr17aybcuf2I7p1nYCdnTUJCe+usW07lcWriZ48eZZpXjY3L0yzZnUAxeNDN7fVWFnVRSbTwdq6OXfuhNKly1js7dsTH5/A3r0n6KvCvKxpNKW8uBwSRqN6pShWJB8A3TrUQFemTXJyCv1HbeP2vWdf3D7y2ZvPpnNbcJida+34rVVFVm06y4j+jVm39W/exiZmSeyamI81MWbh22js21WpqakZrpd+VDHY7LsfLW0tOnVuxePHkWnS5cmjh4+Po3LZ2WkRw4b14Pr1uyxZsg19PV3GjeuLuYVZlsWcnJRM8Ml/Wbl2IlWr/cSxI/8wdKAXB454IpPpZLp9njy6eC0crlx2dVnDoKEduHH9ISuWBaKvJ2Pk2K6Ym5tkWcyZ2bw5CG0tLTp1aknY46efxKuHt89E5bKz82KGDevO9ev3WLpkO/r6uowdZ4u5eeFsizcnSk3NeKwKqTT9b5DY2HgmTVrAkyfPWbVqGvA+L09WpnFy8vkoL29FT0+XcePssMjCvKxpNKW8OHfxIV5LT7B6YXdS5XK27b7Eq6hYkpLS/xj6VvsP32D/4RsAlLDIT61qFsxbfAzXiW2wKJafsxcesGLDX/95/5qYjzUxZuHbaGxLTtEiJjx79lK5HBn5gnz5DMmTR0+5zs/vCFdDbtOh/UgGDphOfHwiHdqPJDLyRZp9hfx7m9fRMVha1sDNbTXTpg3G1rYd3t6bszRmE9P8lCxVhKrVfgKgeYuapKbKefzoy7/OMnI15B7R0bE0bFSZee5bcHKxpWefX1jisztLY86Mv99RQq7epmOH0QwcOIP4+EQ6dhjN08iXadKFhNwm+vVbGllWZ47bGqZOG0Qf29/x9t6SrfHmREWKmPDs2SvlckZ5GSA8/Cndu49HS0vKhg2zMDIyTLevf/+9RXR0DJaWNXFzW8W0aUOwtbXG2/vLjzl+dJpSXhjkkXH2/APadF3Or91WsO/wdQBevY7LZMtvM3V8G6bPO4hl/dIYGOjiMGILzSzLUNLivz9i0cR8rIkxZyWpRJ5tf2o7R7Ud+Ts1sqzBlSs3efAgHICtW4OwalEvTZodOz3Zs3cR/gELWb7CBT09Gf4BCylcuKAyjVwuZ67HWiZMUPQnSUxMQltbG4lUSlx8QpbGbNm4CuFhz5VvVF28cBMkUMz8295skMvlzJ+3jTHju30UsxZSqYT4+Kxpev5a23d4sGePN37+81m+3Bk9PRl+/vMxLfyhsJTL5XjMXc+ECXZp4pVIJMTHZe011kSWGeTlFp/k5aioN/Tu7cgvvzRk/vwJ6OnpptuPXC7Hw2MtEyY4AB/yslQqJT6L87Km0ZTywsw0LzvX2mFooPj3HTWwKf77Q757vx9r2bQckc/ecO1/T9DV0SI5WdFKJJeDnt5/b9zXxHysiTEL30ZjH1cVLGjMbLeRjBwxh6SkZCyKm+HuPpqQkNs4OykKqq+xc+ch6tWronxkMnhwV+ztnJDJdHCdnr5T8PcoZGLMgkUjmDV9A3FxCchk2ngtHM7r128ZNnAGi5aPwdQ0f6b78dt1kjp1f6ZYMcVjqf6DrOnvMBeZTAcXV7ssjTkjV0Pu4Oy8GD//+V+VfufOw9SrV4Vi5qYADBrcBXv7qchkOkx3HazKUDVCwYLGuLmNZMQIN5KSkile3Ax39zGEhNzGycmHgABvtmzZT0TEcw4d+otDhz48Uli3bib58yveotm580/q1av6UV7uhp3dFMV1nj5MLeeWU2hKeXH3wQsWrQ5m75b+SCUS/r4UitOsfV/cZtzQ5gDMW3ws0/3LdLQYObApfQZtAuDEmbvYdq/LoV2D+efKY/53+2kme/g8TczHmhhzVlLnq93ZRSL/9PWCHEDOTXWH8M0SUl5mnigHkUnzqTuEbyaVaGydXFAhOTmuCMuUeeWsfRSuamFXe6k7hFyiXLYe7XTklyvQWalR4d+y7VgfU8ldIyYmBkPD9M8sBUEQBEHIGXJDS45K+uQ0atSIHTt2qGLXgiAIgiAIX0UllZwKFSpw48YNbG1t+fvvv1VxCEEQBEEQvoM0G//URSWPq3R1dXFxcSEkJIQVK1YwY8YM6tevj4WFBba26hnOPzDgGKtX+yGRSNDT12XKlP5UqVJWLbF8zhbfw2zfehSJRIKFhSku0+0pWFDRse1JxAt695jBDr8Z5M+fV82Rpufvf4z16wKVy2/exBIZ+YJjx1dRqJCx+gL7AcnlchwdF1C2bAn69bNRdzg/nOwuK1pbVWDh7I5UqO8GwK8tf2Z4/ybIZFqERbxmpOPuNK+QVyxfmE3L+lCz+bw0+3Ee9wt/nX/AuYsPuXxiPHfvf5iqYZr7Ac6cf0Cp4gXwnNGB/Mb6vI1NZORkP2W6erVK4DSmFXp6OkS/iWe0kz+hj1+hSpqWlzUtXkFFlZz3fZmrVKmCj48Pb9684fz589y/f18Vh8uUYu6RdezaPR9T0wKcOHGBEcPdOHZ8jVriycj1aw/YsDaI7X4zyJs3D55zt7LYezcurnbsCTjNEp/dPHsape4wP6tDh+Z06KB4yyMpKZk+vafQv7+NqOBksbt3H+HquowrV/5H2bIl1B3ODye7y4pSxQvgPO4XpO86R1StVJSZU37DutcqHodHMW1CGyaObMGk6XvR0pLi0LMeQ/+wJI9++sFDLeuVZq73UerXLsG5iw/pOWBjujQ+7p1YtfEs/vtDaG5ZhpXzu2HVYTFFChuxemF3uvffwNUbEfTrXZ/ZTr/R+91bWKqgaXlZ0+L9GhLRJ+e/sbFJW8PNmzcvVlZW9OvX7zNbqJZMpsOMmcMynHskp6hYqSSBQe7kzZuHhIREnj59hbGxIU+fvuLokX9YtGyMukP8aqtW+VGwYD66dW+deWLhm/j67sPGpgVt21qqO5QfUnaWFXp6OnjP6YTr3IPKdZ1+r8rW3f/wODwKAM8lx1iyRjE5bpWfi/BzucIMGL0t3b7K/WTCw8evSEhMpnaN4hjn08dvgwMHdwzCtptiSgIz07yUKVWIgKCrABwLvkMefR0q/1yE31pV5Gjwba7eiABg0/YLTHU/kO44WUnT8rKmxSsoqKQlp2PHjqrY7X9mbl5YOX6BXC5njttqmr+beyQn0dHR5ujhi7i6rEVHps2QYR0xNc3PfO/hmW+cQ7x6Fc26tQHs2u2p7lB+SC4ugwA4e/aKmiP5MWVnWTF3ajs27bjAjVsfppAoVaIgN25Fssa7BxbFjLlxO5Jp7yobl6+GcflqGOZFjdPtq7VVBQ4eVUzZkJKcyqHjt1i4/ASmhQzZscaOyGdvePY8hsinb9JMPhkRGU2RwkaULlmQuNgklnh05qeShQiLeM20uaqt5GhaXta0eL9GLmjI0dwRj/+L2Nh4Ro10JzQ0gpkzc+YATVYta3HizCIGD+3A4AGen51zJ6favu1PrKzq5vr5qATNpuqyom+3OiQnp7LN71Ka9To6WrRqVp6Jrnv4pfMynj2PwWNa5pM9tmhSjiMnbgOwYPkJ5i89TmqqnCdP37Bpx0XatvhZ+UjsU6mpqWhra/GLVXk8fI7Sussygs/dY9WCbt9/ooKgZrmmkhMe/owe3SegpaXF+s/MPaJOoQ8j+efiLeVyB5smRIQ/Jzo6Vo1RfbugoNN0tLFSdxiC8J9lR1nRpUN1qlUuyp87B7FxaS/0dHX4c6eipeDE6Ts8exGDXC5nm98lalW3+OK+CpvkJSEhmahoRedk+571KGr20WCfEkhKTiEs4jUmhdKei5mpERGR0UQ+e8OFy4+4H6oY1HTL7n+oVKEIerpiAM4fmUSSfX/qkisqOVFRb+jT25FWvzTAa/74DOceUbfnz6KYOG4pr169AWD/3r8oU9YcY+OcVRn7ktevYwgNjaBGjQrqDkUQ/pPsKit+77GSFh2X8EvnZfQZ7Et8QhK/dF7Gmk1nadGkHPnz6QPwa8uKXLka9sV9tbaqwJ/HP4wSX7dmcQbbNwLA2EifHjY1CTxwlYjIaB4+eoV128oANG34E6lyOTduPeXA4RvUqVEci2LG7477M/+7HUl8QrIKzl4Qsk+uqKZv3RJERMRzDh86y+FDZ5Xr166boZx7RN1q1i5P/4Ht6Nd3DtpaUkxM8zPfZ4S6w/omoaERmJjkR0cnV2Qr4Qek7rLi0IlbFDHLx8519kilEh6Hv2acS8AXt/mleXkmTd+rXJ4yax/uU9tx1H8oOtpS1m75m1N/3QNgyPgdzHW1ZuSAJiQkJjNwzHbkcjnXbj7BccZeVi/sjra2Fq+j4xg4drtKz1VQv9zQyiHmrsoiYu4q1RNzVwkZEXNXqZ6Yuyq7ZO/cVf88z765q2oWUs/cVbmhIicIgiAIQi4kfhoLgiAIQi4kkWheK+i3Ei05giAIgiD8kERLjiAIgiDkQmIwQEEQBEEQBA0lWnIEQRAEIRcSE3QKgiAIgiBoKNGSIwiCIAi5UC5oyBEtOYIgCIIg/JhES44gCIIg5EKfmZj+hyJacgRBEARB+CGJlhxBEARByIVyQUOOaMkRBEEQBOHHJFpyBEEQBCEXEuPkCIIgCIIgZIMrV67Qp08fAB4+fEiPHj3o2bMnU6dOJTU1FYBFixbRuXNnunfvzr///pvpPkVLjiAIgiDkQjmpIWflypUEBgair68PgJubG6NGjaJevXq4uLhw5MgRihYtyt9//82OHTuIiIhg+PDh7Nq164v7FS05giAIgiCoVfHixfHx8VEuX7t2jbp16wLQpEkTzpw5w8WLF7G0tEQikVC0aFFSUlJ4+fLlF/ebI1ty5PJkdYfwzWTSfOoO4ZtINPBhbGLqG3WH8M10pHnUHcI3SUlNVHcI3yxZHqvuEL5Z2NVe6g7hm5QecV3dIXyz/y2wUHcI30yWi5sdWrduzePHj5XLcrlceZ8yMDDgzZs3xMTEYGxsrEzzfn2BAgU+u98cWckRBEEQBEG1cvJPXan0Q43v7du3GBkZYWhoyNu3b9Osz5s375f3o7IIBUEQBEEQ/oOKFSty7tw5AE6ePEnt2rWpWbMmwcHBpKamEh4eTmpq6hdbcUC05AiCIAhCrpSTp3WYOHEizs7OeHl5Ubp0aVq3bo2Wlha1a9emW7dupKam4uLikul+JHK5XJ4N8X6TVPk1dYfwH+Tg3JIBTeyTk5SqeX0vRJ8c1dPEPjl6WgXVHcI3EX1ysodMWitbj3fr9d5sO1a5fL9n27E+JlpyBEEQBCEX0ryfut9O9MkRBEEQBOGHJFpyBEEQBCEXkkhyXG+VLCdacgRBEARB+CGJlhxBEARByIVEnxxBEARBEAQNJVpyBEEQBCEX0sCRRL6ZaMkRBEEQBOGHJFpyBEEQBCEXyg2tHLnhHAVBEARByIVES44gCIIg5EKiT44gCIIgCIKG0viWHLlczmTHRZQta4FDvw7pPt+0cR++vkHo6ckoXdocZ5f+GBvnJTT0CWPHeBKfkIidnTWdOrUAIDDwBPfuhTFqVE8Vx+xD2bLFM4zZfc5aDh48Q758hgCULFWM+fPH8epVNMOHuxP9OoY2bRsxZEhXAC5evM62bX8yd+4olcR7/PgFvDw3kpiYRPnyJZk1exiGhmknnjx06Cw+3luQSiUYGRkyc9ZQihcvQmhoBGNGe5Lw/jp3bglAYMBxxXUe3UslMQMcOXyeKZOWcfbC6nSf+W46yMrl/hQqZAyAgYEe6zdNJSkxmVEj5vPkyQuqVivDVNc/AHgUGsn0aatZuWayyuKVy+U4OnpTtmwJ+mWQLz6XRh3X2Nf3ANu2/IlEIsGieGFcpw+kYMF8adLsCTzJmjV7kEhAX08Xxyn2VK78E1Gv3jBi+Dyio2No3aYBg4d0BuDixf+xY9sh5swdnuXxAty+9Yg5szbx5k0cWlpSnKfZUbFSyQzThvx7D/s+szl0fD758+clKTGZ0SN9iHzykipVf8LF1Q6AR6FPmem6nuWrx6sk5uPHz+PpuUH53Zs9e0S6715AwDFWr96NRCJBX1+XKVMGUKVKWV69imbYsNlER8fQpo0lQ4d2B+DChWts23YAD4+x3x1fxzoW9GteRrmcV18bM2N9GrkcpE21onRtUAI9HS2uPopi0pZLJCanptvHkFbl6FjXAi2phIALj1kY9D8ArCqbMaFdRRKTU5my9TIhj6IAmN29Ovv+CeP0rWffHf/HNK28yAq5oCFHs1ty7t59jL3dVA4cOJ3h5+fOhrBqlR9r103Dz9+LJk1rMtVlKQCbfYOws2/Prl3zWL5sJwBvY+Lw9d3PwIGdVBjzI+ztXD4bM8ClS//D03Msfv7z8fOfz/z54wDYu+ckTZvUJCBwAfv3BxMTE0tKSgrzvTYxbpytSuJ9+fI1kx198PaZyIGDS7CwKIznvA1p0sTHJzBh/Hx8Fk3CP2ABVi3qMmvmKgB8fYOwd2jPrt2eLFu2A4CY99d5UGeVxAzw8EEEnh6bSZWnL1QBrly6xfiJvdnp58ZOPzfWb5oKQHDwFQqbFWCX/xwiwp9z+9YjADzmbmLcBNVVyO7efYRdXxcOBH0+X3wuTXZf42vX7rFuzR58t8wkYI8nJUqY4eO9LU2a+/fDmeexiRUrJrPbz4OBg2wYOWIeAHv3nqJx0xr4BcwjaP+Zd/k4lQXzNzN2XO8sjxcgLi6BQX/Mw87hV7bvns6AQdY4TliWYdpXr94wa/p6kpKSletOB4dQuHB+dvjNICLiObdvPwbAc+4WxozvppKYX758jaPjQnx8HDl4cBkWFmbMm7cuTZp79x7j4bGWVatcCQjwZvDgbgwfPhuAPXuO07RpLQIDfdi//6SyvPDy2sD48fZZEqPf+Uf8PvcYv889Rod5x3kWncC0Hf9Sq1QBbJuUps/i07R2O4KejhYOzX5Kt32zioVpW6Mo1h7HaeN2lPplC/FrjaIAjGpbgd6LTuOy4wqDWpUFoGpxY/Lq62R5BUfTygvh62l0JWezbxAdbaxo06ZRhp9fu3aXBg2qYWZWCIBWrepz7NgFEhOTkMl0iI9PICEhEYlUcRkWL96GvX179PV1VRxzi8/GnJiYxI0b91mz1p8O7UczYrg74eGKL7RMpkNcfALJySmkJKcglUrZuuUgza3qYGpaQCXxng6+TJUqZShZUlHwdO/Rhj17TiKXf5jzJCUlFblczps3bwGIfRuHTFdHGXN8nOI6S5XXeatKr3NcXAKOE5cwfuLnb5iXL91m/94zdLFxZOAfbty6FfouXm3i4xKQy+XExyeio6PNiWP/YGpagPIVSqgkXlBUVGxsrGjTNuN88aU02X2NK1Uqzf4DC8mbNw8JCYlERr7E2Njwk5i0mT5jECam+RXbVP6J58+jSExMVsabnJxCSsq7fLz1T5o3r61Mn9X+On0V8+KmNG5aDYBmVjXw8BqaLl1qaiqTJy5n+Ki0lUMdmTbx8YnI5XIS4pMU+eL4ZUwL56d8heIqiTk4+BJVqpRVfvd69GjLnj0n0nz3ZDIdZs4crvz+V65c5t11VpRxce+uc3JyKlKplC1bgrCyqqeS8mJgy7K8iElgy5kHdKxbnFXH7vA6Ngm5HJy2X8bv/KN02/xStQiBFx4Tl5hCYnIqO8+G0qG2BQCJyanoy7TII9Mi6V0L0KT2lXHzv5qlcWtieSF8PY2u5Di79Kd9+2af/bxK1bKcOxdCWNhTAPx2HyUpKZmoqDf07vMr+/cFY9d3KuPH23L37mNu3w6lTZuGKo55wBdjfvr0JfXqV2HM6D74+XtRrXo5hg11Qy6X0866KXduP6Jb1wnY2VmTkJDI3r0nsbVtp7J4I548V1YSAczMChETE8vbt3HKdQYG+kxzHUyP7pNobGmPr+9+xo3rC0CfPr+xb/8p+vZ1ZvyEvty9+4jbt0K/eDP/XtOnrqZL1xaUK5/xzSc2Np5SpYvQf2B7dux2o2On5gweMJfYt/E0aFgFHR1tuthMpk7dihQtVogVy/wZPrKLyuIFcHEZQPsOzf9TGnVcYx0dbY4c/hurZoO5eOEGHTumjatYMVOaNqsJKB6xzXVfT/PmtZHJtPm9XWPu3HlE926T6Wv3OwkJiezfG0wf219VFu/Dh5EUKpSPqU6r6dFlGgP7eZCSkpIu3RIfPypXKU0jyypp1jdoWAkdHW262bhQu04FihYtyMplgQwbobpW3ydPnmX63TM3L0yzZnUAxXV2c1uNlVVdZDIdrK2bc+dOKF26jMXevj3x8Qns3XuCvn2tszzW/AYy/rAqw4xdIQCUMjWgkKEuawc3YP/E5oxsW4HouKR02xXJr09E1IfzeRIVh5mxPgDuAdfwtqvD8DYV8D5wk64NSnDm1jPCX8Wl28/30MTyIqtIJNn3py4a3yfnS+rUqcSQoV0ZPtwdqUSKTScr8uUzREdHh/z587J6zVRl2gEDZjJxkj3Hj19gy5YDGBvnxdHRAWPjvNkas7l5YVascFYuOzh0YOmSHYSFPcXcvDDePhOVnzk7L2bYsO5cv36PpUu2o6+vy9hxtpibF86yeFJTM26+fd9iAHDz5gOWLN7Gvv0+FC9ehA0b9jJiuDv+AfMxNS3AmjWuyrQD+k9nkqOD4jpvDlJc58n9suw6b918CC1tKR07NSMsLOMm7Tx59Fi+ylG53KZtfZYv9ePq1bvUrVcJ15kDlJ8tX+pHh05NiXr1BpcpKwAYNMSGnyuWzJJ4s0J2X+P3WrSsS4uWddmx/TAD+s8i6KB3mnwBihvElMlLeBLxguUrFf0T8uTRY6H3OGUaF+dlDBnWhRvX77Ns6S709GWMGdsbc3PTLIs1OSmZ4JP/snLtRKpW+4ljR/5h6EAvDhzxRCZTtDqePHGZkH/vsXRl+r4qUqmUaTMclMsrlgXSwaYJr169wcVJ0Ydj4OD2/Fwx6369p6ZmPEP0p9cYFNd50qQFPHnynFWrpgGK6+zj86FPiJOTD8OG9eD69bssWbIVPT1dxo2zw8LC7Ltj7dGwJIdCnvD4ZSwAOlIpjSqYMHDlORKSUpjXuxbjfq/IjN0hac8lg7vf+/M+f+8FHT1PAGCkr0O3BiXo4R3MkFblqF4yP3eevGHunuvfFXduLC9yG41uycnM25g46tSpxO7dnuzc5cEvvzQASNe0fvDAGUqXKkaZMha4z1nHggXjsbSszvr1e7I95ps3HxAQcDzNOrlcjra2Vpp1ISG3iX79lkaW1Znjtoap0wbRx/Z3vL23ZGk8RYuY8OzZK+VyZOQL8uUzJE8ePeW64ODL1Kj5M8WLFwGgV6+23L4dStSrN2n2deDAGUqVNqdMGQvmuK1hwcIJWFrWYP26wCyLN8D/BNdC7tG5oyNDBs4lIT6Rzh0defr0wzmEhz3Dd9PBtBtmcI0jwp9z5nQInTo3Z/GiXdja/cpkZzvmzF6fZfFmtey4xg8fPuHixf8pl206WREe/ozo12/TpAsPf06vns5oSaWsXT8VIyODdPsKCblDdPRbGjWqhvuc9ThP/YPefX5l0Sd9fL6XiWl+SpYqQtVqin4hzVvUJDVVzuNHH25s/rtPERn5ku6dptK1o+KHxh927ly7ej/NviLCX/DX6avYdG7C0sX+2PZtjaNTH9xn+2ZpzEW+4rsHEB7+lO7dx6OlJWXDhlkYGRl+uiv+/fcW0dExWFrWxM1tFdOmDcHW1hpv76yJ+beaxdh57uGHWKPj+fNKBDHxySSlyPE//4gaJdM/igx/FYup0YfzKWysl6Zl570xv/3Mkj9vUSy/Pg3LmTBg5TmMDWQ0LFcoXdpvkdvLC0k2/qnLD13Jefr0JX1tnYmJUfy6WLpkB7/91hjJR78e4uISWLMmgGHDFZ0Hk5NT0NKSIpVIiY9LyPaYJRIJs2et4vHjSAC2bDlA+fIl0zRby+VyPOauZ8IEO0DRj0dbWwuJRJLlMTeyrM6VKzd58CAcgK1bD2LVom6aNJUqlub8+as8fx4FwOHD5zA3NyV/ASNlmri4BNas9mP4cMUbHu+vs0QqIS4+62Lesn0mfnvmstPPjSXLJ6CrJ2OnnxumH/X10M+jy6KF2wn59w4AJ09cIi4+gSpVyqTZ1zwPX8aM64FUKiXp3TWWSiTEqSFffI3susbPn71i/NgFvHoVDcDePacoU7Y4xvk/tBRFRcVgZzuVVq3qMs9rFHp6snT7kcvleHpsYvyEPsD7fKyNVCLN0ngBLBtXITzsOdevPQDg4oWbIIFi5h++V14Lh+O/143tfjPY7jcDgFXrJlKpcqk0+/Ly2MrocV2RSqWKmHW0kEolxGd1zJY1PvnuBdGiRb00aaKi3tC7tyO//NKQ+fMnoKeXvg+WXC7Hw2MtEyYoWqKU11kqzZKYjfR1KFHIgH/uvVSuC7oczq81iqKro7jFtKpahH9Do9JteyjkCe1rm6Mv00KmLaVTveIcColIk6ZCUSOKFcjDkatPkGlrkfSudTlVLkdP9n0PI3JzeZFb/HCPq66G3MHZeQl+/l6UKl2M/v1t6NZ1IqmpcmrW+hln5z/SpF++fBc9erRRvpZp72CNTcexGBjq4+k5JhtjXoyf/3zKlSvBFKc/GDx4FqkpqRQ2K8S8T+LYufMw9epVodi75vxBg7tgbz8VmUyH6a6DszS2ggWNme02nJEj5pKUlIxFcTPc3UcSEnIHZ6dF+AcsoH6DqvTr1xHbPk7o6GiTL58hi5ekfXVy+bKd9OjZVnmdHRza07HDaAwN8+Dp+f2vsmbm6dNXDBk4lyXLJ2Bqmp9580cwfdpqkhKTMTDUZ6HPGHQ+KjD/OhOCvr4u1aor3uroa/8brlMVb4yNGtNd5fECaa7x18iua1yr9s8MGGiDna0rWtpSTE0K4LNoPFev3sXFeRm7/TzYtvVPIiKec/jw3xw+/Ldy2zVrXJSVoV07j1K3XiWKFVPk44GDOtHPfjoymQ7Tpg/I8Nj/VSETYxYsGsGs6RuIi0tAJtPGa+FwXr9+y7CBM1i0fEyaG9vnnD1zDT19XapWU9zgbO3aMH3qOgBGjs7afhgFCxrj5jaSESPcSEpKpnhxM9zdxxASchsnJx8CArzZsmU/ERHPOXToLw4d+ku57bp1M8mfX/EjY+fOP6lXr6ryMfbgwd2ws5uiKC+mD/vuOEuaGPA0Op7kjx6vbTp1D+M8OgSOb4aWRMK1x6+Z7X8ZgJ6NSlKluDGOWy5z9OoTKhQxwm9sU2RaUg6FRLD777QdlKd0rIzL9isA3IyI5sWbBPZPbE7oi1hOXo/87vgzoonlxX8hzQXvkEvkH3fVV5HExERSU1PR09PLPDGQKr+m4ohUQbNyi0SdPcH+o6TUWHWH8M10pHkyT5SDpKQmqjuEb5Ys17x8oadVUN0hfJPSI76v74s6/G+BhbpD+GYyaa1sPV54bPZ1ySiaR3UvyHyJSh5X3b9/nxEjRjB27FguX75Mu3bt+O2339i/f78qDicIgiAIwjfKDX1yVPK4ytnZmSFDhvDmzRsGDhxIYGAgefPmxd7enl9/Vd1rooIgCIIgCO+ppJKTnJxMw4YNkcvleHl5Ubiw4lmwtrb6ugB9bnqHnMjf/1iat2HevIklMvIFx46vUg4rnpMdPnyWiRMWcvGfrH3TKyvsCQxm3Zq9SCQS9PRkOE7pS6XKpQGIjn6LXZ/pzJg1ULkup5kzZw0HD3yY8qNUqWLMX6CaKQW+h1wuZ8rkJZQta4G9g2JcFsuG/TAt/GEQOgcHa35v11hdIaaxxfcw27ceVUxTYWGKy3R7jI0Nmee+hTOnQ0hJTsXWvg1du1upO9TPUkz5seDdlB82KjlGn8al6GVZCrkcQl+8ZfKWS7yISeT87LZERsUr0608epuAC48xNdJjbq8amBjpIZXAssOK9e8tdqjDwqD/cStC8Samkb6iH4974DWCLofTqJwJjh0qK9Pr6UgpXTgv1h7HuProNQB59XXYNsKSiZsvKad+yCqaXl5kRiJReW8VtVNJraNYsWKMHj2alJQUDAwMmD9/PoaGhpiYmKjicJl6P73D1m1zMDMrREDAcaa6LGWh9wS1xJOZDh2a0+HdoG9JScn06T2F/v1tNKKC8+BBOHPd15ENXb2+2f374Xh5bGb7rlmYmObn5IlLjBoxn0NHfTh54hJz3TYSFp61w8VntUuXbuLpNY6aNSuoO5TPunv3MTNnrObfK7cpW1bRL+L+/XCMjAzZ7eeh5ujSu37tARvWBrHdbwZ58+bBc+5WFnvvpnwFC0IfRrIrYBaxb+Pp03MGP1csSZWqOe+GdvfuI1xdl3Hlyv8oW1Y1I+1WtshHf6uy/OZ+lDfxyTi2r8To335m9bG7RMcm8fvcY+m2GdeuIpcfvmLB/v9ROJ8eh6a04PTNZzx/k4BMW0qJQobKCg6AZ59a5NXXUS6fvvUszX4XO9Th4L8RygpOs4qFcbapQrECWd/37UcoLwQV9clxd3fn999/Z+TIkSxZsoSEhASSk5OZPXu2Kg6XqS9N75DTrVrlR8GC+ejWvbW6Q8lUXJxiDqtJkxwyT6wGMpkOrjP6fzTVQGmeP48iKTGZzZsOMtNtEKYmqplWICskJiZx4/o91q7xp731KIYPn6Oc8iMn2bL5IB07Nqd1mwbKdZcv3URLS4pdX1c6th/HksU7SUnJeKDJ7FaxUkkCg9yV01Q8ffoKY2NDjh7+h/YdLdHW1sIonwFt2tZj354z6g43Q76++7CxaUHbtpYqO8bVR6+xmnGIN/HJyLSlmBnrE/U2kVqlCpCSKsd3eCP2T2zO8DbllW/taEkl5NVTVFr0ZVqkpMqVP4AalTPhzEdzUA1rXZ7/hb3mZnh0hsdvX9sc8wJ58Np3Q7mub9PSjNt0kaev4zPc5ntoennxNUSfnP+6U21tWrRooVyeNGmSKg7z1apULcumTfsJC3tKsWKmaaZ3UNWcT1nh1ato1q0NYNduT3WH8lWmuiyhW7fWlCufM+dsKVbMhGLFFK2JcrkcD/dNNG9eCx2ZNstWqjePfo2nkS+pX78Ko8f0oVSpoqxZ7c/QIbPZ7eeVo96Wc3LuB8DZsx9Gt01OTqFBwyqMG9+H+PhEBg+ag6GhPrZ9f1NXmGno6Ghz9PBFXF3WoiPTZsiwjhw5fAGzIh/Kh8JmBbh16/EX9qI+Li6DADh79opKj5OcKqdVlSK49ahOYnIq8/ffoF6ZQgTffMqcgGvo6mixemB9YuKTWXv8Lh57rrFtZGN+rVGUAoa6zPa7yosYxRt8LasUwf/dfFaWFUyoV6YgfZecYdOw9BU1HS0J49tVZNT6C6R89Kq6/dK/0qXNKppeXggKP9w4ORn50vQOOdn2bX9iZVU3S6dpUJXNvvvR0taiU+eWyoEMc6rY2HicJi8jMuIlS1dOzHyDHMLcojArVroolx36dWDJku2EPX6KuUXOziNdurZU/r9MpkNfu9/w3RiUYyo5AFYta2HVsha7dhxn8ABPtLTSN3Rr5YaBRTJxKCSCQyERdGtQgnWDG9J8xiHeP51OTE5lzbG79G1amrXH7zLftjYrjtzGN/gBJU0M2DzckksPXhLyKIoaJfPjvP0yRfPrM6VDZfosPsNnZrKgbfVihD6P5cJHAw5mF00tL75GDvptpDI/9IjH733t9A45TVDQaTra5NyOjh/z8zvG1ZA7dGg/ioEDZhAfn0iH9qOIjMz+QulLIsKf06fnNLSkUlavd8pwqoGc6ub/HhDgn7bfg1wuR1tH6zNb5ByBASe5efPDsP9yuXpfRPhY6MNI/rl4S7ncwaYJEeHPMS2cn2fPXivXP418RWGznNvyq2olChlQu/SH899x9iHFCuShYx0LKhT9MLq5RALJKankN5BRu3RBtp5R/Ls/ePaW4JvPqFumENVL5CfkURSpckUFRk+mzbrBDdk7oTlVihszqX0lejYqqdznp9NGZBdNLi8EhVxRyfma6R1ymtevYwgNjaBGjZzbwfRjO3Z6sGevN/4BC1i+whk9PRn+AQsoXDjn3BReR8VgbzuDlq3q4OE1IsOpBnIyiVTCrFmrePzo3ZQfm4PSTfmRU92+Hcoin22kpKQSH5/IFt8DtGnbIPMNs8HzZ1FMHLeUV+/mWtu/9y/KlDWnRcta+O8+SXJyCtHRbzkQdI7mLWqqOVr1MTXSY6FdHfIbKL437WtbcCsimrJmeRn1689IJaCrI6VP49Ls/SeMV28TeRIVR9vqRQHFTOV1fyrIlQev+KVqEeX0DauP3aH59EP8PvcYv889RkhoFHMCrrH59APlsev+VDBN/53soOnlxdcQfXJ+EF8zvUNOExoagYlJfnR0csU/UbbYtvUwERHPOXL4AkcOX1CuX7Vmcpp5l3KqcuVK4OTUn8GDZ5GSkoqZWUE8vVQ/JUZWGDK0C7NmrqZD+7EkJ6XQuk19OndpkfmG2aBm7fL0H9iOfn3noK0lxcQ0P/N9RmBmVoDHj57SpaMzyUkpdO7ajNp1NONHhyqcv/eCJX/eZPNwS1JS5Tx9HcfAled4/iYB1y5VCXK0QkcqZf/lMLb9pWh16b/iLNM6V2VY6/LI5XKWHrrF+XsvcO5UhQVB/8vkiAoFDGXk0dXmSVTWdy7+Ek0vLwSFbJnW4VuJaR1ULye3Yn2OmNZB9cS0DtlDTOugemJah8w9iw/MPFEWMdGzzrZjfUw0EwiCIAhCLpQb+qvkhnMUBEEQBCEXEi05giAIgpALaWCvhW8mWnIEQRAEQfghiZYcQRAEQciVfvymHNGSIwiCIAjCD0m05AiCIAhCLiQRLTmCIAiCIAiaSbTkCIIgCEIuJJH8+O0cP/4ZCoIgCIKQK4mWHEEQBEHIlUSfHEEQBEEQBI0kWnIEQRAEIRcSb1cJgiAIgiBoKNGSIwiCIAi5kmjJEQRBEARB0EiikiMIgiAIwg8pRz6ukpOi7hC+mVSio+4QvolcnqruEL6ZjjSPukP4ZqlyzcrLUkmOLBK+SFdaQN0hfDM5cnWH8E1uLyyt7hC+WYW2F9Qdwje7faBWth5PDAYoCIIgCIKgoTTvZ5sgCIIgCFlAdDwWBEEQBEHQSKIlRxAEQRByITEYoCAIgiAIgoYSLTmCIAiCkAuJlhxBEARBEAQNJVpyBEEQBCFX+vHbOX78MxQEQRAEIVcSLTmCIAiCkAtJJKJPjiAIgiAIgkYSLTmCIAiCkCuJlhxBEARBEASNJFpyBEEQBCEXEuPkCIIgCIIgaChRyREEQRAE4Yek0Y+rAgNPsnZ1IEhAX0+XyVMcqFzlJ+XnZ878i8fcDcrlhPhEHjyIYMfOORQrZsrw4R5Ev46hTduGDB7SGYCLF2+wfdsh3OeOUFnccrkcR0dvypYtQb9+HdJ9fvz4Bbw8N5KYmET58iWZNXsYhoZ5CA2NYMxoTxISErGzs6ZT55aK6xBwnHv3whg1upfK4p3suIiyZS1wyCDeTRv34esbhJ6ejNKlzXF26Y+xcV5CQ58wdown8e/j7dRCEW/gCUW8o3qqJN73MWvSNQ4MPMHa1QEgkXyUl8ukSRMUdJrlS3cCkD+/EVNdB1KyZFGiXr1h+HB3ol+/fZeXuwDv8/KfuM8dqZKYv5Qv/P2PsX7dHuXymzexREa+4NjxlcTGxqslXxw/fh4vzw0kJiZTvnwJZs0egaFhnjRpbt58wMyZK4h58xapVAvX6UOoXLkMr15FM3zYbF5Hv6Vtm0YMGdodgIsXrrNt2wHmeoxRW8zvHT58lokT5nPxn20Aaok5szIZYNPGIJYv30WhQsYAGBjos8l3BomJSYwcPo8nT15QtVpZXKcPBCA09Amu01aweo1LlsXZqmEJRvSpgTxVzuuYRKYsCCY04g3ntvYg8kWsMt2qnSEEHruXbvvhvWvwW5NSpKTKuXr7Oc7eZ0hMSsGqngXjHGqTmJSC08LTXL39AoCZIxux/+R9zlwKz7JzyBo/fjuHxp7h/XthzPPYyIqVU/Dzn8fAwZ0YMcIjTZqGDavi5z9P+VeuXHH+6N+BSpV/Ys+eUzRpUgP/QE/27z9NTEwsKSkpzPfazLhxfVQW9927j7Dr68KBoNMZfv7y5WsmO/rg7TORAweXYGFRGM95ioqar28Q9g7t2bXbk2XLdgAQExOHr+9+Bg7qrKJ4H2NvN5UDBzKO99zZEFat8mPtumn4+XvRpGlNprosBWCzbxB29u3ZtWsey5cpbs5v38c7sJNK4lXErFnXWJGXN7BipTN+/p4Z5uXnz6NwnbaCpcun4B84n5at6jFrxioA9uw5SZMmNfEP9GL//uCP8rIv48bZqiTmzPJFhw7N8fP3ws/fi+075lKokDFOTn9QqJCxWvKF4t/cG28fRw4cXIqFhRme89anSRMXl8Af/abyxx82+PkvZMiQrowf5wnAnj0naNK0NoGB3uzff0p5jb28NjBuvJ3aYn7vwYNw5rqvQS6XK9dld8xfUyYDXL50k4kT+yrL5U2+MwAIDr5MYbOC+AXMIyL8GbdvhQIw130D4ydkXT7WlWkxb0IThk4/gvXQAI6cDcV5cH1KmRvxOiYR66EByr+MKjh1q5rxW9NStB8WwG+D/DDMI8O2/c8AjOhTA9tJB5i26C8Gdq0KQJVyhchrIMuBFZzcQWMrOTKZDjNmDMLEND8AlSv/xPPnUSQmJmWYPjDwJGFhzxgxsrty+/j4BJKTU0hJTkEqlbJ1y580t6qt3Kcq+PoGYWNjRZu2jTL8/HTwZapUKUPJkkUB6N6jDXv2nEQulytijksgISERqVTxT7d48Vbs7dujr6+rkng3+wbR0caKNm0yjvfatbs0aFANM7NCALRqVZ9jxy6QmJikvMYJCYlIlPFuU2m8oHnXWJGXh3yUl8uky8uFChlzKng1RYoUIjk5hfDwZxgb51Vu/yEvp77LywdVmpczyxcfW7XKj4IF89Gte+s08WZnvjgdfIkqVcp+9G/elj17TqSpFJw+fQkLCzOaNq0NgFWLeixYMOFDzHGKa5z87hpv2RKElVVdTE0LqC1mUFTOJoz3YtKkfmnWZ3fMX1smX7p8k317g7HpOJ7+/WZy6+ZDxfY6inwhl8uJj09ER0eb48cuUrhwASpUKJllcWpJJUiQkNdABoCBvjYJiSnU/LkwqalyNrq3Zc/SDgzrWR2pNH3HXC2pBF2ZFnoyLXS0pejKtEhITAEgMSkVfV1t9PW0SUpOBWDiH3VwX/V3lsWflSTZ+J+6aGwlp5i5KU2b1QIUzebuc9Zj1bw2MplOurSJiUks8NrMpMl2aGtrAdDOujF3bj+mW1dH+tq1IyEhkX17g7G1/U2lcbu4DKB9h+af/TziyXNlhQHAzKwQMTGxvH0bR58+v7Fv/yn69nVm/IS+3L37iNu3Qj97M88Kzi79ad++2Wc/r1K1LOfOhRAW9hQAv91HSUpKJirqDb37/Mr+fcHY9Z3K+PG23L37mNu3Q2nTpqHK4gXNu8bp8/K6DPOyjo42V0Pu0LzZAHZsP0yv3r8C0M66CXduP6Jb10mf5OXfVRZzZvnivVevolm3NhDHyQ7KderIF1/6N3/vwf0wCpnkZ8pkbzrZjMHB3oXkFMWNytq6GbfvhNK1y1js7NuTEJ/I3r0nse1rrdaYAaa6LKZbt9aUK18yzfrsjvlryuTY2HhKlyrGgIE27PbzwKazFQMHzObt2zgaNqqKjo42Nh3HU6duJYoWM2HZsl3KH6ZZJTY+GRefM2z3+p1g3+70bleRuavPo6Ul4fSlMPo5HaTnuP1Y1iqGrfXP6bb/63IEp/8J58TGbpzZ0gMjQxlb998EYO6q88x3bMawntVZ5HuZLm3K8dflcMKfvs3ScxC+nkb3yQHFl2ay42KePHnBipVTMkzz58GzWFgUplatDxk2Tx49FvqMUy67OC9j6LCuXL9+n2VLdqKnr8vYcb0wNy+s8nP4WGpqaobrpVIppqYFWLPGVbluQP/pTHJ04PjxC2zZHISxcV4cJ/dT/sLPDnXqVGLI0K4MH+6OVCLFppMV+fIZoqOjQ/78eVm9ZuqHeAfMZOIke0W8Ww4o4nV0yNZ4IedeY0VeXsSTJ89ZsdI5wzSVq5ThVPBqTp26xKBBs/nz0BKMjAxY6DNBmcbFeem7vHzvXV6WMXZcn2zPywDbt/2JlVXdNMc2NS2Q7fniS//m7yUnp3DyxAXWb5hFtWrlOXL4LAMHuHL02Gry5NHDx8dRmdbZaRHDhvXg+vW7LFmyDX09XcaN64u5hVm2xrzZdz9a2lp06tyKx48j06RTR8zw5TI5Tx49Vq52Ui63bduQZUt2cjXkLvXqV2bGzMHKz5Yt3YWNTXNevXqD05QlAAwe0oWKFUt9V3zlSuZnWK/qtB24m9CIN9i2r8gi5xZYD/FXpklMSmTt7qvYtq/IOv/rabbv/EtZzM3y0qjnFpKSU5kzpjGT+tdlxtKzXLgWSeeRir5oRoYyurYuR68JQQzqVpXqP5ty52EU89Ze+K74s5KY1iGHCw9/Rq8eTmhpSVm3fipGRgYZpgsKOkNHm8//sg8JuUP06xgaWVbD3W0dLtP608f2V3y8t6kq9M8qWsSEZ89eKZcjI1+QL58hefLopUl34MAZSpU2p0wZC+a4rWHBwglYWtZg/brAbI33bUwcdepUYvduT3bu8uCXXxoAYGxsmCbdwQNnKF2qGGXKWOA+Zx0LFozH0rI669fvyWi3KpUTr7EiL09+l5dd0+Xlp5EvCT51SbncuHENDA30eRT6JE26D3m5+ru8PIA+tr/j4701y2P+GkFBp+loY/XZz7MrXyj+zV8qlzP6NzcxLUDp0uZUq1YegBYt65OSksqjR59c439v8zo6BkvLGri5rWbatMHY2rbD23tztsfs53eEqyG36dB+JAMHTCc+PpEO7UcSGflCLTFnViaHhT1j08agNOvkgLaOVrr9nD59hc5dWrDYZxt97drh5NyP2bPWfHeMjWsV4+K1SEIj3gCwac8NypUwpn2Lnyhf6sPjXYlEQlKKPN32vzQqwZ6jd3kbl0xiUipbg25Sv1qRdOlG2dZk6bYrFDU1oEH1ogyadhhjI10aVE+fVlAdja3kREW9oW+fqbRsVQ9Pr9Ho6WX8LF8ul3Pxwg3qN6jy2c/nzd2o7NiWmJiEtrYWUomE+LhElcX/OY0sq3Plyk0ePFB0Utu69SBWLeqmSRMXl8Ca1X4MH65oxk1OTkFLS4pEKiEuPiFb43369CV9bZ2JiVG8kbB0yQ5++61xml8IcXEJrFkTwLDh3dLEK5VIiY/L3ngh511jRV52oWWr+nh6jckwLyckJjJ2jBcPH0YAig7fKSkplP7JXJlGkZc3MH5CX+DTvJz91/n16xhCQ59Qo0b5DD/PznzRyLLGJ//mQVi1qJcmTZMmtQgLe8rVq3cAOH/+KhKJJE0rlFwuZ67HWiZMsAfeX2NtJFJplueLr4l5x05P9uxdhH/AQpavcEFPT4Z/wEIKFy6Y7TF/TZmcJ48u3gu38O+/twE4ceIf4uMSqPLJm4QeczcyblxvpFIpiYnJ6GhrZVm+uHbnBXWrmlHQWFFZbNWgOI8jYyhXIj8j+9RE+q7PTW/rn9l/In3H42t3XvBLoxJoveuv07pRCS7/72maNBVKFaCYqSFHzz5CpqOlfOwpl8vR181JD1Ak2finHjnpan+TrVv/JCLiOYcPn+Pw4XPK9cuWOzJooBvLl0/GtHABXr2KJjY2HjOzghnuZ9fOo9StV5li5qYADBrcCQf76chkOri6DsyWcwkJuYOz0yL8AxZQsKAxs92GM3LEXJKSkrEoboa7e9pXgJcv20mPnm2Vr5I6OLSnY4fRGBrmwdNzrMrjvRpyB2fnJfj5e1GqdDH697ehW9eJpKbKqVnrZ5yd/0gb7/Jd9OjRRhmvvYM1Nh3HYmCoj6enal69/VROvsZbtx78TF6ezKCBs1m+fAoWFmbMmDmEUSM8QCLBKK8Bi5c6pumou2vnkU/ycmcc7Ke9y8uDsjTmjHycLwBCQyMwMcmPjk7GxUx25gvFv/lIRo6Y89G/+WhCQm6/yxcLMTHJz6LFk5nuuoy4uHh0ZDr4+DiiqytT7mfnzkPUq1dFWfEZPLgr9nZOims8fWi2x/w1sivmry2TveaPYdrUFSQlJWNooI/3ovFp+u2cOfMv+vq6VKteDgA7+3ZMdVkOwOix3z+Ew9krEazaeRXfub+SmJzK6zcJDHI9zOMnb5g6pAH7lnZAW1tK0KkHbD9wC4Aev5ancrlCTFlwmqVb/2XygLoErbAhMSmF/91/ybRFf6U5xqQBdZm26AwAtx684kVUPHuWduBRxBtOXnj83ecgfD2J/NOu+jlAivxfdYfwzaSS9B2eczK5POPn/TmZRKJ5DY+p8hR1h/BNNHGYd4lEY3+raYxUefa3BH6vCm1zTt+Xr3X7gEPmibJQQkr2vfWlq1U380QqoPK7Rg6sQwmCIAiCkAuo5CdQaGgorq6u3Lt3j6dPn1KpUiUsLCyYNGkSJiYmqjikIAiCIAjfRPNabr+VSlpyXF1dcXJy4tixY/j6+lKvXj3s7e2ZMiXjV7wFQRAEQRCymkpacmJiYihVSjGWQfXq1fHw8GDs2LFER0er4nCfJZfLmeK4mDJli+PQz5o3b97iPGUp9+6Hk5qaSocOzfijf4dsjelrzZmzhoMHzpAvn+JV7FKlijF/wXg1R/Vln5vDKifTlOusyMuL3uXl9gBER7/FtrcTM2cNTTfPVU5y6NBZFvlsQyqVYGRkyIyZQyhePGvHZslqmzbtZeuWICQSybtO38MoWNBY3WF9VmDAMVav9kMikaCnr8uUKf2pUqWsusNK59MyOT4+gRnTV3M15A6pcjlVq5bF2aXfZ9+W/R4tGxTHY1wTanTapFyX10DG5nm/4uh1SjnPFCjejlo96xca9Uw79MLEP+rw979POPb3IwB0tKVs9viVA8EPWL3rKmWKG+M1sakyvVQqoXypAgydcYQ/Tz9kdN+a/NqkFHHxyfxz/SmzV/xNYpL6+u3lhnFyVFLJMTc3x8XFhSZNmnD8+HEqV67M8ePH0dfXV8XhMnT37mNmTl/FlSu3GVa2OADeC7dR2KwgC7zHERsbj/XvY6hd+2eqf+YVV3W6dOkmnl7jqFmzgrpD+Srv57Daum0OZmaFCAg4zlSXpSz0npD5xmqkCddZkZdXcuXKLWVePnHiInNmryUs/Jmao/uy+PgEJk5YiJ+/FyVKFGHduj3MmrWK5cudMt9YTa5evcOaNf4EBCwkb14D3N3XsHChL9Oz+O2prHLv3mM8PNaxa/d8TE0LcOLEBUYMd+PY8e8fUyYrZVQmL1+2m5SUFPwC5iGXy5k43oeVK/wYPiJrRzkuUdSISf3rIvlomoamdcyZMrAexQp/GNNLSyqhT/uKDOxaFX299LfHhtWLMn/9P8rlKQPrUbzIhx9yd0KjsB4aoFye1L8utx684s/TD+nUqizN61pgM2IPb94mMrRnNUb3rYn7qvNZeq5CWip5XOXm5kb58uU5ffo0VatWZcKECRgbG+Pl5aWKw2Voi+8BOto0p02bBsp1k6fYK8fDefbsFYlJSRjmzXhGX3VKTEzixvV7rF3jT3vrUQwfPofwHH4z+9IcVjmVplznLb5B7/Lyh2kPfDfux23OcExNVDfPWlZISUlFLpcT80YxjlJsbBy6MlkmW6lX5cplOHhwGXnzGpCQkEhk5Isc3SIpk+kwY+Yw5XxUGc19lhNkVCbXrl2RQYM6IZVK0dLS4ueKpQgPe56lx9XT1cJzQlNmrziXZr1t+4pM8DzJ05cfZh2vVKYgFUrlZ/jMo+n2U6aEMY+evFG2vLRv8RN5DWQcP5/xK+G1KxWmjWVJXHwUr5JXKluQQ3+F8uatYvy1g6cf0qZxyaw4xe8gxsn5T2QyGb16pR3PoHr16qo41Gc5uSjGajn7V4hynUQiQVtbiwnjvfnz4FlatqxLqVJFszWur/E08iX161dh9Jg+lCpVlDWr/Rk6ZDa7/bxybPNilapl2bRpP2FhTylWzDTNHFaqmsDwe2nKdXZy6Q+kzcsrVmU87UNOY2Cgz9RpA+nRwxFj47ykpqbiu3m2usPKlI6ONocPn8Vpig8ymQ4jRnz/+CyqYm5eWDkGjlwuZ47bappb1c1wHj91yqhMbmRZTfn/YWHP2LB+H67Ts3Z8shkjGrF1//+4ef9VmvX9nP5Ml/bfW8/51ys4TevOey3rF+fQX4rJRMuVzE/f9pXoNX4/04Y1SJcWFK04XusvEhOrqGxeufkM+46V2BR4nag3CXRsUQbT/DnvR/aPRvMGHskCcz1GcPqv1bx+HcOSxTvVHU465haFWbHShdKliyGRSHDo14HQ0CeEPX6a+cZq8vEcVp07jUcilSjnsMqpNPE6a5pbNx+ydMkO9u7z5uSp1Qwc2JmRI+ZqxNASLVvW5+w5X4YN78Ef/aZ+di6pnCI2Np5RI90JDY1g5sxh6g7nm1y7epc+vZ3p2asNzZrXyrL99vy9Aikpqez88/Z376tZXQuOn3uEYR4d5o1vwoR5J4lLSM4wbY2fTclvpMueY3eV6wKO3CXo1AM2uLdlm9fv3Hv0msTknJ2nfgS5qpITfOoyTyMVc8EYGOjz62+NuHH9vpqjSu/m/x4Q4H8szTq5XJ5ufpec5GvnsMpJNPE6a5rg4EvUqFFB2dG4Z6823L79iKioN2qO7PMePgzn4oUPkzJ26tSS8PBnvH4do8aoviw8/Bk9uk9AS0uL9RtmYWSUc793n9q/7zT9+s1gzJheDBxkk6X7tmlVlirlTAhc3J5V01uhJ9MicHF7TAt8W/9Q0wL6JCSm8Domkca1zMlrKMNrYlMCF7fHqn5x7DpWYmSfGsr0vzUthd+RO3xcl89nKGPPsbu0G+xP19F7uRMaRWh49r6M8ykJaFkZqAAADEFJREFU0mz7U5dcVck5cOAMixfvQC6Xk5iYxIEDf1GvfmV1h5WORCph1qxVPH6kmFV4y+YgypcvqezvkhN9zRxWOY0mXmdNU7HST5w/f43nz6MAOHL4b8zNTcmf30i9gX3Bs2evGDPGg1cvFTegPXtOULZs8Rwbc1TUG/r0dqTVLw3wmj9eJW8mqcrBA38xe9YaVq1y5vd2jbN8/51H7uG3QX5YDw3gD5dDxCemYD00gKcv475pPy0blODo2VAAgk7dp3nfHVgPDcB6aABHz4ayzu8aCzd+mEC3bhUz/rockWYfVcoVYolLC7S1JGhJJQzsVpXAj1p6BNXIVeOhT5jYF9dpK2hvPRYJ0KJlXfrY/qrusNIpV64ETk79GTx4FikpqZiZFcTTS/VzUn2Pr5nDKqfRxOusaerXr4JDvw70tXVGR0ebfPnysmjxJHWH9UW1a1di0KAu2NpORktLC1PTAixePFndYX3W1i1BijmjDp3l8KGzyvVr183IsRWz9+bP34xcLsfZealyXc2aFXB2yVllR4sGxZUdiL9GiWJGhEWmba0M/iecOlXC2Lu0IxKphMNnHrLW71pWh/qNcu6P0Kwi5q7KImLuKtUTc1epnpi7SsiImLsqe2T33FVJqZez7Vg60urZdqyPidJBEARBEHIhTfxR860076exIAiCIAjCVxAtOYIgCIKQC+XkF0OyimjJEQRBEAThhyRacgRBEAQhV/rx2zl+/DMUBEEQBCFXEi05giAIgpALiberBEEQBEEQNJRoyREEQRCEXEm05AiCIAiCIGgk0ZIjCIIgCLmQGCdHEARBEARBQ4lKjiAIgiAIPyTxuEoQBEEQcqUfv51DVHIEQRAEQVCb1NRUpk2bxs2bN5HJZMycOZMSJUpkyb5//GqcIAiCIAjpSLLxvy85fPgwiYmJbNu2jbFjxzJnzpwsO0dRyREEQRAEQW0uXrxI48aNAahevTpXr17Nsn3nyMdVWpKq6g7hh5cL3hzMEbTEdRZ+AJqYj28fEPeRzJVTdwAAxMTEYGhoqFzW0tIiOTkZbe3vr6KIlhxBEARBENTG0NCQt2/fKpdTU1OzpIIDopIjCIIgCIIa1axZk5MnTwJw+fJlypXLuhYmiVwul2fZ3gRBEARBEL7B+7erbt26hVwuZ/bs2fz0009Zsm9RyREEQRAE4YckHlcJgiAIgvBDEpUcQRAEQRB+SDnyFfKspsrRFFXpypUrzJs3j40bN6o7lEwlJSUxefJkwsLCSExMZPDgwbRo0ULdYX1RSkoKTk5O3L9/H4lEgqura5Z2eFOVFy9eYGNjw5o1a7LsubUqdezYUfl6qLm5OW5ubmqOKHPLly/n6NGjJCUl0aNHD7p06aLukL5o9+7d+Pn5AZCQkMCNGzc4ffo0RkZGao4sY0lJSUyaNImwsDCkUikzZszI8Xk5MTERR0dHHj16hKGhIS4uLpQsWVLdYQmZyBWVnI9HU7x8+TJz5sxh6dKl6g7ri1auXElgYCD6+vrqDuWrBAYGYmxsjIeHB1FRUXTo0CHHV3KOHTsGwNatWzl37hzz58/P8fkiKSkJFxcX9PT01B3KV0lISEAul2tERf29c+fOcenSJbZs2UJcXBxr1qxRd0iZsrGxwcbGBgBXV1c6deqUYys4ACdOnCA5OZmtW7dy+vRpFixYgI+Pj7rD+qLt27eTJ08etm/fzr1795gxYwarV69Wd1hCJnLF4ypVjqaoKsWLF8/xX/qPtWnThpEjRwIgl8vR0tJSc0SZa9myJTNmzAAgPDw8R98U3nN3d6d79+6YmpqqO5Sv8r///Y+4uDgcHBywtbXl8uXL6g4pU8HBwZQrV46hQ4cyaNAgmjVrpu6QvlpISAh37tyhW7du6g7li0qVKkVKSgqpqanExMRk2ZgoqnTnzh2aNGkCQOnSpbl7966aIxK+Rs7PWVlAlaMpqkrr1q15/PixusP4agYGBoDiWo8YMYJRo0apN6CvpK2tzcSJEzl06BDe3t7qDueLdu/eTYECBWjcuDErVqxQdzhfRU9Pj379+tGlSxcePHhA//79OXDgQI7+7r169Yrw8HCWLVvG48ePGTx4MAcOHECiAcOEL1++nKFDh6o7jEzlyZOHsLAw2rZty6tXr1i2bJm6Q8rUzz//zLFjx2jZsiVXrlwhMjKSlJQUjfhBl5vlipYcVY6mKHwQERGBra0t7du3p127duoO56u5u7tz8OBBnJ2diY2NVXc4n7Vr1y7OnDlDnz59uHHjBhMnTuTZs2fqDuuLSpUqhbW1NRKJhFKlSmFsbJzjYzY2NsbS0hKZTEbp0qXR1dXl5cuX6g4rU9HR0dy/f5/69eurO5RMrVu3DktLSw4ePEhAQACTJk0iISFB3WF9UadOnTA0NKRnz54cOnSISpUqiQqOBsgVlRxVjqYoKDx//hwHBwfGjx9P586d1R3OV/H392f58uUA6OvrI5FIkEpz7lfC19eXTZs2sXHjRn7++Wfc3d0xMTFRd1hftHPnTuWMwpGRkcTExOT4mGvVqsWpU6eQy+VERkYSFxeHsbGxusPK1Pnz52nQoIG6w/gqRkZG5M2bF4B8+fKRnJxMSkqKmqP6spCQEBo0aMCWLVto06YNFhYW6g5J+Aq5ojmjVatWnD59mu7duytHUxSy1rJly4iOjmbJkiUsWbIEUHSezskdZH/55RccHR3p1asXycnJTJ48OUfHq4k6d+6Mo6MjPXr0QCKRMHv27Bzfitq8eXPOnz9P586dkcvluLi4aMQv9vv372Nubq7uML6KnZ0dkydPpmfPniQlJTF69Gjy5Mmj7rC+qESJEixcuJBly5aRN29eZs2ape6QhK8gRjwWBEEQBOGHlHPb5gVBEARBEL6DqOQIgiAIgvBDEpUcQRAEQRB+SKKSIwiCIAjCD0lUcgRBEARB+CGJSo4gaKDHjx9TuXJl2rdvT4cOHfjtt9+wt7fnyZMn/2l/u3fvZtKkSQD079+fyMjIz6b19vbmwoUL37T/8uXL/6e4BEEQvoeo5AiChjI1NSUgIAB/f3/27dtH5cqVlXNxfY+VK1dSuHDhz35+/vz5HD9wmyAIAuSSwQAFITeoXbs2R48excrKiqpVq3Ljxg02b97MqVOnWL9+PampqVSqVImpU6eiq6uLv78/S5cuxdDQkGLFiikHY7OysmLDhg2YmJjg6urKxYsX0dHRYciQISQmJnL16lWcnJxYtGgRenp6TJs2jaioKPT09HB2dqZixYo8fvyY8ePHExsbS7Vq1dR8ZQRByK1ES44g/ACSkpIICgqiZs2aADRp0oSDBw/y8uVLtm/fztatWwkICKBgwYKsXr2ayMhI5s2bh6+vL9u2bUszt9t7GzduJDY2lqCgINauXcvixYv59ddfqVy5MjNnzqR8+fJMnDiR8ePH4+fnx4wZMxg9ejQAM2bMwMbGhoCAAGVMgiAI2U205AiChnr69Cnt27cHIDExkapVqzJ27FhOnz6tbD05d+4cDx8+pGvXroCiMlSxYkX+394dqzQShWEYfkfREDSdFnYWFklhEUQEIReQwpQWSUArK1uLQNQUaSSIN2Bjl1owgtYhokUIeAN2sQhWsQjMZJs1kFW22GWFHd6nmzPnDPOf6mPOwN/tdslmsywtLQGws7PDw8PD1POfnp7Y3d1lZmaG5eVlbm5upu4Ph0Oen5+pVCqTsff3d97e3nh8fOT8/ByAQqFAtVr9N5sgSb9hyJH+Ux//5HwlkUgAEIYh+Xx+EjKGwyFhGNLpdIiiaDL/q35Sv469vLywsrIyuY6iiPn5+al36Pf7k2aWHx1jgiAgCII/qFCS/o7HVVKMbW1tcX9/z2AwYDweU6vVuLq6YmNjg16vx+vrK1EU0Wq1Pq3d3Nzk9vaW8XjMYDCgXC4zGo2YnZ0lDENSqRSrq6uTkNNutymVSgBsb29zfX0NwN3dHaPR6PuKlqSf/JIjxVg6nebw8JC9vT2iKCKTyXBwcEAikaBarbK/v08ymWRtbe3T2mKxSL1ep1AoAHB8fMzi4iK5XI7T01POzs5oNBrUajUuLy+Zm5vj4uKCIAg4OTnh6OiIZrPJ+vo6CwsL3126JNmFXJIkxZPHVZIkKZYMOZIkKZYMOZIkKZYMOZIkKZYMOZIkKZYMOZIkKZYMOZIkKZYMOZIkKZZ+AHqLpAWzv/wdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cm(test_labels, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28e97065-c45e-49ed-a603-51111d5037a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89       483\n",
      "           1       0.84      0.87      0.85       539\n",
      "           2       0.87      0.93      0.90       539\n",
      "           3       0.86      0.86      0.86       484\n",
      "           4       0.90      0.90      0.90       490\n",
      "           5       0.87      0.84      0.85       526\n",
      "           6       0.85      0.87      0.86       483\n",
      "           7       0.90      0.91      0.91       506\n",
      "           8       0.88      0.76      0.82       471\n",
      "           9       0.86      0.86      0.86       479\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.87      0.87      0.87      5000\n",
      "weighted avg       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf812527-8b3f-49e1-ba9a-09056d29c3bd",
   "metadata": {},
   "source": [
    "### Part two\n",
    "* #### Trying to set these parameters:\n",
    "** #### hidden_size\n",
    "** #### reg_l1_param"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c374b0c-3c3d-4e79-af68-bfc9f424cced",
   "metadata": {},
   "source": [
    "#### The base code and instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77d2c69d-2dea-4a80-8afd-a2d814cdac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with hidden size: 16 and L1 regularization parameter: 1e-05\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.2276 - accuracy: 0.6100 - val_loss: 0.7718 - val_accuracy: 0.7800\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.8640 - val_loss: 0.5372 - val_accuracy: 0.8308\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3304 - accuracy: 0.9054 - val_loss: 0.4885 - val_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2539 - accuracy: 0.9278 - val_loss: 0.4616 - val_accuracy: 0.8524\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.9410 - val_loss: 0.4548 - val_accuracy: 0.8578\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1729 - accuracy: 0.9578 - val_loss: 0.4449 - val_accuracy: 0.8632\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.9654 - val_loss: 0.4438 - val_accuracy: 0.8644\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.9710 - val_loss: 0.4396 - val_accuracy: 0.8658\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1041 - accuracy: 0.9792 - val_loss: 0.4516 - val_accuracy: 0.8666\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9844 - val_loss: 0.4657 - val_accuracy: 0.8670\n",
      "157/157 [==============================] - 0s 646us/step - loss: 0.4657 - accuracy: 0.8670\n",
      "Training model with hidden size: 16 and L1 regularization parameter: 0.0001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.1896 - accuracy: 0.6296 - val_loss: 0.7769 - val_accuracy: 0.7698\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.8554 - val_loss: 0.5538 - val_accuracy: 0.8310\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3502 - accuracy: 0.9000 - val_loss: 0.4970 - val_accuracy: 0.8448\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2740 - accuracy: 0.9222 - val_loss: 0.4716 - val_accuracy: 0.8580\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.9460 - val_loss: 0.4568 - val_accuracy: 0.8556\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.9546 - val_loss: 0.4523 - val_accuracy: 0.8602\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1523 - accuracy: 0.9670 - val_loss: 0.4441 - val_accuracy: 0.8650\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1280 - accuracy: 0.9762 - val_loss: 0.4297 - val_accuracy: 0.8676\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.9802 - val_loss: 0.4425 - val_accuracy: 0.8668\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0918 - accuracy: 0.9856 - val_loss: 0.4400 - val_accuracy: 0.8692\n",
      "157/157 [==============================] - 0s 646us/step - loss: 0.4400 - accuracy: 0.8692\n",
      "Training model with hidden size: 16 and L1 regularization parameter: 0.001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.2386 - accuracy: 0.6162 - val_loss: 0.7871 - val_accuracy: 0.7714\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.8686 - val_loss: 0.5841 - val_accuracy: 0.8348\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3553 - accuracy: 0.9128 - val_loss: 0.5009 - val_accuracy: 0.8492\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.9304 - val_loss: 0.4956 - val_accuracy: 0.8524\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9442 - val_loss: 0.4764 - val_accuracy: 0.8560\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2050 - accuracy: 0.9598 - val_loss: 0.4680 - val_accuracy: 0.8652\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.9674 - val_loss: 0.4871 - val_accuracy: 0.8540\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9776 - val_loss: 0.4725 - val_accuracy: 0.8596\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1356 - accuracy: 0.9808 - val_loss: 0.4652 - val_accuracy: 0.8616\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1168 - accuracy: 0.9886 - val_loss: 0.4743 - val_accuracy: 0.8608\n",
      "157/157 [==============================] - 0s 652us/step - loss: 0.4743 - accuracy: 0.8608\n",
      "Training model with hidden size: 16 and L1 regularization parameter: 0.01\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.4672 - accuracy: 0.5724 - val_loss: 1.1822 - val_accuracy: 0.6940\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.7806 - accuracy: 0.8474 - val_loss: 0.8450 - val_accuracy: 0.8080\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.5881 - accuracy: 0.8908 - val_loss: 0.7418 - val_accuracy: 0.8324\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.9194 - val_loss: 0.6704 - val_accuracy: 0.8534\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4247 - accuracy: 0.9404 - val_loss: 0.6432 - val_accuracy: 0.8570\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3716 - accuracy: 0.9516 - val_loss: 0.6401 - val_accuracy: 0.8558\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.9628 - val_loss: 0.6036 - val_accuracy: 0.8584\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.9736 - val_loss: 0.6123 - val_accuracy: 0.8608\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2729 - accuracy: 0.9808 - val_loss: 0.5915 - val_accuracy: 0.8628\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.9850 - val_loss: 0.6032 - val_accuracy: 0.8570\n",
      "157/157 [==============================] - 0s 646us/step - loss: 0.6032 - accuracy: 0.8570\n",
      "Training model with hidden size: 16 and L1 regularization parameter: 0.1\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 2.0994 - accuracy: 0.3524 - val_loss: 1.9393 - val_accuracy: 0.4564\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.6052 - accuracy: 0.7002 - val_loss: 1.5535 - val_accuracy: 0.7372\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.2676 - accuracy: 0.8266 - val_loss: 1.2915 - val_accuracy: 0.7968\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.0169 - accuracy: 0.9000 - val_loss: 1.1153 - val_accuracy: 0.8374\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.8717 - accuracy: 0.9248 - val_loss: 1.0385 - val_accuracy: 0.8440\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.7759 - accuracy: 0.9366 - val_loss: 0.9717 - val_accuracy: 0.8478\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.7021 - accuracy: 0.9488 - val_loss: 0.9360 - val_accuracy: 0.8536\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.9582 - val_loss: 0.9090 - val_accuracy: 0.8548\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.5982 - accuracy: 0.9626 - val_loss: 0.8989 - val_accuracy: 0.8526\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.9662 - val_loss: 0.8779 - val_accuracy: 0.8474\n",
      "157/157 [==============================] - 0s 774us/step - loss: 0.8779 - accuracy: 0.8474\n",
      "Training model with hidden size: 32 and L1 regularization parameter: 1e-05\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.0079 - accuracy: 0.6726 - val_loss: 0.6688 - val_accuracy: 0.7880\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3963 - accuracy: 0.8858 - val_loss: 0.4849 - val_accuracy: 0.8532\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2730 - accuracy: 0.9264 - val_loss: 0.4392 - val_accuracy: 0.8612\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.9462 - val_loss: 0.4312 - val_accuracy: 0.8680\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9602 - val_loss: 0.4561 - val_accuracy: 0.8584\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1217 - accuracy: 0.9726 - val_loss: 0.4450 - val_accuracy: 0.8594\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0966 - accuracy: 0.9822 - val_loss: 0.4498 - val_accuracy: 0.8640\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9864 - val_loss: 0.4564 - val_accuracy: 0.8686\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9908 - val_loss: 0.4582 - val_accuracy: 0.8652\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0457 - accuracy: 0.9956 - val_loss: 0.4745 - val_accuracy: 0.8644\n",
      "157/157 [==============================] - 0s 729us/step - loss: 0.4745 - accuracy: 0.8644\n",
      "Training model with hidden size: 32 and L1 regularization parameter: 0.0001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 0.9749 - accuracy: 0.6946 - val_loss: 0.6346 - val_accuracy: 0.8056\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3862 - accuracy: 0.8830 - val_loss: 0.5084 - val_accuracy: 0.8414\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2695 - accuracy: 0.9244 - val_loss: 0.4505 - val_accuracy: 0.8606\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9472 - val_loss: 0.4342 - val_accuracy: 0.8650\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1642 - accuracy: 0.9598 - val_loss: 0.4331 - val_accuracy: 0.8644\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1243 - accuracy: 0.9720 - val_loss: 0.4396 - val_accuracy: 0.8654\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1006 - accuracy: 0.9824 - val_loss: 0.4456 - val_accuracy: 0.8616\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9886 - val_loss: 0.4387 - val_accuracy: 0.8694\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0648 - accuracy: 0.9932 - val_loss: 0.4632 - val_accuracy: 0.8634\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9950 - val_loss: 0.4609 - val_accuracy: 0.8664\n",
      "157/157 [==============================] - 0s 658us/step - loss: 0.4609 - accuracy: 0.8664\n",
      "Training model with hidden size: 32 and L1 regularization parameter: 0.001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.0258 - accuracy: 0.6862 - val_loss: 0.6956 - val_accuracy: 0.8004\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.8854 - val_loss: 0.5240 - val_accuracy: 0.8508\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3088 - accuracy: 0.9294 - val_loss: 0.4910 - val_accuracy: 0.8584\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.9472 - val_loss: 0.4553 - val_accuracy: 0.8674\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2020 - accuracy: 0.9632 - val_loss: 0.4570 - val_accuracy: 0.8686\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9746 - val_loss: 0.4636 - val_accuracy: 0.8680\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1370 - accuracy: 0.9836 - val_loss: 0.4572 - val_accuracy: 0.8740\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.1134 - accuracy: 0.9908 - val_loss: 0.4637 - val_accuracy: 0.8704\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.0983 - accuracy: 0.9946 - val_loss: 0.4654 - val_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9968 - val_loss: 0.4691 - val_accuracy: 0.8694\n",
      "157/157 [==============================] - 0s 806us/step - loss: 0.4691 - accuracy: 0.8694\n",
      "Training model with hidden size: 32 and L1 regularization parameter: 0.01\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.2633 - accuracy: 0.6716 - val_loss: 0.9485 - val_accuracy: 0.7934\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.6626 - accuracy: 0.8830 - val_loss: 0.7460 - val_accuracy: 0.8472\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.5183 - accuracy: 0.9232 - val_loss: 0.6580 - val_accuracy: 0.8682\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.9468 - val_loss: 0.6320 - val_accuracy: 0.8686\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.9650 - val_loss: 0.5999 - val_accuracy: 0.8758\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.9760 - val_loss: 0.6009 - val_accuracy: 0.8708\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2825 - accuracy: 0.9838 - val_loss: 0.5963 - val_accuracy: 0.8696\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9912 - val_loss: 0.5685 - val_accuracy: 0.8730\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9936 - val_loss: 0.5682 - val_accuracy: 0.8710\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.9968 - val_loss: 0.5566 - val_accuracy: 0.8780\n",
      "157/157 [==============================] - 0s 665us/step - loss: 0.5566 - accuracy: 0.8780\n",
      "Training model with hidden size: 32 and L1 regularization parameter: 0.1\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 2.1286 - accuracy: 0.3816 - val_loss: 1.9850 - val_accuracy: 0.4574\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.6571 - accuracy: 0.6834 - val_loss: 1.6060 - val_accuracy: 0.6826\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3438 - accuracy: 0.7818 - val_loss: 1.3492 - val_accuracy: 0.7572\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 1.1340 - accuracy: 0.8378 - val_loss: 1.1981 - val_accuracy: 0.7920\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9879 - accuracy: 0.8818 - val_loss: 1.1010 - val_accuracy: 0.8068\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8825 - accuracy: 0.9060 - val_loss: 1.0418 - val_accuracy: 0.8354\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7824 - accuracy: 0.9314 - val_loss: 0.9717 - val_accuracy: 0.8536\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.9442 - val_loss: 0.9113 - val_accuracy: 0.8592\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.9562 - val_loss: 0.9055 - val_accuracy: 0.8506\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.5968 - accuracy: 0.9614 - val_loss: 0.8654 - val_accuracy: 0.8600\n",
      "157/157 [==============================] - 0s 665us/step - loss: 0.8654 - accuracy: 0.8600\n",
      "Training model with hidden size: 64 and L1 regularization parameter: 1e-05\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 0.8306 - accuracy: 0.7348 - val_loss: 0.5378 - val_accuracy: 0.8276\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.9060 - val_loss: 0.4592 - val_accuracy: 0.8488\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9380 - val_loss: 0.4361 - val_accuracy: 0.8556\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1504 - accuracy: 0.9612 - val_loss: 0.4442 - val_accuracy: 0.8648\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9786 - val_loss: 0.4330 - val_accuracy: 0.8670\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9878 - val_loss: 0.4463 - val_accuracy: 0.8650\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9944 - val_loss: 0.4529 - val_accuracy: 0.8630\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9972 - val_loss: 0.4555 - val_accuracy: 0.8646\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9986 - val_loss: 0.4637 - val_accuracy: 0.8676\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.8676\n",
      "157/157 [==============================] - 0s 722us/step - loss: 0.4668 - accuracy: 0.8676\n",
      "Training model with hidden size: 64 and L1 regularization parameter: 0.0001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 0.8164 - accuracy: 0.7400 - val_loss: 0.5260 - val_accuracy: 0.8344\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.9078 - val_loss: 0.4445 - val_accuracy: 0.8602\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9434 - val_loss: 0.4168 - val_accuracy: 0.8728\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1587 - accuracy: 0.9612 - val_loss: 0.4454 - val_accuracy: 0.8602\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9786 - val_loss: 0.4445 - val_accuracy: 0.8698\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9878 - val_loss: 0.4294 - val_accuracy: 0.8714\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9932 - val_loss: 0.4440 - val_accuracy: 0.8728\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9978 - val_loss: 0.4552 - val_accuracy: 0.8724\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9988 - val_loss: 0.4390 - val_accuracy: 0.8780\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9998 - val_loss: 0.4595 - val_accuracy: 0.8754\n",
      "157/157 [==============================] - 0s 684us/step - loss: 0.4595 - accuracy: 0.8754\n",
      "Training model with hidden size: 64 and L1 regularization parameter: 0.001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 0.8751 - accuracy: 0.7400 - val_loss: 0.6015 - val_accuracy: 0.8306\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.9082 - val_loss: 0.5018 - val_accuracy: 0.8620\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.9422 - val_loss: 0.4807 - val_accuracy: 0.8692\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2042 - accuracy: 0.9670 - val_loss: 0.4954 - val_accuracy: 0.8614\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1568 - accuracy: 0.9816 - val_loss: 0.4571 - val_accuracy: 0.8736\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1266 - accuracy: 0.9914 - val_loss: 0.4608 - val_accuracy: 0.8724\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1008 - accuracy: 0.9980 - val_loss: 0.4493 - val_accuracy: 0.8756\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9986 - val_loss: 0.4452 - val_accuracy: 0.8792\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 0.9996 - val_loss: 0.4443 - val_accuracy: 0.8782\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9998 - val_loss: 0.4446 - val_accuracy: 0.8804\n",
      "157/157 [==============================] - 0s 838us/step - loss: 0.4446 - accuracy: 0.8804\n",
      "Training model with hidden size: 64 and L1 regularization parameter: 0.01\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.2074 - accuracy: 0.7198 - val_loss: 0.8804 - val_accuracy: 0.8300\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.9030 - val_loss: 0.7066 - val_accuracy: 0.8632\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.9374 - val_loss: 0.6445 - val_accuracy: 0.8720\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3963 - accuracy: 0.9648 - val_loss: 0.6031 - val_accuracy: 0.8802\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3303 - accuracy: 0.9806 - val_loss: 0.5832 - val_accuracy: 0.8766\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2842 - accuracy: 0.9872 - val_loss: 0.5608 - val_accuracy: 0.8802\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.9948 - val_loss: 0.5594 - val_accuracy: 0.8754\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.9978 - val_loss: 0.5465 - val_accuracy: 0.8772\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.9986 - val_loss: 0.5348 - val_accuracy: 0.8802\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9988 - val_loss: 0.5371 - val_accuracy: 0.8764\n",
      "157/157 [==============================] - 0s 722us/step - loss: 0.5371 - accuracy: 0.8764\n",
      "Training model with hidden size: 64 and L1 regularization parameter: 0.1\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 2.2242 - accuracy: 0.3366 - val_loss: 2.0240 - val_accuracy: 0.4886\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.6338 - accuracy: 0.7336 - val_loss: 1.5341 - val_accuracy: 0.7526\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.2616 - accuracy: 0.8600 - val_loss: 1.2758 - val_accuracy: 0.8132\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0478 - accuracy: 0.9010 - val_loss: 1.1325 - val_accuracy: 0.8430\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9062 - accuracy: 0.9260 - val_loss: 1.0531 - val_accuracy: 0.8540\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8073 - accuracy: 0.9394 - val_loss: 1.0016 - val_accuracy: 0.8574\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7272 - accuracy: 0.9528 - val_loss: 0.9576 - val_accuracy: 0.8530\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6642 - accuracy: 0.9598 - val_loss: 0.9254 - val_accuracy: 0.8582\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.9646 - val_loss: 0.9133 - val_accuracy: 0.8496\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.5728 - accuracy: 0.9686 - val_loss: 0.8910 - val_accuracy: 0.8482\n",
      "157/157 [==============================] - 0s 710us/step - loss: 0.8910 - accuracy: 0.8482\n",
      "Training model with hidden size: 128 and L1 regularization parameter: 1e-05\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.7232 - accuracy: 0.7748 - val_loss: 0.5016 - val_accuracy: 0.8384\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2798 - accuracy: 0.9158 - val_loss: 0.4496 - val_accuracy: 0.8584\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9550 - val_loss: 0.4244 - val_accuracy: 0.8658\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9766 - val_loss: 0.4266 - val_accuracy: 0.8676\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9876 - val_loss: 0.4291 - val_accuracy: 0.8684\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9948 - val_loss: 0.4662 - val_accuracy: 0.8640\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 0.9988 - val_loss: 0.4272 - val_accuracy: 0.8780\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0159 - accuracy: 0.9998 - val_loss: 0.4249 - val_accuracy: 0.8800\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.8830\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.8812\n",
      "157/157 [==============================] - 0s 729us/step - loss: 0.4408 - accuracy: 0.8812\n",
      "Training model with hidden size: 128 and L1 regularization parameter: 0.0001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.7026 - accuracy: 0.7748 - val_loss: 0.4909 - val_accuracy: 0.8472\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2854 - accuracy: 0.9166 - val_loss: 0.4687 - val_accuracy: 0.8570\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.9546 - val_loss: 0.4413 - val_accuracy: 0.8640\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.9766 - val_loss: 0.4443 - val_accuracy: 0.8668\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0788 - accuracy: 0.9876 - val_loss: 0.4724 - val_accuracy: 0.8566\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9958 - val_loss: 0.4440 - val_accuracy: 0.8704\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.9992 - val_loss: 0.4272 - val_accuracy: 0.8776\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9996 - val_loss: 0.4237 - val_accuracy: 0.8780\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.8772\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.8774\n",
      "157/157 [==============================] - 0s 742us/step - loss: 0.4363 - accuracy: 0.8774\n",
      "Training model with hidden size: 128 and L1 regularization parameter: 0.001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.7852 - accuracy: 0.7730 - val_loss: 0.6121 - val_accuracy: 0.8350\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3517 - accuracy: 0.9216 - val_loss: 0.5143 - val_accuracy: 0.8604\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9642 - val_loss: 0.5083 - val_accuracy: 0.8638\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1711 - accuracy: 0.9828 - val_loss: 0.4843 - val_accuracy: 0.8660\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1334 - accuracy: 0.9910 - val_loss: 0.4462 - val_accuracy: 0.8774\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9984 - val_loss: 0.4393 - val_accuracy: 0.8786\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0868 - accuracy: 0.9994 - val_loss: 0.4310 - val_accuracy: 0.8822\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.8794\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.8842\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.8830\n",
      "157/157 [==============================] - 0s 780us/step - loss: 0.4180 - accuracy: 0.8830\n",
      "Training model with hidden size: 128 and L1 regularization parameter: 0.01\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.1696 - accuracy: 0.7552 - val_loss: 0.8898 - val_accuracy: 0.8462\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.9184 - val_loss: 0.7431 - val_accuracy: 0.8656\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.9550 - val_loss: 0.6671 - val_accuracy: 0.8778\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3793 - accuracy: 0.9764 - val_loss: 0.6244 - val_accuracy: 0.8780\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3131 - accuracy: 0.9880 - val_loss: 0.5907 - val_accuracy: 0.8836\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.9954 - val_loss: 0.5794 - val_accuracy: 0.8832\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.9972 - val_loss: 0.5714 - val_accuracy: 0.8778\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1996 - accuracy: 0.9988 - val_loss: 0.5590 - val_accuracy: 0.8822\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9994 - val_loss: 0.5429 - val_accuracy: 0.8806\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 1.0000 - val_loss: 0.5404 - val_accuracy: 0.8796\n",
      "157/157 [==============================] - 0s 914us/step - loss: 0.5404 - accuracy: 0.8796\n",
      "Training model with hidden size: 128 and L1 regularization parameter: 0.1\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 2.3384 - accuracy: 0.2806 - val_loss: 2.1042 - val_accuracy: 0.3802\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.8639 - accuracy: 0.5332 - val_loss: 1.8040 - val_accuracy: 0.5168\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.5640 - accuracy: 0.6448 - val_loss: 1.5181 - val_accuracy: 0.6226\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.2922 - accuracy: 0.7262 - val_loss: 1.3261 - val_accuracy: 0.7562\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1042 - accuracy: 0.8358 - val_loss: 1.2063 - val_accuracy: 0.7748\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9972 - accuracy: 0.8526 - val_loss: 1.1349 - val_accuracy: 0.7846\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.9161 - accuracy: 0.8676 - val_loss: 1.0977 - val_accuracy: 0.7838\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8573 - accuracy: 0.8712 - val_loss: 1.0681 - val_accuracy: 0.7798\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8078 - accuracy: 0.8812 - val_loss: 1.0500 - val_accuracy: 0.7796\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7375 - accuracy: 0.9134 - val_loss: 1.0054 - val_accuracy: 0.8082\n",
      "157/157 [==============================] - 0s 831us/step - loss: 1.0054 - accuracy: 0.8082\n",
      "Training model with hidden size: 256 and L1 regularization parameter: 1e-05\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6502 - accuracy: 0.7834 - val_loss: 0.4698 - val_accuracy: 0.8492\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9268 - val_loss: 0.4759 - val_accuracy: 0.8498\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1276 - accuracy: 0.9650 - val_loss: 0.4253 - val_accuracy: 0.8686\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9858 - val_loss: 0.4549 - val_accuracy: 0.8670\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9952 - val_loss: 0.4645 - val_accuracy: 0.8656\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9988 - val_loss: 0.4281 - val_accuracy: 0.8728\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9992 - val_loss: 0.4299 - val_accuracy: 0.8786\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.8790\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.8824\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8818\n",
      "157/157 [==============================] - 0s 876us/step - loss: 0.4393 - accuracy: 0.8818\n",
      "Training model with hidden size: 256 and L1 regularization parameter: 0.0001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.6705 - accuracy: 0.7870 - val_loss: 0.5343 - val_accuracy: 0.8256\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2555 - accuracy: 0.9282 - val_loss: 0.4096 - val_accuracy: 0.8756\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1366 - accuracy: 0.9682 - val_loss: 0.4633 - val_accuracy: 0.8608\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9864 - val_loss: 0.4171 - val_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9956 - val_loss: 0.4263 - val_accuracy: 0.8788\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.8886\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9996 - val_loss: 0.3911 - val_accuracy: 0.8874\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9998 - val_loss: 0.3892 - val_accuracy: 0.8896\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.8896\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.8916\n",
      "157/157 [==============================] - 0s 889us/step - loss: 0.3857 - accuracy: 0.8916\n",
      "Training model with hidden size: 256 and L1 regularization parameter: 0.001\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.7781 - accuracy: 0.7814 - val_loss: 0.5840 - val_accuracy: 0.8510\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.9368 - val_loss: 0.5059 - val_accuracy: 0.8686\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.9736 - val_loss: 0.4646 - val_accuracy: 0.8776\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1524 - accuracy: 0.9928 - val_loss: 0.4490 - val_accuracy: 0.8818\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1155 - accuracy: 0.9988 - val_loss: 0.4289 - val_accuracy: 0.8868\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0956 - accuracy: 0.9994 - val_loss: 0.4171 - val_accuracy: 0.8868\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8882\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.8898\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8930\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.8912\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3919 - accuracy: 0.8912\n",
      "Training model with hidden size: 256 and L1 regularization parameter: 0.01\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 1.1891 - accuracy: 0.7820 - val_loss: 0.9117 - val_accuracy: 0.8478\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.9258 - val_loss: 0.7499 - val_accuracy: 0.8722\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.9626 - val_loss: 0.6682 - val_accuracy: 0.8782\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3670 - accuracy: 0.9838 - val_loss: 0.6220 - val_accuracy: 0.8800\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.9924 - val_loss: 0.6059 - val_accuracy: 0.8780\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2499 - accuracy: 0.9966 - val_loss: 0.5655 - val_accuracy: 0.8866\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.9984 - val_loss: 0.5602 - val_accuracy: 0.8818\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.9996 - val_loss: 0.5401 - val_accuracy: 0.8806\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9998 - val_loss: 0.5373 - val_accuracy: 0.8808\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 0.9998 - val_loss: 0.5289 - val_accuracy: 0.8816\n",
      "157/157 [==============================] - 0s 901us/step - loss: 0.5289 - accuracy: 0.8816\n",
      "Training model with hidden size: 256 and L1 regularization parameter: 0.1\n",
      "Epoch 1/10\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 2.4466 - accuracy: 0.2426 - val_loss: 2.1555 - val_accuracy: 0.3888\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.8639 - accuracy: 0.5384 - val_loss: 1.7612 - val_accuracy: 0.5462\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.6149 - accuracy: 0.5916 - val_loss: 1.6294 - val_accuracy: 0.5620\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.4992 - accuracy: 0.6080 - val_loss: 1.5524 - val_accuracy: 0.5836\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.3399 - accuracy: 0.6628 - val_loss: 1.3330 - val_accuracy: 0.6460\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.1241 - accuracy: 0.7242 - val_loss: 1.2633 - val_accuracy: 0.6678\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 1.0403 - accuracy: 0.8012 - val_loss: 1.2152 - val_accuracy: 0.7260\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9747 - accuracy: 0.8260 - val_loss: 1.1685 - val_accuracy: 0.7388\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.9193 - accuracy: 0.8422 - val_loss: 1.1419 - val_accuracy: 0.7434\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.8710 - accuracy: 0.8658 - val_loss: 1.1139 - val_accuracy: 0.7526\n",
      "157/157 [==============================] - 0s 972us/step - loss: 1.1139 - accuracy: 0.7526\n",
      "hidden_size: 256 reg_l1_param: 0.0001 Test accuracy: 0.8916000127792358\n",
      "hidden_size: 256 reg_l1_param: 0.001 Test accuracy: 0.8912000060081482\n",
      "hidden_size: 128 reg_l1_param: 0.001 Test accuracy: 0.8830000162124634\n",
      "hidden_size: 256 reg_l1_param: 1e-05 Test accuracy: 0.8817999958992004\n",
      "hidden_size: 256 reg_l1_param: 0.01 Test accuracy: 0.881600022315979\n",
      "hidden_size: 128 reg_l1_param: 1e-05 Test accuracy: 0.8812000155448914\n",
      "hidden_size: 64 reg_l1_param: 0.001 Test accuracy: 0.8804000020027161\n",
      "hidden_size: 128 reg_l1_param: 0.01 Test accuracy: 0.8795999884605408\n",
      "hidden_size: 32 reg_l1_param: 0.01 Test accuracy: 0.878000020980835\n",
      "hidden_size: 128 reg_l1_param: 0.0001 Test accuracy: 0.8773999810218811\n",
      "hidden_size: 64 reg_l1_param: 0.01 Test accuracy: 0.8763999938964844\n",
      "hidden_size: 64 reg_l1_param: 0.0001 Test accuracy: 0.8754000067710876\n",
      "hidden_size: 32 reg_l1_param: 0.001 Test accuracy: 0.8694000244140625\n",
      "hidden_size: 16 reg_l1_param: 0.0001 Test accuracy: 0.8691999912261963\n",
      "hidden_size: 64 reg_l1_param: 1e-05 Test accuracy: 0.8676000237464905\n",
      "hidden_size: 16 reg_l1_param: 1e-05 Test accuracy: 0.8669999837875366\n",
      "hidden_size: 32 reg_l1_param: 0.0001 Test accuracy: 0.8664000034332275\n",
      "hidden_size: 32 reg_l1_param: 1e-05 Test accuracy: 0.8644000291824341\n",
      "hidden_size: 16 reg_l1_param: 0.001 Test accuracy: 0.86080002784729\n",
      "hidden_size: 32 reg_l1_param: 0.1 Test accuracy: 0.8600000143051147\n",
      "hidden_size: 16 reg_l1_param: 0.01 Test accuracy: 0.8569999933242798\n",
      "hidden_size: 64 reg_l1_param: 0.1 Test accuracy: 0.8482000231742859\n",
      "hidden_size: 16 reg_l1_param: 0.1 Test accuracy: 0.8474000096321106\n",
      "hidden_size: 128 reg_l1_param: 0.1 Test accuracy: 0.8082000017166138\n",
      "hidden_size: 256 reg_l1_param: 0.1 Test accuracy: 0.7526000142097473\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def create_model(hidden_size=32, reg_l1_param=10e-5):\n",
    "    input_tensor = tf.keras.Input(shape=(1024,))\n",
    "    hidden_layer_1 = tf.keras.layers.Dense(units=hidden_size, activation=tf.nn.relu,\n",
    "                                           name='hidden_layer',\n",
    "                                           activity_regularizer=tf.keras.regularizers.l1(reg_l1_param))(input_tensor)\n",
    "    output_layer = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax, name='classification_layer')(hidden_layer_1)\n",
    "    model = tf.keras.Model(inputs=input_tensor, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "param_grid = {'hidden_size': [16, 32, 64, 128, 256],\n",
    "              'reg_l1_param': [0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for hs in param_grid['hidden_size']:\n",
    "    for l1 in param_grid['reg_l1_param']:\n",
    "        print('Training model with hidden size:', hs, 'and L1 regularization parameter:', l1)\n",
    "        model = create_model(hidden_size=hs, reg_l1_param=l1)\n",
    "        history = model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(test_data, test_labels))\n",
    "        test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "        results[(hs,l1)] = {'test_accuracy': test_acc, 'model': model}\n",
    "\n",
    "# Print the results in descending order of test accuracy\n",
    "sorted_results = sorted(results.items(), key=lambda x: -x[1]['test_accuracy'])\n",
    "\n",
    "for (hs, l1), result in sorted_results:\n",
    "    print('hidden_size:', hs, 'reg_l1_param:', l1, 'Test accuracy:', result['test_accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fed1f7d-8ba7-485e-a857-4c084a62a4cb",
   "metadata": {},
   "source": [
    "#### Based on the given results, the best choice would be a model with ***hidden_size = 256*** and ***reg_l1_param = 0.0001*** as it has the highest test accuracy.\n",
    "* #### The reg_l1_param is known as L1 regularization parameter which adds an L1 penalty to the loss function and helps in preventing overfitting of the model by reducing the complexity of the model. \n",
    "* #### Keeping the hidden_size at 256 allows the model to have sufficient capacity to capture complex relationships within the data while also being able to generalize well to unseen data.\n",
    "* #### It's important to note that the model is not overfitted because the test accuracy is close to the training accuracy. If there was overfitting, we would see a large gap between the training accuracy and the test accuracy, meaning that the model is not generalizing well to new data. Therefore, a model with high training accuracy and low test accuracy would indicate overfitting. However, in this case, the difference between the training and test accuracy is quite small, indicating that the chosen model can generalize well to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c5409bdb-f648-47f8-a943-bae1d9d04cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7549 - accuracy: 0.7602 - val_loss: 0.5105 - val_accuracy: 0.8376\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.9202 - val_loss: 0.4399 - val_accuracy: 0.8668\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9604 - val_loss: 0.4228 - val_accuracy: 0.8680\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9816 - val_loss: 0.4177 - val_accuracy: 0.8730\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9936 - val_loss: 0.4108 - val_accuracy: 0.8770\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9966 - val_loss: 0.4097 - val_accuracy: 0.8784\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9992 - val_loss: 0.4152 - val_accuracy: 0.8766\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.8820\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.8812\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.8824\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.8824\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.8830\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8850\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.8852\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8838\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.8836\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.8850\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.8852\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.8856\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9996 - val_loss: 0.4061 - val_accuracy: 0.8870\n",
      "157/157 [==============================] - 0s 876us/step - loss: 0.4061 - accuracy: 0.8870\n",
      "test accuracy: 0.8870000243186951\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tf.keras.Input(shape=(1024,))\n",
    "hidden_size = 256\n",
    "reg_l1_param = 0.0001\n",
    "\n",
    "hidden_layer_1 = tf.keras.layers.Dense(units=hidden_size, activation=tf.nn.relu,\n",
    "                                       name='hidden_layer',\n",
    "                                       activity_regularizer=tf.keras.regularizers.l1(reg_l1_param))(input_tensor)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax, name='classification_layer')(hidden_layer_1)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, train_labels, epochs=20, batch_size=64, validation_data=(test_data, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print(f'test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f4d7c8-e862-4317-b194-246477565bd8",
   "metadata": {},
   "source": [
    "#### Get the weights connecting the input layer to the first hidden layer and then compute the average absolute weight for each input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2119601-55d0-4288-bb8c-d567cc4c4cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc0711-f286-4c2f-8240-86b48fe12e17",
   "metadata": {},
   "source": [
    "#### Here, I used three methods to select the best features with the help of a neural network:\n",
    "\n",
    "* #### Method 1: I ran the neural network only once on all 1024 input features and then obtained the most important features by sorting the average weights. After that, I tested the SVM model on different subsets of features and calculated its accuracy based on the penalty value.\n",
    "\n",
    "* #### Method 2: In this method, I repeatedly trained the neural network and in each iteration, I used the selected features from the previous step to train the new network. I continued this process to select the appropriate features until finally feeding them to the SVM model.\n",
    "\n",
    "* #### Method 3: In this method, I repeatedly trained the neural network and in each iteration, I obtained the best features from the model, and then used the remaining features from the previous step to train the new network. I continued this process in different situations with different number of features and different number of iterations to select the appropriate number of features until finally feeding them to the SVM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dce7e7-a57e-43a8-945b-88e27d86f448",
   "metadata": {},
   "source": [
    "### First Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41174099-2d0e-4b17-88f4-34a302c9a87a",
   "metadata": {},
   "source": [
    "Train the *SVM* model on the top 500 features that is achieved from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57299803-4aca-4b06-bf88-25cb945188f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 500\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "# Extract only the selected features from the training and testing data\n",
    "train_data1 = train_data[:, top_features]\n",
    "test_data1 = test_data[:, top_features]\n",
    "\n",
    "# fit classifier to training set\n",
    "svc.fit(train_data1,train_labels)\n",
    "\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(test_data1)\n",
    "\n",
    "# compute and print accuracy score\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5643dea0-bcec-423f-97f8-11e1a04ce65d",
   "metadata": {},
   "source": [
    "Train the *SVM* model on the top 100 features that is achieved from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fec1748-4055-4f77-ab7a-2cbd4f5b9a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 0.7976\n"
     ]
    }
   ],
   "source": [
    "top_k = 100\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "train_data2 = train_data[:, top_features]\n",
    "test_data2 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data2,train_labels)\n",
    "y_pred=svc.predict(test_data2)\n",
    "\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33a81b-bd26-49e8-9366-5923a4dd381b",
   "metadata": {},
   "source": [
    "Train the *SVM* model on the top 50 features that is achieved from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4f63a32-6203-48a7-b9a1-2db52fbd5ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 0.7739\n"
     ]
    }
   ],
   "source": [
    "top_k = 50\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "train_data3 = train_data[:, top_features]\n",
    "test_data3 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data3,train_labels)\n",
    "y_pred=svc.predict(test_data3)\n",
    "\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6964bd-8d5c-49ab-9bbc-e382f097c04a",
   "metadata": {},
   "source": [
    "Train the *SVM* model on the top 150 features that is achieved from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a105554-c79b-4175-a9ef-683182823dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 0.7699\n"
     ]
    }
   ],
   "source": [
    "top_k = 150\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "train_data4 = train_data[:, top_features]\n",
    "test_data4 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data4,train_labels)\n",
    "y_pred=svc.predict(test_data4)\n",
    "\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b90fe-6079-40e3-8a94-11d24a89eb2f",
   "metadata": {},
   "source": [
    "Train the *SVM* model on the top 200 features that is achieved from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c663fb8a-6e5a-4d63-8619-9b1224b20bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 0.7410\n"
     ]
    }
   ],
   "source": [
    "top_k = 200\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "train_data5 = train_data[:, top_features]\n",
    "test_data5 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data5,train_labels)\n",
    "y_pred=svc.predict(test_data5)\n",
    "\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3e70cc-5de5-4a32-95c9-dca34b1bb080",
   "metadata": {},
   "source": [
    "Train the *SVM* model on the top 130 features that is achieved from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50a61800-28d2-4211-9c6d-47b491c21f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 0.7787\n"
     ]
    }
   ],
   "source": [
    "top_k = 130\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "train_data6 = train_data[:, top_features]\n",
    "test_data6 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data6,train_labels)\n",
    "y_pred=svc.predict(test_data6)\n",
    "\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d2f64-1f8c-4dad-9cca-7ed22bdc7963",
   "metadata": {},
   "source": [
    "Train the *SVM* model on the top 115 features that is achieved from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "134ba702-7ffa-40e9-9b54-c09320de138c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 0.7827\n"
     ]
    }
   ],
   "source": [
    "top_k = 115\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "train_data7 = train_data[:, top_features]\n",
    "test_data7 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data7,train_labels)\n",
    "y_pred=svc.predict(test_data7)\n",
    "\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a302ca6-452e-46bf-9911-47c3c4c74ed2",
   "metadata": {},
   "source": [
    "Train the *SVM* model on the top 105 features that is achieved from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18e3aa8b-f32c-41e2-8fe2-cf4e1088d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 0.7883\n"
     ]
    }
   ],
   "source": [
    "top_k = 105\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "train_data8 = train_data[:, top_features]\n",
    "test_data8 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data8,train_labels)\n",
    "y_pred=svc.predict(test_data8)\n",
    "\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee63ec3-150f-4bc7-8a74-87a2ee39077c",
   "metadata": {},
   "source": [
    "Train the *SVM* model on the top 90 features that is achieved from Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8059e4ae-25a9-48ff-a4ed-ef099c8b85c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 0.7891\n"
     ]
    }
   ],
   "source": [
    "top_k = 90\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "train_data9 = train_data[:, top_features]\n",
    "test_data9 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data9,train_labels)\n",
    "y_pred=svc.predict(test_data9)\n",
    "\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa9ea8-68ed-4fb1-842d-a670c8891fee",
   "metadata": {},
   "source": [
    "### Second Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d7bca-4ec7-4df0-a640-d31369a6f90a",
   "metadata": {},
   "source": [
    "#### Initial The best Network Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ab9538ad-3e20-47e0-b03b-21bbc6437f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7386 - accuracy: 0.7656 - val_loss: 0.4902 - val_accuracy: 0.8502\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.9236 - val_loss: 0.5106 - val_accuracy: 0.8402\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9586 - val_loss: 0.4300 - val_accuracy: 0.8660\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9822 - val_loss: 0.4092 - val_accuracy: 0.8762\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0930 - accuracy: 0.9856 - val_loss: 0.4125 - val_accuracy: 0.8754\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9982 - val_loss: 0.4180 - val_accuracy: 0.8784\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9992 - val_loss: 0.4083 - val_accuracy: 0.8812\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0351 - accuracy: 0.9996 - val_loss: 0.4094 - val_accuracy: 0.8856\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.8838\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.8846\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.8854\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.8856\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.8854\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.8856\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.8866\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.8870\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.8858\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.8862\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.8860\n",
      "157/157 [==============================] - 0s 914us/step - loss: 0.4037 - accuracy: 0.8860\n",
      "test accuracy: 0.8859999775886536\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tf.keras.Input(shape=(1024,))\n",
    "hidden_size = 256\n",
    "reg_l1_param = 0.0001\n",
    "\n",
    "hidden_layer_1 = tf.keras.layers.Dense(units=hidden_size, activation=tf.nn.relu,\n",
    "                                       name='hidden_layer',\n",
    "                                       activity_regularizer=tf.keras.regularizers.l1(reg_l1_param))(input_tensor)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax, name='classification_layer')(hidden_layer_1)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_data, train_labels, epochs=20, batch_size=64, validation_data=(test_data, test_labels))\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print(f'test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "055d2715-705a-4185-89bb-3620f82fdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c937ccb-eb5c-447d-9604-f5f142787a1f",
   "metadata": {},
   "source": [
    "#### Train a network on the top 1000 features achieved from the base network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f571de2d-f90f-4d42-8378-44fe9000ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7626 - accuracy: 0.7618 - val_loss: 0.4908 - val_accuracy: 0.8498\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.9302 - val_loss: 0.4356 - val_accuracy: 0.8660\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1683 - accuracy: 0.9620 - val_loss: 0.4568 - val_accuracy: 0.8604\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1122 - accuracy: 0.9824 - val_loss: 0.4085 - val_accuracy: 0.8766\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9932 - val_loss: 0.4105 - val_accuracy: 0.8754\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9972 - val_loss: 0.4253 - val_accuracy: 0.8756\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9996 - val_loss: 0.4090 - val_accuracy: 0.8798\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.8804\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.8814\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.8820\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.8838\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8848\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.8846\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8852\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8858\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.8864\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.8858\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.8864\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.8880\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.8868\n",
      "157/157 [==============================] - 0s 908us/step - loss: 0.3941 - accuracy: 0.8868\n",
      "Test loss: 0.3940925896167755\n",
      "Test accuracy: 0.8867999911308289\n"
     ]
    }
   ],
   "source": [
    "# Get the indices of the top 1000 features\n",
    "top_k = 1000\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]\n",
    "\n",
    "# Select only the top 1000 features from the data arrays\n",
    "train_data_topk = train_data[:, top_features]\n",
    "test_data_topk = test_data[:, top_features]\n",
    "\n",
    "# Create a new model with input shape (1000,)\n",
    "input_tensor_topk = tf.keras.Input(shape=(top_k,))\n",
    "hidden_layer_1_topk = tf.keras.layers.Dense(units=hidden_size, activation=tf.nn.relu,\n",
    "                                            name='hidden_layer',\n",
    "                                            activity_regularizer=tf.keras.regularizers.l1(reg_l1_param))(input_tensor_topk)\n",
    "output_layer_topk = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax, name='classification_layer')(hidden_layer_1_topk)\n",
    "model_topk = tf.keras.Model(inputs=input_tensor_topk, outputs=output_layer_topk)\n",
    "\n",
    "# Compile and train the new model\n",
    "model_topk.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_topk.fit(train_data_topk, train_labels, epochs=20, batch_size=64, validation_data=(test_data_topk, test_labels))\n",
    "\n",
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)\n",
    "\n",
    "# Evaluate the model on the original test set\n",
    "test_loss, test_acc = model_topk.evaluate(test_data_topk, test_labels)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877165b2-547a-4c1f-aa4c-17ea2283b4ac",
   "metadata": {},
   "source": [
    "#### Train SVM on that based on the best 900 feateures of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "304ca595-870b-47be-a61f-d08a91fe3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "449b69ff-783d-4097-8f19-2311e0764454",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 900\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "a9293d84-deab-4b06-9031-217442108151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 0.2246\n"
     ]
    }
   ],
   "source": [
    "train_data1 = train_data[:, top_features]\n",
    "test_data1 = test_data[:, top_features]\n",
    "svc.fit(train_data1,train_labels)\n",
    "y_pred=svc.predict(test_data1)\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d06c4a-6f05-41d2-a25c-57158920d523",
   "metadata": {},
   "source": [
    "#### Train a network on the top 900 features achieved from the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2a3fb1c2-4125-449a-8970-c243543f91a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7642 - accuracy: 0.7554 - val_loss: 0.5104 - val_accuracy: 0.8462\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2853 - accuracy: 0.9222 - val_loss: 0.4416 - val_accuracy: 0.8656\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.9556 - val_loss: 0.4259 - val_accuracy: 0.8654\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1197 - accuracy: 0.9822 - val_loss: 0.4124 - val_accuracy: 0.8732\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9918 - val_loss: 0.4279 - val_accuracy: 0.8742\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9982 - val_loss: 0.4157 - val_accuracy: 0.8764\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0445 - accuracy: 0.9994 - val_loss: 0.4128 - val_accuracy: 0.8802\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9994 - val_loss: 0.4126 - val_accuracy: 0.8790\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.8834\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.8848\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.8860\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.8856\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.8860\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.8868\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.8834\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8858\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.8846\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.8868\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.8868\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.8876\n",
      "157/157 [==============================] - 0s 959us/step - loss: 0.4077 - accuracy: 0.8876\n",
      "Test loss: 0.40765729546546936\n",
      "Test accuracy: 0.8876000046730042\n"
     ]
    }
   ],
   "source": [
    "train_data_topk = train_data[:, top_features]\n",
    "test_data_topk = test_data[:, top_features]\n",
    "\n",
    "input_tensor_topk = tf.keras.Input(shape=(top_k,))\n",
    "hidden_layer_1_topk = tf.keras.layers.Dense(units=hidden_size, activation=tf.nn.relu,\n",
    "                                            name='hidden_layer',\n",
    "                                            activity_regularizer=tf.keras.regularizers.l1(reg_l1_param))(input_tensor_topk)\n",
    "output_layer_topk = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax, name='classification_layer')(hidden_layer_1_topk)\n",
    "model_topk = tf.keras.Model(inputs=input_tensor_topk, outputs=output_layer_topk)\n",
    "\n",
    "model_topk.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_topk.fit(train_data_topk, train_labels, epochs=20, batch_size=64, validation_data=(test_data_topk, test_labels))\n",
    "\n",
    "test_loss, test_acc = model_topk.evaluate(test_data_topk, test_labels)\n",
    "\n",
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f357eee-a2a2-472b-ba56-175b5006b3f3",
   "metadata": {},
   "source": [
    "#### Train SVM on that based on the best 750 feateures of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b2ee0a0b-cb75-45e1-a849-0c6d4debfd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)\n",
    "top_k = 750\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "c01fd273-ff6b-494f-bd42-a972ad131a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data2 = train_data[:, top_features]\n",
    "test_data2 = test_data[:, top_features]\n",
    "svc.fit(train_data2,train_labels)\n",
    "y_pred=svc.predict(test_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d6486d-c28f-4ca1-81d5-717a05fcaab4",
   "metadata": {},
   "source": [
    "#### Train a network on the top 750 features achieved from the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "cf018cfd-fbfc-4778-ba58-b758a740e4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8065 - accuracy: 0.7420 - val_loss: 0.5652 - val_accuracy: 0.8266\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.9134 - val_loss: 0.4667 - val_accuracy: 0.8582\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2068 - accuracy: 0.9514 - val_loss: 0.4522 - val_accuracy: 0.8666\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9678 - val_loss: 0.4317 - val_accuracy: 0.8712\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1116 - accuracy: 0.9830 - val_loss: 0.4375 - val_accuracy: 0.8714\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9932 - val_loss: 0.4405 - val_accuracy: 0.8696\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0711 - accuracy: 0.9958 - val_loss: 0.4403 - val_accuracy: 0.8762\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9984 - val_loss: 0.4400 - val_accuracy: 0.8772\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9994 - val_loss: 0.4467 - val_accuracy: 0.8770\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.8784\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.8758\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.8796\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.8790\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.8798\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.8776\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.8770\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.8812\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.8812\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.8804\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.8808\n",
      "157/157 [==============================] - 0s 933us/step - loss: 0.4416 - accuracy: 0.8808\n",
      "Test loss: 0.44157469272613525\n",
      "Test accuracy: 0.8808000087738037\n"
     ]
    }
   ],
   "source": [
    "train_data_topk = train_data[:, top_features]\n",
    "test_data_topk = test_data[:, top_features]\n",
    "\n",
    "input_tensor_topk = tf.keras.Input(shape=(top_k,))\n",
    "hidden_layer_1_topk = tf.keras.layers.Dense(units=hidden_size, activation=tf.nn.relu,\n",
    "                                            name='hidden_layer',\n",
    "                                            activity_regularizer=tf.keras.regularizers.l1(reg_l1_param))(input_tensor_topk)\n",
    "output_layer_topk = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax, name='classification_layer')(hidden_layer_1_topk)\n",
    "model_topk = tf.keras.Model(inputs=input_tensor_topk, outputs=output_layer_topk)\n",
    "\n",
    "model_topk.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_topk.fit(train_data_topk, train_labels, epochs=20, batch_size=64, validation_data=(test_data_topk, test_labels))\n",
    "\n",
    "test_loss, test_acc = model_topk.evaluate(test_data_topk, test_labels)\n",
    "\n",
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f419dcd-0dc6-43de-a50f-8c3da17a2854",
   "metadata": {},
   "source": [
    "#### Train SVM on that based on the best 450 feateures of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "cc4dffac-6be1-4b07-98f4-ce755103b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)\n",
    "top_k = 450\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9bcb2aad-0391-47bd-826d-43a00e533dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data3 = train_data[:, top_features]\n",
    "test_data3 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data3,train_labels)\n",
    "y_pred=svc.predict(test_data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cb0e8b-6591-442a-a230-3918485053a2",
   "metadata": {},
   "source": [
    "#### Train a network on the top 450 features achieved from the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297ed8c-db68-4c62-8918-8d482d23c247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.9500 - accuracy: 0.7052 - val_loss: 0.6752 - val_accuracy: 0.7934\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3998 - accuracy: 0.8874 - val_loss: 0.5225 - val_accuracy: 0.8404\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2857 - accuracy: 0.9252 - val_loss: 0.5002 - val_accuracy: 0.8430\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2138 - accuracy: 0.9554 - val_loss: 0.4850 - val_accuracy: 0.8480\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.9694 - val_loss: 0.4943 - val_accuracy: 0.8458\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9814 - val_loss: 0.4741 - val_accuracy: 0.8540\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9886 - val_loss: 0.4775 - val_accuracy: 0.8516\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9928 - val_loss: 0.4754 - val_accuracy: 0.8600\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0650 - accuracy: 0.9964 - val_loss: 0.4947 - val_accuracy: 0.8512\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9974 - val_loss: 0.4904 - val_accuracy: 0.8560\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9994 - val_loss: 0.4883 - val_accuracy: 0.8574\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.9996 - val_loss: 0.4991 - val_accuracy: 0.8572\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.8580\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.8592\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.8600\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.8618\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.8610\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.8592\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.8612\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.5138 - val_accuracy: 0.8600\n",
      "157/157 [==============================] - 0s 844us/step - loss: 0.5138 - accuracy: 0.8600\n",
      "Test loss: 0.5137681365013123\n",
      "Test accuracy: 0.8600000143051147\n"
     ]
    }
   ],
   "source": [
    "train_data_topk = train_data[:, top_features]\n",
    "test_data_topk = test_data[:, top_features]\n",
    "\n",
    "input_tensor_topk = tf.keras.Input(shape=(top_k,))\n",
    "hidden_layer_1_topk = tf.keras.layers.Dense(units=hidden_size, activation=tf.nn.relu,\n",
    "                                            name='hidden_layer',\n",
    "                                            activity_regularizer=tf.keras.regularizers.l1(reg_l1_param))(input_tensor_topk)\n",
    "output_layer_topk = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax, name='classification_layer')(hidden_layer_1_topk)\n",
    "model_topk = tf.keras.Model(inputs=input_tensor_topk, outputs=output_layer_topk)\n",
    "\n",
    "model_topk.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_topk.fit(train_data_topk, train_labels, epochs=20, batch_size=64, validation_data=(test_data_topk, test_labels))\n",
    "\n",
    "test_loss, test_acc = model_topk.evaluate(test_data_topk, test_labels)\n",
    "\n",
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a66c8-51ef-428c-b20b-d89a1e7c48b6",
   "metadata": {},
   "source": [
    "#### Train SVM on that based on the best 200 feateures of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2152e78-2c68-410a-8884-c2174b01a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)\n",
    "top_k = 200\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50145f55-ebb8-42bc-b4c1-774327e8fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data4 = train_data[:, top_features]\n",
    "test_data4 = test_data[:, top_features]\n",
    "\n",
    "svc.fit(train_data4,train_labels)\n",
    "y_pred=svc.predict(test_data4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31f203-276d-41c2-a837-816270ac0f1f",
   "metadata": {},
   "source": [
    "#### Train a network on the top 200 features achieved from the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805aa687-d6f6-4dd0-9b00-46cabc0e9cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 1.2980 - accuracy: 0.6022 - val_loss: 0.9941 - val_accuracy: 0.7002\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.8160 - val_loss: 0.7380 - val_accuracy: 0.7782\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8592 - val_loss: 0.6709 - val_accuracy: 0.7934\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4049 - accuracy: 0.8862 - val_loss: 0.6289 - val_accuracy: 0.8062\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3519 - accuracy: 0.9018 - val_loss: 0.6203 - val_accuracy: 0.8084\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.9198 - val_loss: 0.6287 - val_accuracy: 0.8048\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.9334 - val_loss: 0.6058 - val_accuracy: 0.8140\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.9424 - val_loss: 0.6151 - val_accuracy: 0.8104\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2113 - accuracy: 0.9554 - val_loss: 0.6182 - val_accuracy: 0.8126\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.9592 - val_loss: 0.6006 - val_accuracy: 0.8210\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1645 - accuracy: 0.9718 - val_loss: 0.6023 - val_accuracy: 0.8198\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1464 - accuracy: 0.9772 - val_loss: 0.6300 - val_accuracy: 0.8130\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1282 - accuracy: 0.9824 - val_loss: 0.6215 - val_accuracy: 0.8152\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1201 - accuracy: 0.9826 - val_loss: 0.6240 - val_accuracy: 0.8216\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.9904 - val_loss: 0.6307 - val_accuracy: 0.8218\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0947 - accuracy: 0.9922 - val_loss: 0.6364 - val_accuracy: 0.8206\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9958 - val_loss: 0.6602 - val_accuracy: 0.8212\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9966 - val_loss: 0.6545 - val_accuracy: 0.8202\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0626 - accuracy: 0.9988 - val_loss: 0.6633 - val_accuracy: 0.8208\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0555 - accuracy: 0.9990 - val_loss: 0.6653 - val_accuracy: 0.8226\n",
      "157/157 [==============================] - 0s 729us/step - loss: 0.6653 - accuracy: 0.8226\n",
      "Test loss: 0.6653305888175964\n",
      "Test accuracy: 0.8226000070571899\n"
     ]
    }
   ],
   "source": [
    "train_data_topk = train_data[:, top_features]\n",
    "test_data_topk = test_data[:, top_features]\n",
    "\n",
    "input_tensor_topk = tf.keras.Input(shape=(top_k,))\n",
    "hidden_layer_1_topk = tf.keras.layers.Dense(units=hidden_size, activation=tf.nn.relu,\n",
    "                                            name='hidden_layer',\n",
    "                                            activity_regularizer=tf.keras.regularizers.l1(reg_l1_param))(input_tensor_topk)\n",
    "output_layer_topk = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax, name='classification_layer')(hidden_layer_1_topk)\n",
    "model_topk = tf.keras.Model(inputs=input_tensor_topk, outputs=output_layer_topk)\n",
    "\n",
    "model_topk.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_topk.fit(train_data_topk, train_labels, epochs=20, batch_size=64, validation_data=(test_data_topk, test_labels))\n",
    "\n",
    "test_loss, test_acc = model_topk.evaluate(test_data_topk, test_labels)\n",
    "\n",
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c95f2-6969-43db-94d3-c476043852e1",
   "metadata": {},
   "source": [
    "#### Train SVM on that based on the best 100 feateures of the last network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91841748-a301-4143-98d6-931ea3cb53ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model_topk.layers[1].get_weights()[0]\n",
    "avg_weights = np.mean(np.abs(weights), axis=1)\n",
    "top_k = 100\n",
    "top_features = np.argsort(avg_weights)[::-1][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbb2d3c-f130-4be4-a9fb-d54cd2acc18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score with penalty = 0.00075 : 80.1205\n"
     ]
    }
   ],
   "source": [
    "train_data5 = train_data[:, top_features]\n",
    "test_data5 = test_data[:, top_features]\n",
    "svc.fit(train_data5,train_labels)\n",
    "y_pred=svc.predict(test_data5)\n",
    "print('Model score with penalty = 0.00075 : {0:0.4f}'. format(accuracy_score(test_labels, y_pred) - 0.00075*top_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed86e8c-b146-4f0c-8275-e3373e03077c",
   "metadata": {},
   "source": [
    "Finally, it can be seen that in both cases, the optimal number of features for us is around 100 because it gives us the best score according to the amount of penalty that we considered for each feature. Each of the used methods has advantages and disadvantages, for example, the second method may lead to overfitting. Because every time, we choose the selected features, and in fact, the variety of features and things like this are being less than the original dataset, and it may affect only a part of the data in a good way. Also, in the first method, we have trained the model only once, and it might be better to use the combination of the first and second method and even the combination of other methods and models to have a more comprehensive model. Enyway, according to the demands of practice, we have now achieved good accuracy And in order to achieve this accuracy and this number of features, in general, I implemented the two methods I mentioned earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9187b74-15a7-4f8c-8d33-40134a23007e",
   "metadata": {},
   "source": [
    "#### Third Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f0b2c8-3bc4-4ae2-9821-204a238866d5",
   "metadata": {},
   "source": [
    "#### In this part, i defined a function that receives 2 parameters:\n",
    "* #### num_iterations = number of iterations\n",
    "* #### num_features = number of features\n",
    "\n",
    "#### According to the previous parts, we know that the optimom number of features is most likely to be around 100. so, considering that this method may contain a wide range of possibilities and is hard and in fact 'impossible' to test all the conditions and combinations, so i tested some conditions that are around 100 features:\n",
    "* #### Totally 200 features:\n",
    "> #### iter = 10, feature per iter = 20\n",
    "> #### iter = 5, feature per iter = 40\n",
    "> #### iter = 2, feature per iter = 100\n",
    "\n",
    "* #### Totally 150 features:\n",
    "> #### iter = 3, feature per iter = 50\n",
    "> #### iter = 10, feature per iter = 15\n",
    "\n",
    "* #### Totally 100 features:\n",
    "> #### iter = 10, feature per iter = 10\n",
    "> #### iter = 4, feature per iter = 25\n",
    "> #### iter = 5, feature per iter = 20\n",
    "\n",
    "* #### Totally 80 features:\n",
    "> #### iter = 4, feature per iter = 20\n",
    "> #### iter = 5, feature per iter = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be5cae-b028-4571-b5e0-ce483aaa20dd",
   "metadata": {},
   "source": [
    "#### Defining the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cf06d29-0b7e-4644-9a8d-7730238123de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename: str) -> tuple:\n",
    "    data = np.load(f'{filename}')\n",
    "    return data['data'], data['labels']\n",
    "\n",
    "def model_feature_selection(num_iterations, num_features): \n",
    "\n",
    "    train_data, train_labels = load_data('train_data_SYN.npz')\n",
    "    test_data, test_labels = load_data('test_data_SYN.npz')\n",
    "\n",
    "    input_shape = (1024,)\n",
    "    hidden_size = 256\n",
    "    reg_l1_param = 0.0001\n",
    "\n",
    "    selected_indices = []\n",
    "    remaining_indices = np.arange(1024)\n",
    "\n",
    "    for i in range(num_iterations):\n",
    "        print(f'Iteration {i+1}/{num_iterations}')\n",
    "\n",
    "        # define model and input tensor based on remaining indices\n",
    "        input_tensor = tf.keras.Input(shape=(len(remaining_indices),))\n",
    "        hidden_layer_1 = tf.keras.layers.Dense(units=hidden_size, activation=tf.nn.relu,\n",
    "                                               name='hidden_layer',\n",
    "                                               activity_regularizer=tf.keras.regularizers.l1(reg_l1_param))(input_tensor)\n",
    "        output_layer = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax, name='classification_layer')(hidden_layer_1)\n",
    "        model = tf.keras.Model(inputs=input_tensor, outputs=output_layer)\n",
    "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # train the model and evaluate its performance\n",
    "        history = model.fit(train_data[:, remaining_indices], train_labels, epochs=20, batch_size=64, validation_data=(test_data[:, remaining_indices], test_labels))\n",
    "        test_loss, test_acc = model.evaluate(test_data[:, remaining_indices], test_labels)\n",
    "        print(f'test accuracy ({i+1}/{num_iterations}): {test_acc}')\n",
    "\n",
    "        # select top n features based on weights and sum\n",
    "        weights = model.get_layer('hidden_layer').get_weights()[0]\n",
    "        scores = np.abs(weights).sum(axis=1)\n",
    "        indices = scores.argsort()[::-1][:num_features]\n",
    "\n",
    "        # save selected indices and remove them from remaining indices\n",
    "        selected_indices.append(indices)\n",
    "        remaining_indices = np.delete(remaining_indices, indices)\n",
    "\n",
    "    # concatenate all selected indices\n",
    "    final_indices = np.concatenate(selected_indices)\n",
    "\n",
    "    svc = SVC(kernel='rbf', C=100.0)\n",
    "    svc.fit(train_data[:, final_indices], train_labels)\n",
    "\n",
    "    test_pred = svc.predict(test_data[:, final_indices])\n",
    "    test_acc = accuracy_score(test_labels, test_pred)\n",
    "    \n",
    "    print(f'test accuracy with selected features: {test_acc} ')\n",
    "    print(f'test accuracy with selected features with penalty: {test_acc- num_iterations*num_features*0.00075} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61ca99d0-22e2-4ecf-85a4-54f01469cca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7263 - accuracy: 0.7744 - val_loss: 0.4920 - val_accuracy: 0.8452\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2733 - accuracy: 0.9260 - val_loss: 0.4687 - val_accuracy: 0.8520\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1674 - accuracy: 0.9618 - val_loss: 0.4251 - val_accuracy: 0.8702\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1038 - accuracy: 0.9864 - val_loss: 0.4182 - val_accuracy: 0.8738\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9946 - val_loss: 0.4001 - val_accuracy: 0.8780\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9984 - val_loss: 0.4106 - val_accuracy: 0.8802\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9996 - val_loss: 0.4133 - val_accuracy: 0.8778\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.8828\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.8838\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.8826\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.8848\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.8844\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.8868\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.8882\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.8844\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.8870\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.8890\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.8872\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.8882\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.8864\n",
      "157/157 [==============================] - 0s 940us/step - loss: 0.4015 - accuracy: 0.8864\n",
      "test accuracy (1/10): 0.8863999843597412\n",
      "Iteration 2/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.7702 - accuracy: 0.7534 - val_loss: 0.5433 - val_accuracy: 0.8332\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.9098 - val_loss: 0.4702 - val_accuracy: 0.8596\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.9600 - val_loss: 0.4613 - val_accuracy: 0.8572\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9736 - val_loss: 0.4670 - val_accuracy: 0.8576\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9906 - val_loss: 0.4370 - val_accuracy: 0.8716\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9968 - val_loss: 0.4258 - val_accuracy: 0.8742\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0447 - accuracy: 0.9986 - val_loss: 0.4319 - val_accuracy: 0.8770\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.8786\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.8774\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.8804\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8810\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.8810\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.8832\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8832\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8826\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.8828\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.8824\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.8848\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.8842\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.8838\n",
      "157/157 [==============================] - 0s 940us/step - loss: 0.4169 - accuracy: 0.8838\n",
      "test accuracy (2/10): 0.8838000297546387\n",
      "Iteration 3/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8026 - accuracy: 0.7458 - val_loss: 0.5743 - val_accuracy: 0.8176\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.9056 - val_loss: 0.4508 - val_accuracy: 0.8574\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9564 - val_loss: 0.4532 - val_accuracy: 0.8588\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9752 - val_loss: 0.4275 - val_accuracy: 0.8710\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9870 - val_loss: 0.4223 - val_accuracy: 0.8726\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9964 - val_loss: 0.4305 - val_accuracy: 0.8740\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9992 - val_loss: 0.4163 - val_accuracy: 0.8790\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9966 - val_loss: 0.4178 - val_accuracy: 0.8812\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.8818\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.8812\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8822\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.8834\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.8846\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.8838\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.8842\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.8844\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.8842\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.8836\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.8836\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.8852\n",
      "157/157 [==============================] - 0s 959us/step - loss: 0.4013 - accuracy: 0.8852\n",
      "test accuracy (3/10): 0.885200023651123\n",
      "Iteration 4/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8526 - accuracy: 0.7316 - val_loss: 0.6312 - val_accuracy: 0.8010\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.9058 - val_loss: 0.4977 - val_accuracy: 0.8434\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.9450 - val_loss: 0.4534 - val_accuracy: 0.8596\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9698 - val_loss: 0.4460 - val_accuracy: 0.8612\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9874 - val_loss: 0.4313 - val_accuracy: 0.8668\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9938 - val_loss: 0.4387 - val_accuracy: 0.8698\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9978 - val_loss: 0.4407 - val_accuracy: 0.8664\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0398 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.8678\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9998 - val_loss: 0.4340 - val_accuracy: 0.8736\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8738\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.8746\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.8740\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.8758\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.8760\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.8766\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.8764\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.8780\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.8782\n",
      "157/157 [==============================] - 0s 889us/step - loss: 0.4300 - accuracy: 0.8782\n",
      "test accuracy (4/10): 0.8781999945640564\n",
      "Iteration 5/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8412 - accuracy: 0.7270 - val_loss: 0.6135 - val_accuracy: 0.8002\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.9010 - val_loss: 0.5053 - val_accuracy: 0.8446\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.9360 - val_loss: 0.4672 - val_accuracy: 0.8552\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1583 - accuracy: 0.9700 - val_loss: 0.4872 - val_accuracy: 0.8528\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9806 - val_loss: 0.4477 - val_accuracy: 0.8642\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.9906 - val_loss: 0.4556 - val_accuracy: 0.8670\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9944 - val_loss: 0.4558 - val_accuracy: 0.8646\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9986 - val_loss: 0.4792 - val_accuracy: 0.8618\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9998 - val_loss: 0.4563 - val_accuracy: 0.8696\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9998 - val_loss: 0.4576 - val_accuracy: 0.8688\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.8680\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9994 - val_loss: 0.4613 - val_accuracy: 0.8700\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.8698\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.8704\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.8730\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.8746\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.8724\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.8738\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.8738\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.8714\n",
      "157/157 [==============================] - 0s 940us/step - loss: 0.4534 - accuracy: 0.8714\n",
      "test accuracy (5/10): 0.871399998664856\n",
      "Iteration 6/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8684 - accuracy: 0.7184 - val_loss: 0.6372 - val_accuracy: 0.7948\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.9000 - val_loss: 0.5102 - val_accuracy: 0.8408\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2415 - accuracy: 0.9362 - val_loss: 0.5205 - val_accuracy: 0.8372\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1686 - accuracy: 0.9648 - val_loss: 0.4988 - val_accuracy: 0.8484\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9818 - val_loss: 0.4910 - val_accuracy: 0.8506\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9904 - val_loss: 0.4720 - val_accuracy: 0.8598\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0628 - accuracy: 0.9968 - val_loss: 0.4653 - val_accuracy: 0.8610\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9988 - val_loss: 0.4706 - val_accuracy: 0.8636\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9996 - val_loss: 0.4733 - val_accuracy: 0.8634\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.8654\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8680\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.8672\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.8674\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.8660\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.8676\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.8676\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.8688\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.8668\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8676\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.8698\n",
      "157/157 [==============================] - 0s 921us/step - loss: 0.4602 - accuracy: 0.8698\n",
      "test accuracy (6/10): 0.8697999715805054\n",
      "Iteration 7/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8998 - accuracy: 0.7166 - val_loss: 0.7005 - val_accuracy: 0.7758\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8840 - val_loss: 0.5609 - val_accuracy: 0.8230\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2561 - accuracy: 0.9392 - val_loss: 0.5537 - val_accuracy: 0.8300\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1930 - accuracy: 0.9570 - val_loss: 0.5408 - val_accuracy: 0.8286\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9758 - val_loss: 0.4889 - val_accuracy: 0.8534\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9896 - val_loss: 0.4937 - val_accuracy: 0.8554\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9958 - val_loss: 0.4904 - val_accuracy: 0.8612\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0545 - accuracy: 0.9976 - val_loss: 0.4954 - val_accuracy: 0.8588\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9994 - val_loss: 0.4933 - val_accuracy: 0.8616\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9990 - val_loss: 0.4960 - val_accuracy: 0.8610\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.8602\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.8626\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.8658\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.8648\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.8634\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.8656\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.8666\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.8660\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.8668\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.8660\n",
      "157/157 [==============================] - 0s 946us/step - loss: 0.4897 - accuracy: 0.8660\n",
      "test accuracy (7/10): 0.8659999966621399\n",
      "Iteration 8/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 0.9289 - accuracy: 0.6984 - val_loss: 0.7001 - val_accuracy: 0.7690\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4076 - accuracy: 0.8828 - val_loss: 0.5668 - val_accuracy: 0.8266\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2747 - accuracy: 0.9286 - val_loss: 0.5090 - val_accuracy: 0.8392\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.9604 - val_loss: 0.4956 - val_accuracy: 0.8436\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1336 - accuracy: 0.9798 - val_loss: 0.5299 - val_accuracy: 0.8344\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1009 - accuracy: 0.9874 - val_loss: 0.5143 - val_accuracy: 0.8438\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9962 - val_loss: 0.5097 - val_accuracy: 0.8472\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9970 - val_loss: 0.4962 - val_accuracy: 0.8522\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9984 - val_loss: 0.5013 - val_accuracy: 0.8530\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.8536\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.8560\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.8556\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.8562\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8566\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.8564\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.8550\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.8564\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.8602\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.8568\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.8590\n",
      "157/157 [==============================] - 0s 927us/step - loss: 0.5013 - accuracy: 0.8590\n",
      "test accuracy (8/10): 0.859000027179718\n",
      "Iteration 9/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.9476 - accuracy: 0.6936 - val_loss: 0.6828 - val_accuracy: 0.7766\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8744 - val_loss: 0.6081 - val_accuracy: 0.8022\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2929 - accuracy: 0.9210 - val_loss: 0.5291 - val_accuracy: 0.8302\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9534 - val_loss: 0.4893 - val_accuracy: 0.8460\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9744 - val_loss: 0.5194 - val_accuracy: 0.8380\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9842 - val_loss: 0.5251 - val_accuracy: 0.8340\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9942 - val_loss: 0.5067 - val_accuracy: 0.8448\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9978 - val_loss: 0.5014 - val_accuracy: 0.8506\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0500 - accuracy: 0.9984 - val_loss: 0.4995 - val_accuracy: 0.8516\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9996 - val_loss: 0.4977 - val_accuracy: 0.8516\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9998 - val_loss: 0.5058 - val_accuracy: 0.8540\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.8514\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.8546\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.8522\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8552\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.8556\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8536\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.8540\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.8552\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.8562\n",
      "157/157 [==============================] - 0s 940us/step - loss: 0.5086 - accuracy: 0.8562\n",
      "test accuracy (9/10): 0.8561999797821045\n",
      "Iteration 10/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.9752 - accuracy: 0.6774 - val_loss: 0.7205 - val_accuracy: 0.7566\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4356 - accuracy: 0.8730 - val_loss: 0.6171 - val_accuracy: 0.7978\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.9290 - val_loss: 0.5339 - val_accuracy: 0.8322\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2127 - accuracy: 0.9532 - val_loss: 0.5186 - val_accuracy: 0.8328\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9722 - val_loss: 0.5259 - val_accuracy: 0.8326\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1193 - accuracy: 0.9838 - val_loss: 0.5154 - val_accuracy: 0.8414\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9926 - val_loss: 0.5299 - val_accuracy: 0.8404\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9976 - val_loss: 0.5261 - val_accuracy: 0.8402\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9992 - val_loss: 0.5313 - val_accuracy: 0.8394\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9986 - val_loss: 0.5342 - val_accuracy: 0.8406\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0377 - accuracy: 0.9996 - val_loss: 0.5367 - val_accuracy: 0.8426\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.8436\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9996 - val_loss: 0.5327 - val_accuracy: 0.8446\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.5353 - val_accuracy: 0.8468\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.8442\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.8442\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.8474\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.8470\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.5365 - val_accuracy: 0.8468\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8456\n",
      "157/157 [==============================] - 0s 921us/step - loss: 0.5358 - accuracy: 0.8456\n",
      "test accuracy (10/10): 0.8456000089645386\n",
      "test accuracy with selected features: 0.8676 \n",
      "test accuracy with selected features with penalty: 0.7176 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fbffd8e-27ad-4ccb-a067-edf5acc069d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7495 - accuracy: 0.7566 - val_loss: 0.5008 - val_accuracy: 0.8436\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.9282 - val_loss: 0.4530 - val_accuracy: 0.8564\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1805 - accuracy: 0.9566 - val_loss: 0.4299 - val_accuracy: 0.8676\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9842 - val_loss: 0.4533 - val_accuracy: 0.8602\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9888 - val_loss: 0.4150 - val_accuracy: 0.8770\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0533 - accuracy: 0.9974 - val_loss: 0.4172 - val_accuracy: 0.8798\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9998 - val_loss: 0.4161 - val_accuracy: 0.8760\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 0.9996 - val_loss: 0.4131 - val_accuracy: 0.8800\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.8820\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.8828\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.8852\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.8832\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.8840\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.8850\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.8846\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.8856\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.8852\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.8854\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8850\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.8852\n",
      "157/157 [==============================] - 0s 901us/step - loss: 0.3975 - accuracy: 0.8852\n",
      "test accuracy (1/5): 0.885200023651123\n",
      "Iteration 2/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7949 - accuracy: 0.7402 - val_loss: 0.5561 - val_accuracy: 0.8230\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.9094 - val_loss: 0.4619 - val_accuracy: 0.8572\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2197 - accuracy: 0.9460 - val_loss: 0.4724 - val_accuracy: 0.8516\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1449 - accuracy: 0.9716 - val_loss: 0.4438 - val_accuracy: 0.8644\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9888 - val_loss: 0.4348 - val_accuracy: 0.8674\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9958 - val_loss: 0.4260 - val_accuracy: 0.8756\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0498 - accuracy: 0.9990 - val_loss: 0.4187 - val_accuracy: 0.8766\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0399 - accuracy: 0.9994 - val_loss: 0.4202 - val_accuracy: 0.8778\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.8746\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.8766\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.8782\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.8780\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.8786\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0221 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.8774\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.8770\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.8812\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.8788\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.8808\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8806\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.8792\n",
      "157/157 [==============================] - 0s 901us/step - loss: 0.4117 - accuracy: 0.8792\n",
      "test accuracy (2/5): 0.8791999816894531\n",
      "Iteration 3/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8693 - accuracy: 0.7254 - val_loss: 0.5649 - val_accuracy: 0.8278\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3404 - accuracy: 0.9006 - val_loss: 0.4897 - val_accuracy: 0.8434\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9456 - val_loss: 0.4712 - val_accuracy: 0.8582\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1577 - accuracy: 0.9688 - val_loss: 0.4338 - val_accuracy: 0.8676\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9850 - val_loss: 0.4494 - val_accuracy: 0.8628\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9946 - val_loss: 0.4302 - val_accuracy: 0.8694\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0532 - accuracy: 0.9990 - val_loss: 0.4287 - val_accuracy: 0.8690\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9950 - val_loss: 0.4320 - val_accuracy: 0.8696\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.8720\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8722\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.8748\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.8756\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.8768\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.8754\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.8760\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.8766\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.8746\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.8768\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.8788\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.8786\n",
      "157/157 [==============================] - 0s 908us/step - loss: 0.4284 - accuracy: 0.8786\n",
      "test accuracy (3/5): 0.878600001335144\n",
      "Iteration 4/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8776 - accuracy: 0.7148 - val_loss: 0.7064 - val_accuracy: 0.7688\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8970 - val_loss: 0.5701 - val_accuracy: 0.8124\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2490 - accuracy: 0.9350 - val_loss: 0.5414 - val_accuracy: 0.8304\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1961 - accuracy: 0.9560 - val_loss: 0.5003 - val_accuracy: 0.8428\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9776 - val_loss: 0.4861 - val_accuracy: 0.8536\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9916 - val_loss: 0.4795 - val_accuracy: 0.8518\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0670 - accuracy: 0.9964 - val_loss: 0.4831 - val_accuracy: 0.8508\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9984 - val_loss: 0.4787 - val_accuracy: 0.8598\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.9994 - val_loss: 0.4805 - val_accuracy: 0.8604\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9996 - val_loss: 0.4927 - val_accuracy: 0.8550\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.8610\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.8608\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.8618\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.8638\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.8638\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8644\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.8618\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4757 - val_accuracy: 0.8632\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.8638\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.8630\n",
      "157/157 [==============================] - 0s 921us/step - loss: 0.4812 - accuracy: 0.8630\n",
      "test accuracy (4/5): 0.8629999756813049\n",
      "Iteration 5/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.9435 - accuracy: 0.6906 - val_loss: 0.6855 - val_accuracy: 0.7836\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8802 - val_loss: 0.6063 - val_accuracy: 0.8102\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.9232 - val_loss: 0.5549 - val_accuracy: 0.8186\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9522 - val_loss: 0.5148 - val_accuracy: 0.8338\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1492 - accuracy: 0.9722 - val_loss: 0.5104 - val_accuracy: 0.8358\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1089 - accuracy: 0.9870 - val_loss: 0.5255 - val_accuracy: 0.8372\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9930 - val_loss: 0.5364 - val_accuracy: 0.8392\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0604 - accuracy: 0.9968 - val_loss: 0.5008 - val_accuracy: 0.8464\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9990 - val_loss: 0.5204 - val_accuracy: 0.8486\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0426 - accuracy: 0.9992 - val_loss: 0.5074 - val_accuracy: 0.8498\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.8526\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.8534\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.8550\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.8540\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.8546\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.8538\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.8536\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.8562\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.8536\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.8546\n",
      "157/157 [==============================] - 0s 953us/step - loss: 0.5078 - accuracy: 0.8546\n",
      "test accuracy (5/5): 0.8546000123023987\n",
      "test accuracy with selected features: 0.8702 \n",
      "test accuracy with selected features with penalty: 0.7202 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(5, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bf9d081-ec1c-4be2-810a-6f1eee0cab33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/2\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7454 - accuracy: 0.7640 - val_loss: 0.5422 - val_accuracy: 0.8304\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.9212 - val_loss: 0.4547 - val_accuracy: 0.8542\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9642 - val_loss: 0.4355 - val_accuracy: 0.8690\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9830 - val_loss: 0.4080 - val_accuracy: 0.8814\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9946 - val_loss: 0.4098 - val_accuracy: 0.8794\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9968 - val_loss: 0.4173 - val_accuracy: 0.8812\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9994 - val_loss: 0.4054 - val_accuracy: 0.8840\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9998 - val_loss: 0.4094 - val_accuracy: 0.8838\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.8886\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.8870\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.8878\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.8892\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.8886\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.8882\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.8894\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.8864\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.3976 - val_accuracy: 0.8886\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.8900\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.8868\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.8860\n",
      "157/157 [==============================] - 0s 908us/step - loss: 0.4007 - accuracy: 0.8860\n",
      "test accuracy (1/2): 0.8859999775886536\n",
      "Iteration 2/2\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8357 - accuracy: 0.7340 - val_loss: 0.6130 - val_accuracy: 0.8040\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.9056 - val_loss: 0.5386 - val_accuracy: 0.8312\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9484 - val_loss: 0.4847 - val_accuracy: 0.8482\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.9628 - val_loss: 0.4762 - val_accuracy: 0.8532\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9856 - val_loss: 0.4974 - val_accuracy: 0.8460\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9918 - val_loss: 0.4591 - val_accuracy: 0.8626\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9972 - val_loss: 0.4612 - val_accuracy: 0.8622\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.9990 - val_loss: 0.4837 - val_accuracy: 0.8586\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.9996 - val_loss: 0.4622 - val_accuracy: 0.8664\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.8676\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.8660\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.8680\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.8682\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.8698\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.8698\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.8710\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.8730\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.8702\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.8714\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.8732\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4574 - accuracy: 0.8732\n",
      "test accuracy (2/2): 0.873199999332428\n",
      "test accuracy with selected features: 0.8796 \n",
      "test accuracy with selected features with penalty: 0.7296 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbc8a4b9-ffee-4200-81bc-acde7ac19590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7285 - accuracy: 0.7672 - val_loss: 0.4987 - val_accuracy: 0.8422\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.9212 - val_loss: 0.4391 - val_accuracy: 0.8650\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9572 - val_loss: 0.4299 - val_accuracy: 0.8682\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1182 - accuracy: 0.9790 - val_loss: 0.3927 - val_accuracy: 0.8828\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0752 - accuracy: 0.9926 - val_loss: 0.3788 - val_accuracy: 0.8884\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9978 - val_loss: 0.3934 - val_accuracy: 0.8846\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9992 - val_loss: 0.3969 - val_accuracy: 0.8852\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.8854\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.8880\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.8870\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.8876\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.8874\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.8918\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.8884\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.8888\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.8904\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.8904\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.8906\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.8898\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.3841 - val_accuracy: 0.8918\n",
      "157/157 [==============================] - 0s 914us/step - loss: 0.3841 - accuracy: 0.8918\n",
      "test accuracy (1/5): 0.8917999863624573\n",
      "Iteration 2/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7808 - accuracy: 0.7502 - val_loss: 0.5737 - val_accuracy: 0.8210\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.9186 - val_loss: 0.4796 - val_accuracy: 0.8508\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1864 - accuracy: 0.9568 - val_loss: 0.4558 - val_accuracy: 0.8568\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9798 - val_loss: 0.4459 - val_accuracy: 0.8638\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9910 - val_loss: 0.4366 - val_accuracy: 0.8702\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9934 - val_loss: 0.4205 - val_accuracy: 0.8762\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9990 - val_loss: 0.4178 - val_accuracy: 0.8772\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.8800\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 0.9998 - val_loss: 0.4197 - val_accuracy: 0.8796\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9998 - val_loss: 0.4135 - val_accuracy: 0.8804\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8812\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.8804\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.8818\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.8818\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.8846\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.8840\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.8826\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.8834\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.8870\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.8838\n",
      "157/157 [==============================] - 0s 940us/step - loss: 0.4047 - accuracy: 0.8838\n",
      "test accuracy (2/5): 0.8838000297546387\n",
      "Iteration 3/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.8130 - accuracy: 0.7384 - val_loss: 0.5540 - val_accuracy: 0.8282\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.9122 - val_loss: 0.4967 - val_accuracy: 0.8442\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2057 - accuracy: 0.9538 - val_loss: 0.4762 - val_accuracy: 0.8470\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1413 - accuracy: 0.9768 - val_loss: 0.4552 - val_accuracy: 0.8584\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1013 - accuracy: 0.9870 - val_loss: 0.4365 - val_accuracy: 0.8654\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9926 - val_loss: 0.4360 - val_accuracy: 0.8678\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0519 - accuracy: 0.9978 - val_loss: 0.4344 - val_accuracy: 0.8704\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9990 - val_loss: 0.4412 - val_accuracy: 0.8734\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0360 - accuracy: 0.9996 - val_loss: 0.4406 - val_accuracy: 0.8726\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9998 - val_loss: 0.4380 - val_accuracy: 0.8734\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.8764\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.8760\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.8760\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.8772\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8752\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.8772\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.8774\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8768\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.8794\n",
      "157/157 [==============================] - 0s 904us/step - loss: 0.4263 - accuracy: 0.8794\n",
      "test accuracy (3/5): 0.8794000148773193\n",
      "Iteration 4/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 8ms/step - loss: 0.8609 - accuracy: 0.7194 - val_loss: 0.6276 - val_accuracy: 0.8032\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8946 - val_loss: 0.5005 - val_accuracy: 0.8440\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2385 - accuracy: 0.9428 - val_loss: 0.4926 - val_accuracy: 0.8442\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1584 - accuracy: 0.9708 - val_loss: 0.4606 - val_accuracy: 0.8588\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9864 - val_loss: 0.4776 - val_accuracy: 0.8550\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0827 - accuracy: 0.9918 - val_loss: 0.4693 - val_accuracy: 0.8566\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0606 - accuracy: 0.9968 - val_loss: 0.4803 - val_accuracy: 0.8568\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9984 - val_loss: 0.4511 - val_accuracy: 0.8660\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9996 - val_loss: 0.4575 - val_accuracy: 0.8680\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.8648\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.8716\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.8690\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.8664\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.8660\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.8688\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.8688\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.8696\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.8686\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.8680\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.8684\n",
      "157/157 [==============================] - 0s 921us/step - loss: 0.4502 - accuracy: 0.8684\n",
      "test accuracy (4/5): 0.868399977684021\n",
      "Iteration 5/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8952 - accuracy: 0.7082 - val_loss: 0.6245 - val_accuracy: 0.8076\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3885 - accuracy: 0.8904 - val_loss: 0.5589 - val_accuracy: 0.8222\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9294 - val_loss: 0.5041 - val_accuracy: 0.8432\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9592 - val_loss: 0.5240 - val_accuracy: 0.8346\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9764 - val_loss: 0.4864 - val_accuracy: 0.8478\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9918 - val_loss: 0.4895 - val_accuracy: 0.8588\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0893 - accuracy: 0.9870 - val_loss: 0.4673 - val_accuracy: 0.8578\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9984 - val_loss: 0.4726 - val_accuracy: 0.8612\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0441 - accuracy: 0.9996 - val_loss: 0.4763 - val_accuracy: 0.8630\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.9998 - val_loss: 0.4725 - val_accuracy: 0.8644\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.8680\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.8662\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.8658\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.8682\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.8702\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.8674\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.8702\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.8690\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.8712\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8688\n",
      "157/157 [==============================] - 0s 921us/step - loss: 0.4652 - accuracy: 0.8688\n",
      "test accuracy (5/5): 0.8687999844551086\n",
      "test accuracy with selected features: 0.8586 \n",
      "test accuracy with selected features with penalty: 0.7461 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(5, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e698e3d-ae66-432d-b878-bc8c399449a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7175 - accuracy: 0.7732 - val_loss: 0.5309 - val_accuracy: 0.8308\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.9220 - val_loss: 0.4486 - val_accuracy: 0.8590\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1875 - accuracy: 0.9538 - val_loss: 0.4218 - val_accuracy: 0.8716\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1157 - accuracy: 0.9794 - val_loss: 0.4213 - val_accuracy: 0.8724\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9922 - val_loss: 0.4210 - val_accuracy: 0.8770\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0541 - accuracy: 0.9972 - val_loss: 0.4040 - val_accuracy: 0.8758\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9996 - val_loss: 0.4099 - val_accuracy: 0.8806\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.8874\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.8832\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.8872\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.8856\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.8860\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.8866\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.8884\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.8852\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.8888\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.8868\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.8894\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.8894\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.8908\n",
      "157/157 [==============================] - 0s 908us/step - loss: 0.3860 - accuracy: 0.8908\n",
      "test accuracy (1/10): 0.8907999992370605\n",
      "Iteration 2/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7425 - accuracy: 0.7620 - val_loss: 0.5245 - val_accuracy: 0.8348\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.9222 - val_loss: 0.4548 - val_accuracy: 0.8618\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1814 - accuracy: 0.9564 - val_loss: 0.4453 - val_accuracy: 0.8654\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1149 - accuracy: 0.9834 - val_loss: 0.4267 - val_accuracy: 0.8718\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0811 - accuracy: 0.9916 - val_loss: 0.4329 - val_accuracy: 0.8726\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0567 - accuracy: 0.9976 - val_loss: 0.4345 - val_accuracy: 0.8736\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0450 - accuracy: 0.9990 - val_loss: 0.4229 - val_accuracy: 0.8754\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0395 - accuracy: 0.9982 - val_loss: 0.4340 - val_accuracy: 0.8774\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.8782\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.8780\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8838\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8814\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.8806\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.8806\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.8834\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8860\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.8840\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.8844\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.8850\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.8850\n",
      "157/157 [==============================] - 0s 927us/step - loss: 0.4091 - accuracy: 0.8850\n",
      "test accuracy (2/10): 0.8849999904632568\n",
      "Iteration 3/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7990 - accuracy: 0.7488 - val_loss: 0.5316 - val_accuracy: 0.8364\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.9088 - val_loss: 0.4606 - val_accuracy: 0.8586\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9526 - val_loss: 0.4478 - val_accuracy: 0.8644\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9790 - val_loss: 0.4264 - val_accuracy: 0.8716\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9890 - val_loss: 0.4277 - val_accuracy: 0.8706\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9948 - val_loss: 0.4203 - val_accuracy: 0.8754\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9946 - val_loss: 0.4307 - val_accuracy: 0.8752\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0388 - accuracy: 0.9996 - val_loss: 0.4241 - val_accuracy: 0.8814\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.8812\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.8834\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.8828\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.8824\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8840\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.8832\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.8820\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.8834\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.8836\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.8846\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.8834\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.8864\n",
      "157/157 [==============================] - 0s 927us/step - loss: 0.4002 - accuracy: 0.8864\n",
      "test accuracy (3/10): 0.8863999843597412\n",
      "Iteration 4/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8172 - accuracy: 0.7374 - val_loss: 0.5286 - val_accuracy: 0.8280\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.9040 - val_loss: 0.4815 - val_accuracy: 0.8508\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2181 - accuracy: 0.9434 - val_loss: 0.4704 - val_accuracy: 0.8544\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1410 - accuracy: 0.9736 - val_loss: 0.4349 - val_accuracy: 0.8644\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9892 - val_loss: 0.4262 - val_accuracy: 0.8688\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9970 - val_loss: 0.4270 - val_accuracy: 0.8740\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9990 - val_loss: 0.4199 - val_accuracy: 0.8746\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0404 - accuracy: 0.9996 - val_loss: 0.4301 - val_accuracy: 0.8782\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0339 - accuracy: 0.9998 - val_loss: 0.4217 - val_accuracy: 0.8784\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.8792\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.8808\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.8822\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.8800\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.8828\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.8834\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.8826\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8840\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.8842\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.8828\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8826\n",
      "157/157 [==============================] - 0s 933us/step - loss: 0.4126 - accuracy: 0.8826\n",
      "test accuracy (4/10): 0.8826000094413757\n",
      "Iteration 5/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8338 - accuracy: 0.7274 - val_loss: 0.5664 - val_accuracy: 0.8268\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.9094 - val_loss: 0.4965 - val_accuracy: 0.8458\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.9496 - val_loss: 0.4721 - val_accuracy: 0.8576\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9752 - val_loss: 0.4416 - val_accuracy: 0.8634\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9886 - val_loss: 0.4517 - val_accuracy: 0.8624\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9956 - val_loss: 0.4495 - val_accuracy: 0.8686\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9972 - val_loss: 0.4301 - val_accuracy: 0.8730\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9996 - val_loss: 0.4393 - val_accuracy: 0.8776\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.8770\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.8762\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.8764\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.8768\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.8772\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.8784\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.8786\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.8796\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.8784\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.8776\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.8786\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.8792\n",
      "157/157 [==============================] - 0s 914us/step - loss: 0.4386 - accuracy: 0.8792\n",
      "test accuracy (5/10): 0.8791999816894531\n",
      "Iteration 6/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8754 - accuracy: 0.7192 - val_loss: 0.5910 - val_accuracy: 0.8156\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3516 - accuracy: 0.9008 - val_loss: 0.4913 - val_accuracy: 0.8482\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2361 - accuracy: 0.9398 - val_loss: 0.4588 - val_accuracy: 0.8584\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1579 - accuracy: 0.9674 - val_loss: 0.4448 - val_accuracy: 0.8642\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9832 - val_loss: 0.4682 - val_accuracy: 0.8596\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9918 - val_loss: 0.4453 - val_accuracy: 0.8668\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9960 - val_loss: 0.4565 - val_accuracy: 0.8666\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9996 - val_loss: 0.4514 - val_accuracy: 0.8716\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9992 - val_loss: 0.4437 - val_accuracy: 0.8728\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.8742\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.8742\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.8746\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.8758\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4426 - val_accuracy: 0.8768\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8780\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.8774\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.8782\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.8768\n",
      "157/157 [==============================] - 0s 953us/step - loss: 0.4405 - accuracy: 0.8768\n",
      "test accuracy (6/10): 0.876800000667572\n",
      "Iteration 7/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8437 - accuracy: 0.7314 - val_loss: 0.5907 - val_accuracy: 0.8132\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3533 - accuracy: 0.8994 - val_loss: 0.5547 - val_accuracy: 0.8264\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2301 - accuracy: 0.9432 - val_loss: 0.4896 - val_accuracy: 0.8476\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1665 - accuracy: 0.9630 - val_loss: 0.5083 - val_accuracy: 0.8472\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9866 - val_loss: 0.4686 - val_accuracy: 0.8546\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0811 - accuracy: 0.9934 - val_loss: 0.4960 - val_accuracy: 0.8542\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9968 - val_loss: 0.4667 - val_accuracy: 0.8590\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9994 - val_loss: 0.4684 - val_accuracy: 0.8586\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.8576\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.8622\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.8590\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.8652\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.8610\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.8644\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.8654\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.8660\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.8652\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.8674\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.8676\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.8656\n",
      "157/157 [==============================] - 0s 946us/step - loss: 0.4709 - accuracy: 0.8656\n",
      "test accuracy (7/10): 0.8655999898910522\n",
      "Iteration 8/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8924 - accuracy: 0.7134 - val_loss: 0.6159 - val_accuracy: 0.8168\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3761 - accuracy: 0.8944 - val_loss: 0.5316 - val_accuracy: 0.8276\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2471 - accuracy: 0.9378 - val_loss: 0.5138 - val_accuracy: 0.8394\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9616 - val_loss: 0.5215 - val_accuracy: 0.8388\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1226 - accuracy: 0.9818 - val_loss: 0.5163 - val_accuracy: 0.8464\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9908 - val_loss: 0.4939 - val_accuracy: 0.8534\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9970 - val_loss: 0.4671 - val_accuracy: 0.8630\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0515 - accuracy: 0.9974 - val_loss: 0.4801 - val_accuracy: 0.8580\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 1.0000 - val_loss: 0.4801 - val_accuracy: 0.8608\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.8612\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.8630\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.8608\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.4789 - val_accuracy: 0.8620\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.8610\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.8642\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.8624\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.8644\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.8654\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.8644\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.8646\n",
      "157/157 [==============================] - 0s 965us/step - loss: 0.4695 - accuracy: 0.8646\n",
      "test accuracy (8/10): 0.8646000027656555\n",
      "Iteration 9/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.9153 - accuracy: 0.7058 - val_loss: 0.6302 - val_accuracy: 0.8040\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8844 - val_loss: 0.5641 - val_accuracy: 0.8262\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9382 - val_loss: 0.5375 - val_accuracy: 0.8324\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.9614 - val_loss: 0.5049 - val_accuracy: 0.8408\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.9724 - val_loss: 0.4914 - val_accuracy: 0.8484\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9874 - val_loss: 0.4960 - val_accuracy: 0.8528\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9956 - val_loss: 0.4965 - val_accuracy: 0.8488\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9970 - val_loss: 0.5110 - val_accuracy: 0.8488\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9992 - val_loss: 0.5044 - val_accuracy: 0.8498\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.8522\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0323 - accuracy: 0.9996 - val_loss: 0.5078 - val_accuracy: 0.8500\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.8502\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.8550\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9998 - val_loss: 0.5014 - val_accuracy: 0.8536\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.8564\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.8562\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.8542\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.8556\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8564\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.8584\n",
      "157/157 [==============================] - 0s 946us/step - loss: 0.5008 - accuracy: 0.8584\n",
      "test accuracy (9/10): 0.8583999872207642\n",
      "Iteration 10/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.9487 - accuracy: 0.6952 - val_loss: 0.7382 - val_accuracy: 0.7678\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8834 - val_loss: 0.5793 - val_accuracy: 0.8192\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2727 - accuracy: 0.9284 - val_loss: 0.5385 - val_accuracy: 0.8306\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2028 - accuracy: 0.9544 - val_loss: 0.5032 - val_accuracy: 0.8442\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9776 - val_loss: 0.4947 - val_accuracy: 0.8482\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0970 - accuracy: 0.9888 - val_loss: 0.4962 - val_accuracy: 0.8508\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9948 - val_loss: 0.5104 - val_accuracy: 0.8452\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9980 - val_loss: 0.5098 - val_accuracy: 0.8490\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9994 - val_loss: 0.5109 - val_accuracy: 0.8520\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.9998 - val_loss: 0.5090 - val_accuracy: 0.8506\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.8526\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 0.5144 - val_accuracy: 0.8522\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.8564\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.8554\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.8602\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.8568\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.8580\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.8616\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.8602\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.8604\n",
      "157/157 [==============================] - 0s 972us/step - loss: 0.5111 - accuracy: 0.8604\n",
      "test accuracy (10/10): 0.8604000210762024\n",
      "test accuracy with selected features: 0.8384 \n",
      "test accuracy with selected features with penalty: 0.7259 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(10, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fef35569-7f98-482b-bee0-09d97c790aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7467 - accuracy: 0.7572 - val_loss: 0.4998 - val_accuracy: 0.8452\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.9232 - val_loss: 0.4446 - val_accuracy: 0.8586\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1668 - accuracy: 0.9620 - val_loss: 0.4195 - val_accuracy: 0.8776\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9810 - val_loss: 0.4171 - val_accuracy: 0.8730\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9922 - val_loss: 0.4322 - val_accuracy: 0.8738\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9980 - val_loss: 0.4099 - val_accuracy: 0.8814\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0402 - accuracy: 0.9994 - val_loss: 0.4110 - val_accuracy: 0.8806\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.8830\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.8852\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8824\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.8862\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.8846\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.8862\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.8876\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.8858\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.8870\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.8878\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.8860\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.8876\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.8856\n",
      "157/157 [==============================] - 0s 946us/step - loss: 0.3991 - accuracy: 0.8856\n",
      "test accuracy (1/10): 0.8855999708175659\n",
      "Iteration 2/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7306 - accuracy: 0.7716 - val_loss: 0.5223 - val_accuracy: 0.8358\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.9208 - val_loss: 0.4522 - val_accuracy: 0.8590\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1722 - accuracy: 0.9640 - val_loss: 0.4095 - val_accuracy: 0.8724\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9824 - val_loss: 0.4151 - val_accuracy: 0.8730\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9912 - val_loss: 0.4274 - val_accuracy: 0.8768\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0565 - accuracy: 0.9970 - val_loss: 0.4146 - val_accuracy: 0.8792\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0429 - accuracy: 0.9998 - val_loss: 0.4113 - val_accuracy: 0.8814\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.8832\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.8836\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.8872\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.8842\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8830\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.8842\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.8860\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.8866\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.8878\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.8860\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.8872\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.8888\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.8880\n",
      "157/157 [==============================] - 0s 946us/step - loss: 0.3893 - accuracy: 0.8880\n",
      "test accuracy (2/10): 0.8880000114440918\n",
      "Iteration 3/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7769 - accuracy: 0.7538 - val_loss: 0.5682 - val_accuracy: 0.8236\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.9192 - val_loss: 0.4836 - val_accuracy: 0.8436\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9582 - val_loss: 0.4362 - val_accuracy: 0.8650\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9714 - val_loss: 0.4253 - val_accuracy: 0.8702\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9898 - val_loss: 0.4394 - val_accuracy: 0.8690\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9970 - val_loss: 0.4180 - val_accuracy: 0.8766\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0451 - accuracy: 0.9998 - val_loss: 0.4160 - val_accuracy: 0.8796\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0379 - accuracy: 0.9998 - val_loss: 0.4169 - val_accuracy: 0.8812\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.8828\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.8826\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.8836\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8832\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.8844\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.8836\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.8848\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.8844\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.8854\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8842\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.8874\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.8864\n",
      "157/157 [==============================] - 0s 991us/step - loss: 0.4067 - accuracy: 0.8864\n",
      "test accuracy (3/10): 0.8863999843597412\n",
      "Iteration 4/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7511 - accuracy: 0.7624 - val_loss: 0.5329 - val_accuracy: 0.8348\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.9142 - val_loss: 0.4483 - val_accuracy: 0.8678\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1946 - accuracy: 0.9554 - val_loss: 0.4591 - val_accuracy: 0.8582\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9740 - val_loss: 0.4493 - val_accuracy: 0.8620\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1371 - accuracy: 0.9698 - val_loss: 0.4356 - val_accuracy: 0.8684\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9932 - val_loss: 0.4373 - val_accuracy: 0.8742\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9950 - val_loss: 0.4281 - val_accuracy: 0.8760\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0380 - accuracy: 0.9998 - val_loss: 0.4271 - val_accuracy: 0.8794\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.8780\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.8820\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.8800\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.8830\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.8812\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.8826\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.8828\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.8830\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.8832\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 0.9998 - val_loss: 0.4107 - val_accuracy: 0.8834\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.8836\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.8848\n",
      "157/157 [==============================] - 0s 985us/step - loss: 0.4076 - accuracy: 0.8848\n",
      "test accuracy (4/10): 0.8848000168800354\n",
      "Iteration 5/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8178 - accuracy: 0.7428 - val_loss: 0.5493 - val_accuracy: 0.8226\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.9102 - val_loss: 0.4881 - val_accuracy: 0.8472\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2136 - accuracy: 0.9460 - val_loss: 0.4565 - val_accuracy: 0.8578\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9744 - val_loss: 0.4382 - val_accuracy: 0.8672\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1025 - accuracy: 0.9860 - val_loss: 0.4357 - val_accuracy: 0.8702\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9920 - val_loss: 0.4316 - val_accuracy: 0.8712\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9982 - val_loss: 0.4261 - val_accuracy: 0.8746\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.8778\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.8778\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.8802\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 0.9992 - val_loss: 0.4274 - val_accuracy: 0.8762\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.8804\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.8790\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.8816\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.8814\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.8828\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.8816\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.8814\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.8802\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.8814\n",
      "157/157 [==============================] - 0s 978us/step - loss: 0.4187 - accuracy: 0.8814\n",
      "test accuracy (5/10): 0.8813999891281128\n",
      "Iteration 6/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8195 - accuracy: 0.7440 - val_loss: 0.5414 - val_accuracy: 0.8332\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.9058 - val_loss: 0.4813 - val_accuracy: 0.8528\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2030 - accuracy: 0.9524 - val_loss: 0.4367 - val_accuracy: 0.8632\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9784 - val_loss: 0.4445 - val_accuracy: 0.8642\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0967 - accuracy: 0.9872 - val_loss: 0.4504 - val_accuracy: 0.8654\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0681 - accuracy: 0.9944 - val_loss: 0.4346 - val_accuracy: 0.8742\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0492 - accuracy: 0.9988 - val_loss: 0.4295 - val_accuracy: 0.8754\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9996 - val_loss: 0.4238 - val_accuracy: 0.8792\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.8790\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0294 - accuracy: 0.9998 - val_loss: 0.4314 - val_accuracy: 0.8796\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.8800\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.8768\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.8816\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.8814\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.8824\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.8820\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.8836\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.8822\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.8844\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.8840\n",
      "157/157 [==============================] - 0s 965us/step - loss: 0.4181 - accuracy: 0.8840\n",
      "test accuracy (6/10): 0.8840000033378601\n",
      "Iteration 7/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7936 - accuracy: 0.7538 - val_loss: 0.5592 - val_accuracy: 0.8262\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.9044 - val_loss: 0.5151 - val_accuracy: 0.8394\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9516 - val_loss: 0.4570 - val_accuracy: 0.8592\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9720 - val_loss: 0.4588 - val_accuracy: 0.8590\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9884 - val_loss: 0.4444 - val_accuracy: 0.8664\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0721 - accuracy: 0.9962 - val_loss: 0.4512 - val_accuracy: 0.8666\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9986 - val_loss: 0.4511 - val_accuracy: 0.8666\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 0.9994 - val_loss: 0.4481 - val_accuracy: 0.8684\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9980 - val_loss: 0.4512 - val_accuracy: 0.8714\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9996 - val_loss: 0.4552 - val_accuracy: 0.8706\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.8712\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.8724\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.8738\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.8712\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.8704\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.8720\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.8740\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.8738\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8750\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.8736\n",
      "157/157 [==============================] - 0s 953us/step - loss: 0.4396 - accuracy: 0.8736\n",
      "test accuracy (7/10): 0.8736000061035156\n",
      "Iteration 8/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.8446 - accuracy: 0.7320 - val_loss: 0.5518 - val_accuracy: 0.8328\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.9044 - val_loss: 0.5193 - val_accuracy: 0.8408\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2252 - accuracy: 0.9448 - val_loss: 0.4671 - val_accuracy: 0.8546\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9676 - val_loss: 0.4421 - val_accuracy: 0.8652\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.9858 - val_loss: 0.4391 - val_accuracy: 0.8656\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9932 - val_loss: 0.4663 - val_accuracy: 0.8636\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0562 - accuracy: 0.9982 - val_loss: 0.4537 - val_accuracy: 0.8692\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9994 - val_loss: 0.4351 - val_accuracy: 0.8750\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.8738\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.8754\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.8770\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.8784\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8778\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.8772\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.8804\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.8798\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8792\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8812\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.8810\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8810\n",
      "test accuracy (8/10): 0.8809999823570251\n",
      "Iteration 9/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8517 - accuracy: 0.7218 - val_loss: 0.6308 - val_accuracy: 0.7948\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8974 - val_loss: 0.5162 - val_accuracy: 0.8366\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2292 - accuracy: 0.9440 - val_loss: 0.4828 - val_accuracy: 0.8510\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1695 - accuracy: 0.9624 - val_loss: 0.4742 - val_accuracy: 0.8544\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9866 - val_loss: 0.4624 - val_accuracy: 0.8576\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0767 - accuracy: 0.9922 - val_loss: 0.4501 - val_accuracy: 0.8626\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9972 - val_loss: 0.4641 - val_accuracy: 0.8658\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9992 - val_loss: 0.4614 - val_accuracy: 0.8686\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.9998 - val_loss: 0.4664 - val_accuracy: 0.8658\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.8714\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.8708\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.8722\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.8712\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.8720\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.8744\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.8736\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.8742\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.8724\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.8720\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.8730\n",
      "157/157 [==============================] - 0s 972us/step - loss: 0.4482 - accuracy: 0.8730\n",
      "test accuracy (9/10): 0.8730000257492065\n",
      "Iteration 10/10\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8915 - accuracy: 0.7176 - val_loss: 0.6505 - val_accuracy: 0.7914\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3653 - accuracy: 0.8968 - val_loss: 0.5267 - val_accuracy: 0.8316\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.9364 - val_loss: 0.4872 - val_accuracy: 0.8478\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9652 - val_loss: 0.4655 - val_accuracy: 0.8544\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.9740 - val_loss: 0.4475 - val_accuracy: 0.8636\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9916 - val_loss: 0.4433 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9944 - val_loss: 0.4704 - val_accuracy: 0.8636\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9992 - val_loss: 0.4559 - val_accuracy: 0.8626\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9996 - val_loss: 0.4606 - val_accuracy: 0.8676\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.8658\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.8696\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.8690\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.8702\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.8708\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.8712\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.8724\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8702\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.8710\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.8696\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.8712\n",
      "157/157 [==============================] - 0s 959us/step - loss: 0.4475 - accuracy: 0.8712\n",
      "test accuracy (10/10): 0.8712000250816345\n",
      "test accuracy with selected features: 0.8084 \n",
      "test accuracy with selected features with penalty: 0.7334 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90fe0a2a-f05b-4b4d-83d2-0510bf2186b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7444 - accuracy: 0.7702 - val_loss: 0.5303 - val_accuracy: 0.8326\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.9266 - val_loss: 0.4753 - val_accuracy: 0.8534\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1714 - accuracy: 0.9614 - val_loss: 0.4104 - val_accuracy: 0.8758\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1126 - accuracy: 0.9802 - val_loss: 0.4306 - val_accuracy: 0.8700\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9900 - val_loss: 0.4248 - val_accuracy: 0.8740\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9946 - val_loss: 0.4215 - val_accuracy: 0.8774\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9986 - val_loss: 0.4078 - val_accuracy: 0.8816\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9994 - val_loss: 0.4064 - val_accuracy: 0.8830\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0289 - accuracy: 0.9998 - val_loss: 0.4051 - val_accuracy: 0.8874\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.8854\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.8880\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.8842\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.8856\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.8864\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.8860\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.8860\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.8858\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.8870\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.8882\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.8872\n",
      "157/157 [==============================] - 0s 933us/step - loss: 0.3933 - accuracy: 0.8872\n",
      "test accuracy (1/5): 0.8871999979019165\n",
      "Iteration 2/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7645 - accuracy: 0.7608 - val_loss: 0.5629 - val_accuracy: 0.8280\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.9172 - val_loss: 0.4356 - val_accuracy: 0.8616\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1812 - accuracy: 0.9602 - val_loss: 0.4496 - val_accuracy: 0.8576\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1234 - accuracy: 0.9810 - val_loss: 0.4144 - val_accuracy: 0.8720\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9846 - val_loss: 0.4261 - val_accuracy: 0.8712\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9966 - val_loss: 0.4094 - val_accuracy: 0.8788\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0466 - accuracy: 0.9990 - val_loss: 0.4156 - val_accuracy: 0.8770\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0354 - accuracy: 0.9998 - val_loss: 0.4184 - val_accuracy: 0.8792\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.8804\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.8800\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.8804\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8820\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.8824\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.8842\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.8834\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.8850\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.8844\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.8834\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.8852\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.8878\n",
      "157/157 [==============================] - 0s 959us/step - loss: 0.4049 - accuracy: 0.8878\n",
      "test accuracy (2/5): 0.8877999782562256\n",
      "Iteration 3/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7990 - accuracy: 0.7480 - val_loss: 0.5617 - val_accuracy: 0.8228\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.9100 - val_loss: 0.4559 - val_accuracy: 0.8582\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1984 - accuracy: 0.9528 - val_loss: 0.4361 - val_accuracy: 0.8628\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9768 - val_loss: 0.4203 - val_accuracy: 0.8702\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9876 - val_loss: 0.4306 - val_accuracy: 0.8696\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9950 - val_loss: 0.4244 - val_accuracy: 0.8720\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0491 - accuracy: 0.9988 - val_loss: 0.4166 - val_accuracy: 0.8736\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0485 - accuracy: 0.9966 - val_loss: 0.4295 - val_accuracy: 0.8744\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.8774\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.8788\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.8780\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.8774\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.8784\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.8774\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8792\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.8798\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.8792\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.8782\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.8796\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8792\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4102 - accuracy: 0.8792\n",
      "test accuracy (3/5): 0.8791999816894531\n",
      "Iteration 4/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7961 - accuracy: 0.7430 - val_loss: 0.6244 - val_accuracy: 0.7986\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.9048 - val_loss: 0.4882 - val_accuracy: 0.8486\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2257 - accuracy: 0.9422 - val_loss: 0.4696 - val_accuracy: 0.8522\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1502 - accuracy: 0.9704 - val_loss: 0.4317 - val_accuracy: 0.8670\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.9840 - val_loss: 0.4458 - val_accuracy: 0.8694\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9934 - val_loss: 0.4402 - val_accuracy: 0.8660\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9962 - val_loss: 0.4485 - val_accuracy: 0.8670\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9986 - val_loss: 0.4423 - val_accuracy: 0.8740\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9998 - val_loss: 0.4484 - val_accuracy: 0.8740\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.8764\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.8754\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.8762\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8748\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.8766\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8780\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8780\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.8778\n",
      "157/157 [==============================] - 0s 947us/step - loss: 0.4304 - accuracy: 0.8778\n",
      "test accuracy (4/5): 0.8777999877929688\n",
      "Iteration 5/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8338 - accuracy: 0.7374 - val_loss: 0.5874 - val_accuracy: 0.8162\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3522 - accuracy: 0.8936 - val_loss: 0.5307 - val_accuracy: 0.8324\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2267 - accuracy: 0.9438 - val_loss: 0.4763 - val_accuracy: 0.8522\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9738 - val_loss: 0.4593 - val_accuracy: 0.8574\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1093 - accuracy: 0.9840 - val_loss: 0.4663 - val_accuracy: 0.8628\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9922 - val_loss: 0.4473 - val_accuracy: 0.8646\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9962 - val_loss: 0.4540 - val_accuracy: 0.8656\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9904 - val_loss: 0.4616 - val_accuracy: 0.8654\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9994 - val_loss: 0.4585 - val_accuracy: 0.8664\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0320 - accuracy: 0.9996 - val_loss: 0.4597 - val_accuracy: 0.8690\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.8698\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.8702\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.8714\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.8690\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.8702\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.8700\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.8702\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.8718\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.8696\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.8718\n",
      "157/157 [==============================] - 0s 953us/step - loss: 0.4525 - accuracy: 0.8718\n",
      "test accuracy (5/5): 0.8718000054359436\n",
      "test accuracy with selected features: 0.822 \n",
      "test accuracy with selected features with penalty: 0.747 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c28a6c0d-4166-440d-ac3a-a11fe19b1c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/4\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7522 - accuracy: 0.7698 - val_loss: 0.6831 - val_accuracy: 0.7938\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.9212 - val_loss: 0.4320 - val_accuracy: 0.8700\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9614 - val_loss: 0.4191 - val_accuracy: 0.8682\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9832 - val_loss: 0.4049 - val_accuracy: 0.8768\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9908 - val_loss: 0.4191 - val_accuracy: 0.8750\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9986 - val_loss: 0.4054 - val_accuracy: 0.8814\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0467 - accuracy: 0.9990 - val_loss: 0.4084 - val_accuracy: 0.8806\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9998 - val_loss: 0.4052 - val_accuracy: 0.8816\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.8868\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.8832\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.8872\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.8846\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.8854\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.8852\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.8868\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.8878\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.8874\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.8864\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 0.8864\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.8874\n",
      "157/157 [==============================] - 0s 951us/step - loss: 0.3878 - accuracy: 0.8874\n",
      "test accuracy (1/4): 0.8873999714851379\n",
      "Iteration 2/4\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7769 - accuracy: 0.7460 - val_loss: 0.5240 - val_accuracy: 0.8394\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.9206 - val_loss: 0.4518 - val_accuracy: 0.8582\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 0.9558 - val_loss: 0.4448 - val_accuracy: 0.8674\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1291 - accuracy: 0.9790 - val_loss: 0.4322 - val_accuracy: 0.8706\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0846 - accuracy: 0.9910 - val_loss: 0.4193 - val_accuracy: 0.8764\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9968 - val_loss: 0.4166 - val_accuracy: 0.8774\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9972 - val_loss: 0.4288 - val_accuracy: 0.8786\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.8778\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.8830\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.8840\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.8838\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.8848\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.8836\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.8866\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.8866\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.8856\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.8824\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.8848\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.8874\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.8858\n",
      "157/157 [==============================] - 0s 959us/step - loss: 0.4088 - accuracy: 0.8858\n",
      "test accuracy (2/4): 0.8858000040054321\n",
      "Iteration 3/4\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7844 - accuracy: 0.7442 - val_loss: 0.5811 - val_accuracy: 0.8166\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3282 - accuracy: 0.9044 - val_loss: 0.5148 - val_accuracy: 0.8392\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9564 - val_loss: 0.4636 - val_accuracy: 0.8580\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1397 - accuracy: 0.9748 - val_loss: 0.4418 - val_accuracy: 0.8634\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9844 - val_loss: 0.4508 - val_accuracy: 0.8690\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9948 - val_loss: 0.4387 - val_accuracy: 0.8680\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9972 - val_loss: 0.4395 - val_accuracy: 0.8696\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.8730\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8704\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.8738\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.8736\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.8748\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.8770\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.8746\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.8776\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8776\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8762\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.8780\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8782\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.8782\n",
      "157/157 [==============================] - 0s 927us/step - loss: 0.4256 - accuracy: 0.8782\n",
      "test accuracy (3/4): 0.8781999945640564\n",
      "Iteration 4/4\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8073 - accuracy: 0.7420 - val_loss: 0.5727 - val_accuracy: 0.8184\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.9032 - val_loss: 0.4906 - val_accuracy: 0.8472\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.2207 - accuracy: 0.9444 - val_loss: 0.4607 - val_accuracy: 0.8556\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1525 - accuracy: 0.9688 - val_loss: 0.4662 - val_accuracy: 0.8548\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1061 - accuracy: 0.9846 - val_loss: 0.4484 - val_accuracy: 0.8648\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9930 - val_loss: 0.4627 - val_accuracy: 0.8616\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9976 - val_loss: 0.4581 - val_accuracy: 0.8676\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9992 - val_loss: 0.4687 - val_accuracy: 0.8642\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9998 - val_loss: 0.4523 - val_accuracy: 0.8678\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.8702\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 1.0000 - val_loss: 0.4547 - val_accuracy: 0.8716\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.8706\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.8708\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.8730\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.8720\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.8718\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.8718\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.8732\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.8742\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.8732\n",
      "157/157 [==============================] - 0s 965us/step - loss: 0.4491 - accuracy: 0.8732\n",
      "test accuracy (4/4): 0.873199999332428\n",
      "test accuracy with selected features: 0.836 \n",
      "test accuracy with selected features with penalty: 0.761 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(4, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca0d6fd0-51e5-478e-b742-d9bfd95b7e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/4\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7191 - accuracy: 0.7708 - val_loss: 0.5000 - val_accuracy: 0.8460\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.9244 - val_loss: 0.4523 - val_accuracy: 0.8594\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9572 - val_loss: 0.4496 - val_accuracy: 0.8640\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9796 - val_loss: 0.4189 - val_accuracy: 0.8752\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9918 - val_loss: 0.4347 - val_accuracy: 0.8740\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9978 - val_loss: 0.4099 - val_accuracy: 0.8784\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0416 - accuracy: 0.9992 - val_loss: 0.4069 - val_accuracy: 0.8812\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.8832\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.8828\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.8838\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.8862\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.8812\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.8848\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.8828\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.8822\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.8842\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.8850\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.8852\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.8852\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.8838\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4020 - accuracy: 0.8838\n",
      "test accuracy (1/4): 0.8838000297546387\n",
      "Iteration 2/4\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7988 - accuracy: 0.7434 - val_loss: 0.5354 - val_accuracy: 0.8338\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.9140 - val_loss: 0.4705 - val_accuracy: 0.8528\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9552 - val_loss: 0.4481 - val_accuracy: 0.8636\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9768 - val_loss: 0.4299 - val_accuracy: 0.8714\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9904 - val_loss: 0.4381 - val_accuracy: 0.8682\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0616 - accuracy: 0.9946 - val_loss: 0.4215 - val_accuracy: 0.8774\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9986 - val_loss: 0.4286 - val_accuracy: 0.8748\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.8762\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9998 - val_loss: 0.4173 - val_accuracy: 0.8792\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.8772\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9996 - val_loss: 0.4209 - val_accuracy: 0.8812\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.8824\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.8812\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.8830\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.8832\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.8842\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.8828\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8848\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.8844\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.8860\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4125 - accuracy: 0.8860\n",
      "test accuracy (2/4): 0.8859999775886536\n",
      "Iteration 3/4\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7990 - accuracy: 0.7440 - val_loss: 0.5487 - val_accuracy: 0.8290\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.9106 - val_loss: 0.4856 - val_accuracy: 0.8474\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9490 - val_loss: 0.4462 - val_accuracy: 0.8628\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9772 - val_loss: 0.4403 - val_accuracy: 0.8640\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.9830 - val_loss: 0.4443 - val_accuracy: 0.8670\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9930 - val_loss: 0.4244 - val_accuracy: 0.8742\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0543 - accuracy: 0.9972 - val_loss: 0.4222 - val_accuracy: 0.8766\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9996 - val_loss: 0.4191 - val_accuracy: 0.8770\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.8788\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.8770\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.8810\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.8826\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8812\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.8832\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.8810\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.8830\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.8838\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8842\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.8844\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.8856\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4105 - accuracy: 0.8856\n",
      "test accuracy (3/4): 0.8855999708175659\n",
      "Iteration 4/4\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.8192 - accuracy: 0.7414 - val_loss: 0.5825 - val_accuracy: 0.8138\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.9054 - val_loss: 0.4735 - val_accuracy: 0.8544\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9488 - val_loss: 0.5041 - val_accuracy: 0.8422\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1447 - accuracy: 0.9730 - val_loss: 0.4718 - val_accuracy: 0.8506\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 0.9864 - val_loss: 0.4371 - val_accuracy: 0.8668\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0717 - accuracy: 0.9938 - val_loss: 0.4488 - val_accuracy: 0.8694\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9986 - val_loss: 0.4478 - val_accuracy: 0.8706\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.8710\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9998 - val_loss: 0.4516 - val_accuracy: 0.8682\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.8740\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.8724\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.8740\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0242 - accuracy: 0.9998 - val_loss: 0.4401 - val_accuracy: 0.8738\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.8724\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8748\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8752\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.8748\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.8740\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8750\n",
      "157/157 [==============================] - 0s 965us/step - loss: 0.4369 - accuracy: 0.8750\n",
      "test accuracy (4/4): 0.875\n",
      "test accuracy with selected features: 0.7992 \n",
      "test accuracy with selected features with penalty: 0.7392000000000001 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(4, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba8a6762-aac0-4a21-a5e0-f226334913a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7576 - accuracy: 0.7638 - val_loss: 0.5327 - val_accuracy: 0.8360\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2829 - accuracy: 0.9208 - val_loss: 0.4249 - val_accuracy: 0.8686\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.9602 - val_loss: 0.4310 - val_accuracy: 0.8660\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9826 - val_loss: 0.4424 - val_accuracy: 0.8662\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9930 - val_loss: 0.4229 - val_accuracy: 0.8718\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9976 - val_loss: 0.4075 - val_accuracy: 0.8784\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9996 - val_loss: 0.4092 - val_accuracy: 0.8798\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy: 0.9994 - val_loss: 0.4111 - val_accuracy: 0.8790\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0296 - accuracy: 0.9998 - val_loss: 0.4046 - val_accuracy: 0.8838\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.8852\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.8848\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.8852\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.8868\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.8856\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.8864\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.8884\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.8876\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.8878\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.8880\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.8888\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3901 - accuracy: 0.8888\n",
      "test accuracy (1/5): 0.8888000249862671\n",
      "Iteration 2/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 5ms/step - loss: 0.7345 - accuracy: 0.7668 - val_loss: 0.5099 - val_accuracy: 0.8468\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.9222 - val_loss: 0.5130 - val_accuracy: 0.8406\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9544 - val_loss: 0.4439 - val_accuracy: 0.8644\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9786 - val_loss: 0.4417 - val_accuracy: 0.8652\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9920 - val_loss: 0.4234 - val_accuracy: 0.8750\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9956 - val_loss: 0.4151 - val_accuracy: 0.8772\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0457 - accuracy: 0.9982 - val_loss: 0.4143 - val_accuracy: 0.8770\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.8800\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.8816\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.8810\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.8832\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.8808\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.8820\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.8844\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.8836\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.8836\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.8840\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.8836\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.8834\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.8842\n",
      "157/157 [==============================] - 0s 959us/step - loss: 0.3959 - accuracy: 0.8842\n",
      "test accuracy (2/5): 0.8841999769210815\n",
      "Iteration 3/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7996 - accuracy: 0.7512 - val_loss: 0.5446 - val_accuracy: 0.8314\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.9148 - val_loss: 0.4772 - val_accuracy: 0.8524\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 0.9512 - val_loss: 0.4363 - val_accuracy: 0.8730\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9794 - val_loss: 0.4363 - val_accuracy: 0.8692\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9912 - val_loss: 0.4137 - val_accuracy: 0.8774\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9948 - val_loss: 0.4198 - val_accuracy: 0.8770\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 0.9994 - val_loss: 0.4255 - val_accuracy: 0.8790\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.8802\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8834\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.8824\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.8816\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9998 - val_loss: 0.4150 - val_accuracy: 0.8832\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.8838\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.8842\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.8828\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.8856\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.8836\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.8844\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.8826\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.8842\n",
      "157/157 [==============================] - 0s 972us/step - loss: 0.4088 - accuracy: 0.8842\n",
      "test accuracy (3/5): 0.8841999769210815\n",
      "Iteration 4/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.7957 - accuracy: 0.7480 - val_loss: 0.5381 - val_accuracy: 0.8310\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.9072 - val_loss: 0.4689 - val_accuracy: 0.8524\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9554 - val_loss: 0.4673 - val_accuracy: 0.8522\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9698 - val_loss: 0.4607 - val_accuracy: 0.8572\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0961 - accuracy: 0.9884 - val_loss: 0.4511 - val_accuracy: 0.8610\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9940 - val_loss: 0.4621 - val_accuracy: 0.8626\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0508 - accuracy: 0.9998 - val_loss: 0.4363 - val_accuracy: 0.8704\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9994 - val_loss: 0.4353 - val_accuracy: 0.8728\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.8734\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0291 - accuracy: 0.9994 - val_loss: 0.4351 - val_accuracy: 0.8742\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.8746\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.8746\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.8756\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.8770\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.8764\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.8768\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8766\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.8786\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8792\n",
      "157/157 [==============================] - 0s 953us/step - loss: 0.4243 - accuracy: 0.8792\n",
      "test accuracy (4/5): 0.8791999816894531\n",
      "Iteration 5/5\n",
      "Epoch 1/20\n",
      "79/79 [==============================] - 1s 4ms/step - loss: 0.8413 - accuracy: 0.7260 - val_loss: 0.6151 - val_accuracy: 0.8042\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.9062 - val_loss: 0.5193 - val_accuracy: 0.8362\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.9432 - val_loss: 0.4528 - val_accuracy: 0.8614\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.1454 - accuracy: 0.9710 - val_loss: 0.4524 - val_accuracy: 0.8582\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9862 - val_loss: 0.4320 - val_accuracy: 0.8690\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0749 - accuracy: 0.9942 - val_loss: 0.4350 - val_accuracy: 0.8728\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9932 - val_loss: 0.4470 - val_accuracy: 0.8708\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0423 - accuracy: 0.9990 - val_loss: 0.4389 - val_accuracy: 0.8752\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9998 - val_loss: 0.4386 - val_accuracy: 0.8744\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.8770\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8756\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.8762\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.8778\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.8790\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.8800\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8800\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0186 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.8792\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.8806\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.8810\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8804\n",
      "157/157 [==============================] - 0s 933us/step - loss: 0.4254 - accuracy: 0.8804\n",
      "test accuracy (5/5): 0.8804000020027161\n",
      "test accuracy with selected features: 0.7652 \n",
      "test accuracy with selected features with penalty: 0.70895 \n"
     ]
    }
   ],
   "source": [
    "model_feature_selection(5, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da5d49-d969-41bc-872e-d856becb1eaf",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________________________________________________________\n",
    "The function `model_feature_selection()` performs feature selection by iteratively training a model and selecting the top features based on their weights. The function takes two parameters, `num_iterations` and `num_features`, that determine the number of iterations and the number of features to select per iteration.\n",
    "\n",
    "Here the penalty for each feature is fixed at 0.00075. This means that as the number of selected features increases, the penalty increases linearly, leading to a decrease in accuracy. Therefore, we expect to see a decreasing trend in accuracy as the number of selected features increases.\n",
    "\n",
    "Based on the results provided, we can observe the following trends:\n",
    "\n",
    "*For 200 features*:\n",
    "- With 10 iterations and 20 features per iteration, the accuracy is 0.7176.\n",
    "- With 5 iterations and 40 features per iteration, the accuracy is 0.7296.\n",
    "- With 2 iterations and 100 features per iteration, the model may not have enough capacity to accurately learn from the data.\n",
    "\n",
    "*For 150 features*:\n",
    "- With 3 iterations and 50 features per iteration, the accuracy is 0.7461, which is higher compared to using 200 features with the same total number of features.\n",
    "- With 10 iterations and 15 features per iteration, the accuracy is 0.7259.\n",
    "\n",
    "*For 100 features*:\n",
    "- With 10 iterations and 10 features per iteration, the accuracy is 0.7334, which is higher compared to using 150 or 200 features with the same total number of features.\n",
    "- With 4 iterations and 25 features per iteration, the accuracy is 0.761, which is the highest accuracy among all the tested conditions.\n",
    "- With 5 iterations and 20 features per iteration, the accuracy is 0.747.\n",
    " \n",
    "*For 80 features*:\n",
    "- With 4 iterations and 20 features per iteration, the accuracy is 0.73.\n",
    "- With 5 iterations and 15 features per iteration, the accuracy is 0.70.\n",
    "\n",
    "Based on the results, it seems that selecting fewer features with more iterations generally leads to better accuracy. This is likely because with fewer features per iteration, the selected features are likely to be more informative, and with more iterations, the model can learn more complex patterns from the data.\n",
    "\n",
    "Additionally, we can see that the condition that gives the ***best score is with 4 iterations and 25 features per iteration***, with an accuracy of 0.761. This could be because this condition strikes a good balance between the number of features and the number of iterations, allowing the model to select informative features while still having enough capacity to learn from the data.\n",
    "\n",
    "In summary, the optimal combination of `num_iterations` and `num_features` depends on the specific dataset and problem at hand. However, in general, selecting fewer features with more iterations may lead to better accuracy, and there is a trade-off between the number of features selected and the penalty for each feature. The best score is achieved when this trade-off is optimized. And according to the penalty and computing cost, here the trade offs and number of features and number of iterations are tryed to be optimized.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
